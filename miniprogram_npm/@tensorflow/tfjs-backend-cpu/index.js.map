{"version":3,"file":"tf-backend-cpu.min.js","sources":["../src/cpu_util.ts","../src/backend_cpu.ts","../src/kernels/Abs.ts","../src/utils/binary_impl.ts","../src/kernels/Complex.ts","../src/kernels/Identity.ts","../src/kernels/Real.ts","../src/kernels/Cast.ts","../src/utils/kernel_utils.ts","../src/kernels/Add.ts","../src/utils/unary_impl.ts","../src/utils/unary_utils.ts","../src/kernels/Ceil.ts","../src/kernels/Exp.ts","../src/kernels/Expm1.ts","../src/kernels/Floor.ts","../src/kernels/Log.ts","../src/kernels/Max_impl.ts","../src/kernels/Multiply.ts","../src/kernels/Rsqrt.ts","../src/kernels/Slice.ts","../src/kernels/Sub.ts","../src/kernels/Transpose_impl.ts","../src/kernels/Unique_impl.ts","../src/base.ts","../src/kernels/Acos.ts","../src/kernels/Acosh.ts","../src/kernels/Asin.ts","../src/kernels/Asinh.ts","../src/kernels/Atan.ts","../src/kernels/Atanh.ts","../src/utils/pool_utils.ts","../src/kernels/AvgPool.ts","../src/kernels/AvgPoolBackprop.ts","../src/kernels/BatchNorm.ts","../src/kernels/Clip.ts","../src/kernels/Imag.ts","../src/kernels/Reshape.ts","../src/kernels/Concat.ts","../src/kernels/Cos.ts","../src/kernels/Cosh.ts","../src/kernels/Dilation2D.ts","../src/kernels/Dilation2DBackpropFilter.ts","../src/kernels/Dilation2DBackpropInput.ts","../src/kernels/Div.ts","../src/kernels/Elu.ts","../src/kernels/Erf.ts","../src/utils/fft_utils.ts","../src/kernels/FFT.ts","../src/kernels/FlipLeftRight.ts","../src/kernels/IFFT.ts","../src/kernels/IsFinite.ts","../src/kernels/IsInf.ts","../src/kernels/IsNaN.ts","../src/kernels/Log1p.ts","../src/kernels/LogicalNot.ts","../src/kernels/Max.ts","../src/kernels/MaxPool.ts","../src/kernels/MaxPoolBackprop.ts","../src/kernels/MaxPoolWithArgmax.ts","../src/kernels/MaxPoolWithArgmax_impl.ts","../src/kernels/NonMaxSuppressionV4.ts","../src/kernels/NonMaxSuppressionV5.ts","../src/kernels/NotEqual.ts","../src/kernels/PadV2.ts","../src/kernels/Reciprocal.ts","../src/kernels/RotateWithOffset.ts","../src/kernels/Round.ts","../src/kernels/Selu.ts","../src/kernels/Sigmoid.ts","../src/kernels/Sign.ts","../src/kernels/Sin.ts","../src/kernels/Sinh.ts","../src/kernels/Softplus.ts","../src/kernels/Transpose.ts","../src/kernels/SpaceToBatchND.ts","../src/kernels/Sqrt.ts","../src/kernels/Square.ts","../src/kernels/SquaredDifference.ts","../src/kernels/Step.ts","../src/kernels/Tan.ts","../src/kernels/Tanh.ts","../src/register_all_kernels.ts","../src/kernels/Unique.ts","../src/version.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TensorInfo, util} from '@tensorflow/tfjs-core';\n\nexport function assertNotComplex(\n    tensor: TensorInfo|TensorInfo[], opName: string): void {\n  if (!Array.isArray(tensor)) {\n    tensor = [tensor];\n  }\n  tensor.forEach(t => {\n    if (t != null) {\n      util.assert(\n          t.dtype !== 'complex64',\n          () => `${\n              opName} does not support complex64 tensors in the CPU backend.`);\n    }\n  });\n}\n","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\nimport {backend_util, BackendTimingInfo, DataStorage, DataType, DataValues, engine, env, kernel_impls, KernelBackend, max, NumericDataType, Rank, Scalar, ShapeMap, slice_util, Tensor, Tensor1D, Tensor2D, Tensor3D, Tensor4D, Tensor5D, TensorBuffer, TensorInfo, TypedArray, upcastType, util} from '@tensorflow/tfjs-core';\n\nconst nonMaxSuppressionV3Impl = kernel_impls.nonMaxSuppressionV3Impl;\nconst split = kernel_impls.split;\nconst tile = kernel_impls.tile;\nconst topkImpl = kernel_impls.topkImpl;\nconst whereImpl = kernel_impls.whereImpl;\nimport * as seedrandom from 'seedrandom';\nimport {assertNotComplex} from './cpu_util';\n\ninterface DataId {}\n\nfunction mapActivation(\n    backend: MathBackendCPU, x: Tensor, activation: backend_util.Activation,\n    preluActivationWeights?: Tensor): Tensor {\n  if (activation === 'linear') {\n    return backend.linear(x);\n  } else if (activation === 'relu') {\n    return backend.relu(x);\n  } else if (activation === 'elu') {\n    return tf.elu(x);\n  } else if (activation === 'relu6') {\n    return backend.relu6(x);\n  } else if (activation === 'prelu') {\n    return backend.prelu(x, preluActivationWeights);\n  }\n  throw new Error(\n      `Activation ${activation} has not been implemented for the CPU backend.`);\n}\n\nexport interface TensorData<D extends DataType> {\n  values?: backend_util.BackendValues;\n  dtype: D;\n  // For complex numbers, the real and imaginary parts are stored as their own\n  // individual tensors, with a parent joining the two with the\n  // complexTensorInfos field.\n  complexTensorInfos?: {real: TensorInfo, imag: TensorInfo};\n  // refCount keeps track of how many tensors reference it. Used for memory\n  // management.\n  refCount: number;\n}\n\nexport class MathBackendCPU extends KernelBackend {\n  public blockSize = 48;\n\n  data: DataStorage<TensorData<DataType>>;\n  private firstUse = true;\n\n  constructor() {\n    super();\n    this.data = new DataStorage(this, engine());\n  }\n\n  write(values: backend_util.BackendValues, shape: number[], dtype: DataType):\n      DataId {\n    if (this.firstUse) {\n      this.firstUse = false;\n      if (env().get('IS_NODE')) {\n        backend_util.warn(\n            '\\n============================\\n' +\n            'Hi there ðŸ‘‹. Looks like you are running TensorFlow.js in ' +\n            'Node.js. To speed things up dramatically, install our node ' +\n            'backend, which binds to TensorFlow C++, by running ' +\n            'npm i @tensorflow/tfjs-node, ' +\n            'or npm i @tensorflow/tfjs-node-gpu if you have CUDA. ' +\n            'Then call require(\\'@tensorflow/tfjs-node\\'); (-gpu ' +\n            'suffix for CUDA) at the start of your program. ' +\n            'Visit https://github.com/tensorflow/tfjs-node for more details.' +\n            '\\n============================');\n      }\n    }\n    const dataId = {};\n\n    this.data.set(dataId, {values, dtype, refCount: 1});\n\n    return dataId;\n  }\n\n  /**\n   * Create a data bucket in cpu backend.\n   * @param shape Shape of the `TensorInfo`.\n   * @param dtype DType of the `TensorInfo`.\n   * @param values The value of the `TensorInfo` stored as a flattened array.\n   */\n  makeTensorInfo(\n      shape: number[], dtype: DataType,\n      values?: backend_util.BackendValues): TensorInfo {\n    const outId = this.write(values, shape, dtype);\n\n    return {dataId: outId, shape, dtype};\n  }\n\n  /** Increase refCount of a `TensorData`. */\n  incRef(dataId: DataId): void {\n    const tensorData = this.data.get(dataId);\n    tensorData.refCount++;\n  }\n\n  /** Decrease refCount of a `TensorData`. */\n  decRef(dataId: DataId): void {\n    if (this.data.has(dataId)) {\n      const tensorData = this.data.get(dataId);\n      tensorData.refCount--;\n    }\n  }\n\n  move(\n      dataId: DataId, values: backend_util.BackendValues, shape: number[],\n      dtype: DataType): void {\n    this.data.set(dataId, {values, dtype, refCount: 1});\n  }\n\n  numDataIds(): number {\n    return this.data.numDataIds();\n  }\n\n  async read(dataId: DataId): Promise<backend_util.BackendValues> {\n    return this.readSync(dataId);\n  }\n  readSync(dataId: DataId): backend_util.BackendValues {\n    const {dtype, complexTensorInfos} = this.data.get(dataId);\n\n    if (dtype === 'complex64') {\n      const realValues =\n          this.readSync(complexTensorInfos.real.dataId) as Float32Array;\n      const imagValues =\n          this.readSync(complexTensorInfos.imag.dataId) as Float32Array;\n      return backend_util.mergeRealAndImagArrays(realValues, imagValues);\n    }\n\n    return this.data.get(dataId).values;\n  }\n\n  private bufferSync<R extends Rank>(t: Tensor<R>): TensorBuffer<R> {\n    const data = this.readSync(t.dataId);\n    let decodedData = data as DataValues;\n    if (t.dtype === 'string') {\n      try {\n        // Decode the bytes into string.\n        decodedData = (data as Uint8Array[]).map(d => util.decodeString(d));\n      } catch {\n        throw new Error('Failed to decode encoded string bytes into utf-8');\n      }\n    }\n    return tf.buffer(t.shape, t.dtype, decodedData) as TensorBuffer<R>;\n  }\n\n  makeOutput<T extends Tensor>(\n      values: backend_util.BackendValues, shape: number[], dtype: DataType): T {\n    const dataId = this.write(values, shape, dtype);\n    return engine().makeTensorFromDataId(dataId, shape, dtype, this) as T;\n  }\n\n  disposeData(dataId: DataId): void {\n    if (this.data.has(dataId)) {\n      const {complexTensorInfos} = this.data.get(dataId);\n\n      if (complexTensorInfos != null) {\n        this.disposeData(complexTensorInfos.real.dataId);\n        this.disposeData(complexTensorInfos.imag.dataId);\n      }\n\n      this.data.delete(dataId);\n    }\n  }\n\n  disposeIntermediateTensorInfo(tensorInfo: TensorInfo): void {\n    const dataId = tensorInfo.dataId;\n\n    if (this.data.has(dataId)) {\n      const tensorData = this.data.get(dataId);\n\n      tensorData.refCount--;\n\n      if (tensorData.refCount < 1) {\n        this.disposeData(dataId);\n      }\n    }\n  }\n\n  async time(f: () => void): Promise<BackendTimingInfo> {\n    const start = util.now();\n    f();\n    const kernelMs = util.now() - start;\n    return {kernelMs};\n  }\n\n  memory() {\n    return {\n      // Unreliable due to automatic gc. The numbers above are cumulative.\n      unreliable: true,\n      reasons:\n          ['The reported memory is an upper bound. Due to automatic garbage ' +\n           'collection, the true allocated memory may be less.']\n    };\n  }\n\n  stridedSlice<T extends Tensor>(\n      x: T, begin: number[], end: number[], strides: number[]): T {\n    assertNotComplex(x, 'stridedSlice');\n\n    const outShape = slice_util.computeOutShape(begin, end, strides);\n\n    if (outShape.some(axis => axis === 0)) {\n      return tf.tensor([], outShape) as T;\n    }\n\n    const buffer = tf.buffer(outShape, x.dtype);\n    const xBuf = this.bufferSync(x);\n    for (let i = 0; i < buffer.size; i++) {\n      const loc = buffer.indexToLoc(i);\n\n      const newLoc: number[] = new Array(loc.length);\n      for (let j = 0; j < newLoc.length; j++) {\n        newLoc[j] = loc[j] * strides[j] + begin[j];\n      }\n      buffer.set(xBuf.get(...newLoc), ...loc);\n    }\n\n    return buffer.toTensor() as T;\n  }\n\n  diag(x: Tensor): Tensor {\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    const buffer = tf.buffer([x.size, x.size], x.dtype);\n    const vals = buffer.values;\n    for (let i = 0; i < xVals.length; i++) {\n      vals[i * x.size + i] = xVals[i];\n    }\n    return buffer.toTensor();\n  }\n\n  unstack(x: Tensor, axis: number): Tensor[] {\n    const num = x.shape[axis];\n    const outShape: number[] = new Array(x.rank - 1);\n    let outIndex = 0;\n    for (let i = 0; i < x.rank; i++) {\n      if (i !== axis) {\n        outShape[outIndex++] = x.shape[i];\n      }\n    }\n\n    const begin = new Array(x.rank).fill(0);\n    const size = x.shape.slice();\n    size[axis] = 1;\n    const res = new Array(num);\n    for (let i = 0; i < res.length; i++) {\n      begin[axis] = i;\n      res[i] = tf.slice(x, begin, size).reshape(outShape);\n    }\n    return res;\n  }\n\n  reverse<T extends Tensor>(x: T, axis: number[]): T {\n    assertNotComplex(x, 'reverse');\n\n    const buffer = tf.buffer(x.shape, x.dtype);\n    const xBuf = this.bufferSync(x);\n\n    for (let i = 0; i < buffer.size; i++) {\n      const outLoc = buffer.indexToLoc(i);\n      const inLoc = outLoc.slice();\n      axis.forEach(ax => inLoc[ax] = x.shape[ax] - 1 - inLoc[ax]);\n      buffer.set(xBuf.get(...inLoc), ...outLoc);\n    }\n\n    return buffer.toTensor() as T;\n  }\n\n  neg<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'neg');\n\n    // TODO(lina128): Use mul directly once neg is modularized.\n    return tf.mul(tf.scalar(-1), x);\n  }\n\n  addN<T extends Tensor>(tensors: T[]): T {\n    assertNotComplex(tensors, 'addN');\n\n    const vals = tensors.map(t => this.readSync(t.dataId) as TypedArray);\n    const result = tf.buffer(tensors[0].shape, tensors[0].dtype as 'float32');\n    const resultVals = result.values;\n    for (let i = 0; i < tensors.length; i++) {\n      const currVals = vals[i];\n      for (let j = 0; j < resultVals.length; j++) {\n        resultVals[j] += currVals[j];\n      }\n    }\n    return result.toTensor() as T;\n  }\n\n  softmax<T extends Tensor>(logits: T, dim: number): T {\n    const axes = util.parseAxisParam([dim], logits.shape);\n    // TODO(annxingyuan): Call maxImpl rather than op as part of softmax kernel\n    // modularization.\n    const maxLogit = max(logits, axes);\n    const expandedShape =\n        backend_util.expandShapeToKeepDim(maxLogit.shape, axes);\n\n    // TODO(lina128): Use sub directly once softmax is modularized.\n    const a = tf.sub(logits, maxLogit.reshape(expandedShape));\n    const b = tf.exp(a);\n    const sumExp = this.sum(b, axes).reshape(expandedShape);\n\n    // TODO(annxingyuan): Call divImpl rather than op as part of softmax\n    // kernel modularization.\n    return tf.div(b, sumExp);\n  }\n\n  pow<T extends Tensor>(a: T, b: Tensor): T {\n    assertNotComplex([a, b], 'pow');\n\n    return this.broadcastedBinaryOp(\n               a, b, a.dtype, (aValue, bValue) => Math.pow(aValue, bValue)) as\n        T;\n  }\n\n  batchMatMul(\n      a: Tensor3D, b: Tensor3D, transposeA: boolean,\n      transposeB: boolean): Tensor3D {\n    assertNotComplex([a, b], 'matMul');\n\n    const sharedDim = transposeA ? a.shape[1] : a.shape[2];\n    const leftDim = transposeA ? a.shape[2] : a.shape[1];\n    const rightDim = transposeB ? b.shape[1] : b.shape[2];\n    const batchDim = a.shape[0];\n\n    const aValues = this.readSync(a.dataId) as TypedArray;\n    const bValues = this.readSync(b.dataId) as TypedArray;\n    const [aBatch, aOuterStep, aInnerStep] = transposeA ?\n        [a.strides[0], 1, a.strides[1]] :\n        [a.strides[0], a.strides[1], 1];\n    const [bInnerStep, bOuterStep, bBatch] = transposeB ?\n        [1, b.strides[1], b.strides[0]] :\n        [b.strides[1], 1, b.strides[0]];\n\n    const size = leftDim * rightDim;\n    const result = tf.buffer([batchDim, leftDim, rightDim], a.dtype);\n    const resVals = result.values as TypedArray;\n    const blockSize = this.blockSize;\n\n    for (let b = 0; b < batchDim; b++) {\n      for (let i0 = 0; i0 < leftDim; i0 += blockSize) {\n        for (let j0 = 0; j0 < rightDim; j0 += blockSize) {\n          for (let k0 = 0; k0 < sharedDim; k0 += blockSize) {\n            // for when blockSize doesn't evenly divide the input\n            const iBlock = Math.min(i0 + blockSize, leftDim);\n            const jBlock = Math.min(j0 + blockSize, rightDim);\n            const kBlock = Math.min(k0 + blockSize, sharedDim);\n\n            for (let i = i0; i < iBlock; i++) {\n              for (let j = j0; j < jBlock; j++) {\n                let sum = 0.0;\n\n                for (let k = k0; k < kBlock; k++) {\n                  sum += aValues[b * aBatch + i * aOuterStep + k * aInnerStep] *\n                      bValues[k * bInnerStep + j * bOuterStep + b * bBatch];\n                }\n                resVals[b * size + (i * rightDim + j)] += sum;\n              }\n            }\n          }\n        }\n      }\n    }\n    return result.toTensor() as Tensor3D;\n  }\n\n  fusedBatchMatMul(\n      {a, b, transposeA, transposeB, bias, activation, preluActivationWeights}:\n          backend_util.FusedBatchMatMulConfig): Tensor3D {\n    let result = this.batchMatMul(a, b, transposeA, transposeB);\n    if (bias) {\n      // TODO(lina128): Use add directly once fusedBatchMatMul is modularized.\n      result = tf.add(result, bias);\n    }\n    if (activation) {\n      result =\n          mapActivation(this, result, activation, preluActivationWeights) as\n          Tensor3D;\n    }\n\n    return result;\n  }\n\n  floorDiv(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'floorDiv');\n\n    const op = (a: number, b: number) => Math.floor(a / b);\n    const outputDtype = 'int32';\n    return this.broadcastedBinaryOp(a, b, outputDtype, op);\n  }\n\n  sum(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'sum');\n\n    backend_util.assertAxesAreInnerMostDims('sum', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const resultDtype = upcastType(x.dtype, 'int32');\n    const result = tf.zeros(outShape, resultDtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let sum = 0;\n      for (let j = 0; j < reduceSize; ++j) {\n        sum += aVals[offset + j];\n      }\n      vals[i] = sum;\n    }\n    return result;\n  }\n\n  prod(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'sum');\n\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const resultDtype = upcastType(x.dtype, 'int32');\n    const result = tf.zeros(outShape, resultDtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let prod = 1;\n      for (let j = 0; j < reduceSize; ++j) {\n        prod *= aVals[offset + j];\n      }\n      vals[i] = prod;\n    }\n    return result;\n  }\n\n  unsortedSegmentSum<T extends Tensor>(\n      x: T, segmentIds: Tensor1D, numSegments: number): Tensor {\n    assertNotComplex(x, 'unsortedSegmentSum');\n\n    const res = [];\n\n    // Reshape the segment id's so that they can be broadcast with\n    // x. The new shape should be [segmentIds.shape, 1, ..., 1]\n    const numIters = x.rank - segmentIds.rank;\n    for (let i = 0; i < numIters; ++i) {\n      segmentIds = segmentIds.expandDims(i + 1);\n    }\n\n    for (let i = 0; i < numSegments; ++i) {\n      const segmentId = tf.scalar(i, 'int32');\n      const mask = tf.equal(segmentId, segmentIds).asType('float32');\n      const sum = mask.mul(x).sum(0);\n      res.push(sum);\n    }\n\n    return tf.stack(res);\n  }\n\n  argMin(x: Tensor, axis: number): Tensor {\n    assertNotComplex(x, 'argMin');\n\n    const axes = [axis];\n    backend_util.assertAxesAreInnerMostDims('argMin', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, 'int32');\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let min = aVals[offset];\n      let minIndex = 0;\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        if (value < min) {\n          min = value;\n          minIndex = j;\n        }\n      }\n      vals[i] = minIndex;\n    }\n    return result;\n  }\n\n  argMax(x: Tensor, axis: number): Tensor {\n    assertNotComplex(x, 'argMax');\n\n    const axes = [axis];\n    backend_util.assertAxesAreInnerMostDims('argMax', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, 'int32');\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let max = aVals[offset];\n      let maxIndex = 0;\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        if (value > max) {\n          max = value;\n          maxIndex = j;\n        }\n      }\n      vals[i] = maxIndex;\n    }\n    return result;\n  }\n\n  cumsum(x: Tensor, axis: number, exclusive: boolean, reverse: boolean):\n      Tensor {\n    assertNotComplex(x, 'cumsum');\n\n    if (axis !== x.rank - 1) {\n      throw new Error(\n          `backend.cumsum in CPU expects an inner-most axis=${x.rank - 1} ` +\n          `but got axis=${axis}`);\n    }\n    const resultDtype = upcastType(x.dtype, 'int32');\n    const result = tf.zeros(x.shape, resultDtype);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    const finalDim = x.shape[x.rank - 1];\n    const indexAdjuster = reverse ?\n        (i: number, j: number) => i + finalDim - j - 1 :\n        (i: number, j: number) => i + j;\n    for (let i = 0; i < aVals.length; i += finalDim) {\n      for (let j = 0; j < finalDim; j++) {\n        const idx = indexAdjuster(i, j);\n        if (j === 0) {\n          vals[idx] = exclusive ? 0 : aVals[idx];\n        } else {\n          const prevIdx = indexAdjuster(i, j - 1);\n          vals[idx] = exclusive ? aVals[prevIdx] + vals[prevIdx] :\n                                  aVals[idx] + vals[prevIdx];\n        }\n      }\n    }\n    return result;\n  }\n\n  equal(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'equal');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal === bVal) ? 1 : 0;\n    });\n  }\n\n  notEqual(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'notEqual');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal !== bVal) ? 1 : 0;\n    });\n  }\n\n  less(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'less');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal < bVal) ? 1 : 0;\n    });\n  }\n\n  lessEqual(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'lessEqual');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal <= bVal) ? 1 : 0;\n    });\n  }\n\n  greater(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'greater');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal > bVal) ? 1 : 0;\n    });\n  }\n\n  greaterEqual(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'greaterEqual');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal >= bVal) ? 1 : 0;\n    });\n  }\n\n  logicalAnd(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'logicalAnd');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return aVal && bVal;\n    });\n  }\n\n  logicalOr(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'logicalOr');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return aVal || bVal;\n    });\n  }\n\n  select(condition: Tensor, a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([condition, a, b], 'select');\n\n    const values = this.readSync(condition.dataId) as TypedArray;\n    const aValues = this.readSync(a.dataId) as TypedArray;\n    const bValues = this.readSync(b.dataId) as TypedArray;\n    const result = tf.zeros(a.shape, upcastType(a.dtype, b.dtype));\n    const newValues = this.readSync(result.dataId) as TypedArray;\n    let index = 0;\n    const offset = condition.rank === 0 || condition.rank > 1 || a.rank === 1 ?\n        1 :\n        util.sizeFromShape(a.shape.slice(1));\n\n    for (let i = 0; i < values.length; i++) {\n      for (let j = 0; j < offset; j++) {\n        if (values[i] === 1) {\n          newValues[index++] = aValues[i];\n        } else {\n          newValues[index++] = bValues[i];\n        }\n      }\n    }\n\n    return result;\n  }\n\n  where(condition: Tensor): Tensor2D {\n    assertNotComplex([condition], 'where');\n\n    const condVals = this.readSync(condition.dataId) as TypedArray;\n    return whereImpl(condition.shape, condVals);\n  }\n\n  topk<T extends Tensor>(x: T, k: number, sorted: boolean): [T, T] {\n    assertNotComplex(x, 'topk');\n\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    return topkImpl(xVals, x.shape, x.dtype as NumericDataType, k, sorted);\n  }\n\n  min(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'min');\n\n    backend_util.assertAxesAreInnerMostDims('min', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, x.dtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let min = aVals[offset];\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        if (value < min) {\n          min = value;\n        }\n      }\n      vals[i] = min;\n    }\n    return result;\n  }\n\n  minimum(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'minimum');\n\n    return this.broadcastedBinaryOp(\n        a, b, a.dtype, (aVal, bVal) => Math.min(aVal, bVal));\n  }\n\n  mod(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'mod');\n\n    return this.broadcastedBinaryOp(a, b, a.dtype, (aVal, bVal) => {\n      const rem = aVal % bVal;\n      if ((aVal < 0 && bVal < 0) || (aVal >= 0 && bVal >= 0)) {\n        return rem;\n      } else {\n        return (rem + bVal) % bVal;\n      }\n    });\n  }\n\n  maximum(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'maximum');\n\n    return this.broadcastedBinaryOp(\n        a, b, a.dtype, (aVal, bVal) => Math.max(aVal, bVal));\n  }\n\n  all(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'all');\n\n    backend_util.assertAxesAreInnerMostDims('all', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, x.dtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let all = aVals[offset];\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        all = all && value;\n      }\n      vals[i] = all;\n    }\n    return result;\n  }\n\n  any(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'any');\n\n    backend_util.assertAxesAreInnerMostDims('any', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, x.dtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let anyVal = aVals[offset];\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        anyVal = anyVal || value;\n      }\n      vals[i] = anyVal;\n    }\n    return result;\n  }\n\n  squaredDifference(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'squaredDifference');\n\n    return this.broadcastedBinaryOp(a, b, a.dtype, (aVal, bVal) => {\n      const diff = aVal - bVal;\n      return diff * diff;\n    });\n  }\n\n  linear<T extends Tensor>(x: T): T {\n    return x;\n  }\n\n  relu<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'relu');\n\n    const res = tf.zeros(x.shape, x.dtype);\n    const resVals = this.readSync(res.dataId) as TypedArray;\n    const inVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < inVals.length; ++i) {\n      resVals[i] = Math.max(0, inVals[i]);\n    }\n    return res as T;\n  }\n\n  relu6<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'relu');\n\n    const res = tf.zeros(x.shape, x.dtype);\n    const resVals = this.readSync(res.dataId) as TypedArray;\n    const inVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < inVals.length; ++i) {\n      resVals[i] = Math.min(Math.max(0, inVals[i]), 6);\n    }\n    return res as T;\n  }\n\n  prelu<T extends Tensor>(x: T, a: T): T {\n    assertNotComplex([x, a], 'prelu');\n\n    return this.broadcastedBinaryOp(\n               x, a, x.dtype,\n               (xValue, aValue) => xValue < 0 ? aValue * xValue : xValue) as T;\n  }\n\n  eluDer<T extends Tensor>(dy: T, y: T): T {\n    assertNotComplex([dy, y], 'eluDer');\n\n    const resultValues = new Float32Array(y.size);\n    const values = this.readSync(y.dataId) as TypedArray;\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      const v = values[i];\n      if (v >= 1) {\n        resultValues[i] = dyValues[i];\n      } else {\n        resultValues[i] = dyValues[i] * (v + 1);\n      }\n    }\n    return this.makeOutput(resultValues, y.shape, 'float32');\n  }\n\n  atan2<T extends Tensor>(a: T, b: T): T {\n    assertNotComplex([a, b], 'atan2');\n\n    return this.broadcastedBinaryOp(\n               a, b, a.dtype, (aValue, bValue) => Math.atan2(aValue, bValue)) as\n        T;\n  }\n\n  fusedConv2d(\n      {input, filter, convInfo, bias, activation, preluActivationWeights}:\n          backend_util.FusedConv2DConfig): Tensor4D {\n    let result = this.conv2d(input, filter, convInfo);\n\n    if (bias) {\n      // TODO(lina128): Use add directly once fusedConv2d is modularized.\n      result = tf.add(result, bias);\n    }\n    if (activation) {\n      result =\n          mapActivation(this, result, activation, preluActivationWeights) as\n          Tensor4D;\n    }\n    return result;\n  }\n\n  conv2d(x: Tensor4D, filter: Tensor4D, convInfo: backend_util.Conv2DInfo):\n      Tensor4D {\n    assertNotComplex([x, filter], 'conv2d');\n\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const padLeft = convInfo.padInfo.left;\n    const padTop = convInfo.padInfo.top;\n    const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n\n    const y = tf.buffer(convInfo.outShape, x.dtype as 'float32');\n\n    const xBatchStride = x.strides[0];\n    const xRowStride = isChannelsLast ? x.strides[1] : x.strides[2];\n    const xColStride = isChannelsLast ? x.strides[2] : 1;\n    const xChannelStride = isChannelsLast ? 1 : x.strides[1];\n    const yBatchStride = y.strides[0];\n    const yRowStride = isChannelsLast ? y.strides[1] : y.strides[2];\n    const yColStride = isChannelsLast ? y.strides[2] : 1;\n    const yChannelStride = isChannelsLast ? 1 : y.strides[1];\n\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    const wVals = this.readSync(filter.dataId) as TypedArray;\n    const yVals = y.values;\n\n    for (let b = 0; b < convInfo.batchSize; ++b) {\n      const xOffset1 = b * xBatchStride;\n      const yOffset1 = b * yBatchStride;\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const yOffset2 = yOffset1 + yR * yRowStride;\n        const xRCorner = yR * convInfo.strideHeight - padTop;\n        for (let wR = 0; wR < filterHeight; wR++) {\n          const xR = xRCorner + wR * dilationHeight;\n          if (xR < 0 || xR >= convInfo.inHeight) {\n            continue;\n          }\n          const wOffset1 = wR * filter.strides[0];\n          const xOffset2 = xOffset1 + xR * xRowStride;\n          for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n            const yOffset3 = yOffset2 + yC * yColStride;\n            const xCCorner = yC * convInfo.strideWidth - padLeft;\n            for (let wC = 0; wC < filterWidth; wC++) {\n              const xC = xCCorner + wC * dilationWidth;\n              if (xC < 0 || xC >= convInfo.inWidth) {\n                continue;\n              }\n              const wOffset2 = wOffset1 + wC * filter.strides[1];\n              const xOffset3 = xOffset2 + xC * xColStride;\n              let wOffset3 = wOffset2;\n              for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                const xVal = xVals[xOffset3 + d1 * xChannelStride];\n                for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                  yVals[yOffset3 + d2 * yChannelStride] +=\n                      xVal * wVals[wOffset3 + d2];\n                }\n                wOffset3 += convInfo.outChannels;\n              }\n            }\n          }\n        }\n      }\n    }\n    return y.toTensor() as Tensor4D;\n  }\n\n  conv3d(x: Tensor5D, filter: Tensor5D, convInfo: backend_util.Conv3DInfo):\n      Tensor5D {\n    const filterDepth = convInfo.filterDepth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const padFront = convInfo.padInfo.front;\n    const padLeft = convInfo.padInfo.left;\n    const padTop = convInfo.padInfo.top;\n    const y = tf.buffer<Rank.R5>(convInfo.outShape, x.dtype as 'float32');\n\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    const wVals = this.readSync(filter.dataId) as TypedArray;\n    const yVals = y.values;\n\n    for (let b = 0; b < convInfo.batchSize; ++b) {\n      const xOffset1 = b * x.strides[0];\n      const yOffset1 = b * y.strides[0];\n      for (let yF = 0; yF < convInfo.outDepth; ++yF) {\n        const yOffset2 = yOffset1 + yF * y.strides[1];\n        const xFCorner = yF * convInfo.strideDepth - padFront;\n        for (let wF = 0; wF < filterDepth; wF++) {\n          const xF = xFCorner + wF * dilationDepth;\n          if (xF < 0 || xF >= convInfo.inDepth) {\n            continue;\n          }\n          const wOffset1 = wF * filter.strides[0];\n          const xOffset2 = xOffset1 + xF * x.strides[1];\n\n          for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n            const yOffset3 = yOffset2 + yR * y.strides[2];\n            const xRCorner = yR * convInfo.strideHeight - padTop;\n            for (let wR = 0; wR < filterHeight; wR++) {\n              const xR = xRCorner + wR * dilationHeight;\n              if (xR < 0 || xR >= convInfo.inHeight) {\n                continue;\n              }\n              const wOffset2 = wOffset1 + wR * filter.strides[1];\n              const xOffset3 = xOffset2 + xR * x.strides[2];\n              for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n                const yOffset4 = yOffset3 + yC * convInfo.outChannels;\n                const xCCorner = yC * convInfo.strideWidth - padLeft;\n                for (let wC = 0; wC < filterWidth; wC++) {\n                  const xC = xCCorner + wC * dilationWidth;\n                  if (xC < 0 || xC >= convInfo.inWidth) {\n                    continue;\n                  }\n                  const wOffset3 = wOffset2 + wC * filter.strides[2];\n                  const xOffset4 = xOffset3 + xC * convInfo.inChannels;\n                  let wOffset4 = wOffset3;\n                  for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                    const xVal = xVals[xOffset4 + d1];\n                    for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                      yVals[yOffset4 + d2] += xVal * wVals[wOffset4 + d2];\n                    }\n                    wOffset4 += convInfo.outChannels;\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    return y.toTensor();\n  }\n\n  conv2dDerInput(\n      dy: Tensor4D, filter: Tensor4D,\n      convInfo: backend_util.Conv2DInfo): Tensor4D {\n    assertNotComplex([dy, filter], 'conv2dDerInput');\n\n    const dx = tf.buffer<Rank.R4>(convInfo.inShape, 'float32');\n    const dxValues = dx.values;\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    const fltValues = this.readSync(filter.dataId) as TypedArray;\n    const [fltS0, fltS1, fltS2] = filter.strides;\n    const {\n      batchSize,\n      filterHeight,\n      filterWidth,\n      inChannels,\n      inHeight,\n      inWidth,\n      outChannels,\n      outHeight,\n      outWidth,\n      strideHeight,\n      strideWidth,\n      dataFormat\n    } = convInfo;\n    const topPad = filterHeight - 1 - convInfo.padInfo.top;\n    const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n\n    const isChannelsLast = dataFormat === 'channelsLast';\n    const xBatchStride = dx.strides[0];\n    const xRowStride = isChannelsLast ? dx.strides[1] : dx.strides[2];\n    const xColStride = isChannelsLast ? dx.strides[2] : 1;\n    const xChannelStride = isChannelsLast ? 1 : dx.strides[1];\n    const yBatchStride = dy.strides[0];\n    const yRowStride = isChannelsLast ? dy.strides[1] : dy.strides[2];\n    const yColStride = isChannelsLast ? dy.strides[2] : 1;\n    const yChannelStride = isChannelsLast ? 1 : dy.strides[1];\n\n    for (let b = 0; b < batchSize; ++b) {\n      for (let d1 = 0; d1 < inChannels; ++d1) {\n        for (let xR = 0; xR < inHeight; ++xR) {\n          const xRCorner = xR - topPad;\n          const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n          const yRMax =\n              Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n\n          for (let xC = 0; xC < inWidth; ++xC) {\n            const xCCorner = xC - leftPad;\n            const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n            const yCMax =\n                Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n            let dotProd = 0;\n            for (let yR = xRMin; yR < yRMax; ++yR) {\n              const wR = yR * strideHeight - xRCorner;\n\n              for (let yC = xCMin; yC < yCMax; ++yC) {\n                const wC = yC * strideWidth - xCCorner;\n                const dyOffset =\n                    yBatchStride * b + yRowStride * yR + yColStride * yC;\n                const fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                    fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;\n\n                for (let d2 = 0; d2 < outChannels; ++d2) {\n                  const pixel = dyValues[dyOffset + yChannelStride * d2];\n                  const weight = fltValues[fltOffset + d2];\n                  dotProd += pixel * weight;\n                }\n              }\n            }\n            const dxOffset = xBatchStride * b + xRowStride * xR +\n                xColStride * xC + xChannelStride * d1;\n            dxValues[dxOffset] = dotProd;\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  conv3dDerInput(\n      dy: Tensor5D, filter: Tensor5D,\n      convInfo: backend_util.Conv3DInfo): Tensor5D {\n    const dx = tf.buffer<Rank.R5>(convInfo.inShape, 'float32');\n    const dxValues = dx.values;\n    const [dxS0, dxS1, dxS2, dxS3] = dx.strides;\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    const [dyS0, dyS1, dyS2, dyS3] = dy.strides;\n    const fltValues = this.readSync(filter.dataId) as TypedArray;\n    const [fltS0, fltS1, fltS2, fltS3] = filter.strides;\n    const {\n      batchSize,\n      filterDepth,\n      filterHeight,\n      filterWidth,\n      inChannels,\n      inDepth,\n      inHeight,\n      inWidth,\n      outChannels,\n      outDepth,\n      outHeight,\n      outWidth,\n      strideDepth,\n      strideHeight,\n      strideWidth\n    } = convInfo;\n    const frontPad = filterDepth - 1 - convInfo.padInfo.front;\n    const topPad = filterHeight - 1 - convInfo.padInfo.top;\n    const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n\n    for (let b = 0; b < batchSize; ++b) {\n      for (let d1 = 0; d1 < inChannels; ++d1) {\n        // Frames of depth\n        for (let xF = 0; xF < inDepth; ++xF) {\n          const xFCorner = xF - frontPad;\n          const xFMin = Math.max(0, Math.ceil(xFCorner / strideDepth));\n          const yFMax =\n              Math.min(outDepth, (filterDepth + xFCorner) / strideDepth);\n\n          // Rows as per standard 2d matrix notation\n          for (let xR = 0; xR < inHeight; ++xR) {\n            const xRCorner = xR - topPad;\n            const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n            const yRMax =\n                Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n            // Columns as per standard 2d matrix notation\n            for (let xC = 0; xC < inWidth; ++xC) {\n              const xCCorner = xC - leftPad;\n              const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n              const yCMax =\n                  Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n              let dotProd = 0;\n              for (let yF = xFMin; yF < yFMax; ++yF) {\n                const wF = yF * strideDepth - xFCorner;\n\n                for (let yR = xRMin; yR < yRMax; ++yR) {\n                  const wR = yR * strideHeight - xRCorner;\n\n                  for (let yC = xCMin; yC < yCMax; ++yC) {\n                    const wC = yC * strideWidth - xCCorner;\n                    const dyOffset =\n                        dyS0 * b + dyS1 * yF + dyS2 * yR + dyS3 * yC;\n                    const fltOffset = fltS0 * (filterDepth - 1 - wF) +\n                        fltS1 * (filterHeight - 1 - wR) +\n                        fltS2 * (filterWidth - 1 - wC) + fltS3 * d1;\n\n                    for (let d2 = 0; d2 < outChannels; ++d2) {\n                      const pixel = dyValues[dyOffset + d2];\n                      const weight = fltValues[fltOffset + d2];\n                      dotProd += pixel * weight;\n                    }\n                  }\n                }\n              }\n              dxValues[dxS0 * b + dxS1 * xF + dxS2 * xR + dxS3 * xC + d1] =\n                  dotProd;\n            }\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  conv2dDerFilter(x: Tensor4D, dy: Tensor4D, convInfo: backend_util.Conv2DInfo):\n      Tensor4D {\n    assertNotComplex([x, dy], 'conv2dDerFilter');\n\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n    const dW = tf.buffer<Rank.R4>(convInfo.filterShape, 'float32');\n\n    const leftPad = convInfo.padInfo.left;\n    const topPad = convInfo.padInfo.top;\n    const xBuf = this.bufferSync(x);\n    const dyBuf = this.bufferSync(dy);\n    for (let wR = 0; wR < filterHeight; ++wR) {\n      const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n      const yRMax = Math.min(\n          convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n\n      for (let wC = 0; wC < filterWidth; ++wC) {\n        const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n        const yCMax = Math.min(\n            convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n\n        for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n          for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n            // Need to convolve.\n            let dotProd = 0;\n            for (let b = 0; b < convInfo.batchSize; ++b) {\n              for (let yR = yRMin; yR < yRMax; ++yR) {\n                const xR = wR + yR * strideHeight - topPad;\n                for (let yC = yCMin; yC < yCMax; ++yC) {\n                  const xC = wC + yC * strideWidth - leftPad;\n                  if (isChannelsLast) {\n                    dotProd +=\n                        xBuf.get(b, xR, xC, d1) * dyBuf.get(b, yR, yC, d2);\n                  } else {\n                    dotProd +=\n                        xBuf.get(b, d1, xR, xC) * dyBuf.get(b, d2, yR, yC);\n                  }\n                }\n              }\n            }\n            dW.set(dotProd, wR, wC, d1, d2);\n          }\n        }\n      }\n    }\n    return dW.toTensor();\n  }\n\n  conv3dDerFilter(x: Tensor5D, dy: Tensor5D, convInfo: backend_util.Conv3DInfo):\n      Tensor5D {\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterDepth = convInfo.filterDepth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n\n    const dw = tf.buffer<Rank.R5>(convInfo.filterShape, 'float32');\n    const dwValues = dw.values;\n    const [dwS0, dwS1, dwS2, dwS3] = dw.strides;\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    const [dyS0, dyS1, dyS2, dyS3] = dy.strides;\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const [xS0, xS1, xS2, xS3] = x.strides;\n\n    const frontPad = convInfo.padInfo.front;\n    const leftPad = convInfo.padInfo.left;\n    const topPad = convInfo.padInfo.top;\n\n    for (let wF = 0; wF < filterDepth; ++wF) {\n      const yFMin = Math.max(0, Math.ceil((frontPad - wF) / strideDepth));\n      const yFMax = Math.min(\n          convInfo.outDepth, (convInfo.inDepth + frontPad - wF) / strideDepth);\n      const wOffset1 = wF * dwS0;\n\n      for (let wR = 0; wR < filterHeight; ++wR) {\n        const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n        const yRMax = Math.min(\n            convInfo.outHeight,\n            (convInfo.inHeight + topPad - wR) / strideHeight);\n        const wOffset2 = wR * dwS1 + wOffset1;\n\n        for (let wC = 0; wC < filterWidth; ++wC) {\n          const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n          const yCMax = Math.min(\n              convInfo.outWidth,\n              (convInfo.inWidth + leftPad - wC) / strideWidth);\n          const wOffset3 = wC * dwS2 + wOffset2;\n\n          for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n            const wOffset4 = d1 * dwS3 + wOffset3;\n\n            for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n              let dotProd = 0;\n              for (let b = 0; b < convInfo.batchSize; ++b) {\n                const xOffset1 = b * xS0;\n                const yOffset1 = b * dyS0;\n\n                for (let yF = yFMin; yF < yFMax; ++yF) {\n                  const xF = wF + yF * strideDepth - frontPad;\n                  const xOffset2 = xF * xS1 + xOffset1;\n                  const yOffset2 = yF * dyS1 + yOffset1;\n\n                  for (let yR = yRMin; yR < yRMax; ++yR) {\n                    const xR = wR + yR * strideHeight - topPad;\n                    const xOffset3 = xR * xS2 + xOffset2;\n                    const yOffset3 = yR * dyS2 + yOffset2;\n\n                    for (let yC = yCMin; yC < yCMax; ++yC) {\n                      const xC = wC + yC * strideWidth - leftPad;\n                      const xOffset4 = xC * xS3 + xOffset3;\n                      const yOffset4 = yC * dyS3 + yOffset3;\n\n                      dotProd +=\n                          xValues[xOffset4 + d1] * dyValues[yOffset4 + d2];\n                    }\n                  }\n                }\n              }\n              dwValues[wOffset4 + d2] = dotProd;\n            }\n          }\n        }\n      }\n    }\n    return dw.toTensor();\n  }\n\n  fusedDepthwiseConv2D(\n      {input, filter, convInfo, bias, activation, preluActivationWeights}:\n          backend_util.FusedConv2DConfig): Tensor4D {\n    let result = this.depthwiseConv2D(input, filter, convInfo);\n\n    if (bias) {\n      // TODO(lina128): Use add directly once fusedDepthwiseConv2D is\n      // modularized.\n      result = tf.add(result, bias);\n    }\n    if (activation) {\n      result =\n          mapActivation(this, result, activation, preluActivationWeights) as\n          Tensor4D;\n    }\n    return result;\n  }\n\n  depthwiseConv2D(\n      x: Tensor4D, filter: Tensor4D,\n      convInfo: backend_util.Conv2DInfo): Tensor4D {\n    assertNotComplex([x, filter], 'depthwiseConv2D');\n\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const padLeft = convInfo.padInfo.left;\n    const padTop = convInfo.padInfo.top;\n    const chMul = convInfo.outChannels / convInfo.inChannels;\n    const y = tf.buffer(convInfo.outShape, x.dtype as 'float32');\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    const wVals = this.readSync(filter.dataId) as TypedArray;\n    const yVals = y.values;\n\n    for (let b = 0; b < convInfo.batchSize; ++b) {\n      const xOffset1 = b * x.strides[0];\n      const yOffset1 = b * y.strides[0];\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const yOffset2 = yOffset1 + yR * y.strides[1];\n        const xRCorner = yR * convInfo.strideHeight - padLeft;\n        for (let wR = 0; wR < filterHeight; ++wR) {\n          const xR = xRCorner + wR * dilationHeight;\n          if (xR < 0 || xR >= convInfo.inHeight) {\n            continue;\n          }\n          const wOffset1 = wR * filter.strides[0];\n          const xOffset2 = xOffset1 + xR * x.strides[1];\n          for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n            const yOffset3 = yOffset2 + yC * y.strides[2];\n            const xCCorner = yC * convInfo.strideWidth - padTop;\n            for (let wC = 0; wC < filterWidth; ++wC) {\n              const xC = xCCorner + wC * dilationWidth;\n              if (xC < 0 || xC >= convInfo.inWidth) {\n                continue;\n              }\n              const wOffset2 = wOffset1 + wC * filter.strides[1];\n              const xOffset3 = xOffset2 + xC * convInfo.inChannels;\n              let yOffset4 = yOffset3;\n              let wOffset3 = wOffset2;\n              for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                const xVal = xVals[xOffset3 + d1];\n                for (let q = 0; q < chMul; ++q) {\n                  yVals[yOffset4 + q] += xVal * wVals[wOffset3 + q];\n                }\n                yOffset4 += chMul;\n                wOffset3 += chMul;\n              }\n            }\n          }\n        }\n      }\n    }\n\n    return y.toTensor() as Tensor4D;\n  }\n\n  depthwiseConv2DDerInput(\n      dy: Tensor4D, filter: Tensor4D,\n      convInfo: backend_util.Conv2DInfo): Tensor4D {\n    assertNotComplex([dy, filter], 'depthwiseConv2DDerInput');\n\n    const dx = tf.buffer<Rank.R4>(convInfo.inShape, 'float32');\n    const dxValues = dx.values;\n    const [dxS0, dxS1, dxS2] = dx.strides;\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    const [dyS0, dyS1, dyS2] = dy.strides;\n    const fltValues = this.readSync(filter.dataId) as TypedArray;\n    const [fltS0, fltS1, fltS2] = filter.strides;\n    const {\n      batchSize,\n      filterHeight,\n      filterWidth,\n      inChannels,\n      inHeight,\n      inWidth,\n      outChannels,\n      outHeight,\n      outWidth,\n      strideHeight,\n      strideWidth\n    } = convInfo;\n    const topPad = filterHeight - 1 - convInfo.padInfo.top;\n    const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n    const chMul = outChannels / inChannels;\n\n    for (let b = 0; b < batchSize; ++b) {\n      for (let d1 = 0; d1 < inChannels; ++d1) {\n        for (let xR = 0; xR < inHeight; ++xR) {\n          const xRCorner = xR - topPad;\n          const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n          const yRMax =\n              Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n\n          for (let xC = 0; xC < inWidth; ++xC) {\n            const xCCorner = xC - leftPad;\n            const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n            const yCMax =\n                Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n            let dotProd = 0;\n            for (let yR = xRMin; yR < yRMax; ++yR) {\n              const wR = yR * strideHeight - xRCorner;\n\n              for (let yC = xCMin; yC < yCMax; ++yC) {\n                const wC = yC * strideWidth - xCCorner;\n                const dyOffset = dyS0 * b + dyS1 * yR + dyS2 * yC;\n                const fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                    fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;\n\n                for (let dm = 0; dm < chMul; ++dm) {\n                  const d2 = d1 * chMul + dm;\n                  const pixel = dyValues[dyOffset + d2];\n                  const weight = fltValues[fltOffset + dm];\n                  dotProd += pixel * weight;\n                }\n              }\n            }\n            dxValues[dxS0 * b + dxS1 * xR + dxS2 * xC + d1] = dotProd;\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  depthwiseConv2DDerFilter(\n      x: Tensor4D, dy: Tensor4D, convInfo: backend_util.Conv2DInfo): Tensor4D {\n    assertNotComplex([x, dy], 'depthwiseConv2DDerFilter');\n\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dW = tf.buffer<Rank.R4>(convInfo.filterShape, 'float32');\n\n    const leftPad = convInfo.padInfo.left;\n    const topPad = convInfo.padInfo.top;\n    const chMul = convInfo.outChannels / convInfo.inChannels;\n\n    const xBuf = this.bufferSync(x);\n    const dyBuf = this.bufferSync(dy);\n    for (let wR = 0; wR < filterHeight; ++wR) {\n      const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n      const yRMax = Math.min(\n          convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n\n      for (let wC = 0; wC < filterWidth; ++wC) {\n        const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n        const yCMax = Math.min(\n            convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n\n        for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n          const d1 = Math.trunc(d2 / chMul);\n          const dm = d2 % chMul;\n\n          let dotProd = 0;\n          for (let b = 0; b < convInfo.batchSize; ++b) {\n            for (let yR = yRMin; yR < yRMax; ++yR) {\n              const xR = wR + yR * strideHeight - topPad;\n              for (let yC = yCMin; yC < yCMax; ++yC) {\n                const xC = wC + yC * strideWidth - leftPad;\n                dotProd += xBuf.get(b, xR, xC, d1) * dyBuf.get(b, yR, yC, d2);\n              }\n            }\n          }\n          dW.set(dotProd, wR, wC, d1, dm);\n        }\n      }\n    }\n    return dW.toTensor();\n  }\n\n  tile<T extends Tensor>(x: T, reps: number[]): T {\n    assertNotComplex(x, 'tile');\n    return tile(this.bufferSync(x), reps) as T;\n  }\n\n  gather<T extends Tensor>(x: T, indices: Tensor1D, axis: number): T {\n    assertNotComplex([x, indices], 'gather');\n\n    const newShape: number[] = x.shape.slice();\n    const indicesValues = this.readSync(indices.dataId) as TypedArray;\n    newShape[axis] = indicesValues.length;\n    const result = tf.buffer(newShape, x.dtype);\n    const xBuf = this.bufferSync(x);\n\n    for (let i = 0; i < result.size; ++i) {\n      const newLoc = result.indexToLoc(i);\n\n      const originalLoc: number[] = newLoc.slice();\n      originalLoc[axis] = indicesValues[newLoc[axis]];\n\n      const originalIndex = xBuf.locToIndex(originalLoc);\n      result.values[i] = xBuf.values[originalIndex];\n    }\n    return result.toTensor() as T;\n  }\n\n  batchToSpaceND<T extends Tensor>(\n      x: T, blockShape: number[], crops: number[][]): T {\n    assertNotComplex([x], 'batchToSpaceND');\n\n    const prod = blockShape.reduce((a, b) => a * b);\n\n    const reshaped = backend_util.getReshaped(x.shape, blockShape, prod);\n    const permuted =\n        backend_util.getPermuted(reshaped.length, blockShape.length);\n    const reshapedPermuted =\n        backend_util.getReshapedPermuted(x.shape, blockShape, prod);\n    const sliceBeginCoords =\n        backend_util.getSliceBeginCoords(crops, blockShape.length);\n    const sliceSize =\n        backend_util.getSliceSize(reshapedPermuted, crops, blockShape.length);\n\n    return tf.transpose(x.reshape(reshaped), permuted)\n               .reshape(reshapedPermuted)\n               .slice(sliceBeginCoords, sliceSize) as T;\n  }\n\n  private pool3d(\n      x: Tensor5D, convInfo: backend_util.Conv3DInfo,\n      poolType: 'max'|'avg'): Tensor5D {\n    assertNotComplex(x, 'pool3d');\n\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padFront = convInfo.padInfo.front;\n    const padTop = convInfo.padInfo.top;\n    const padLeft = convInfo.padInfo.left;\n\n    const initialValue =\n        (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n                              Number.POSITIVE_INFINITY);\n\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const output = tf.buffer(convInfo.outShape, x.dtype);\n    const outputVals = output.values;\n\n    const outputBatchStrides = convInfo.outShape[1] * convInfo.outShape[2] *\n        convInfo.outShape[3] * convInfo.outShape[4];\n    const outputDepthStrides =\n        convInfo.outShape[2] * convInfo.outShape[3] * convInfo.outShape[4];\n    const outputRowStrides = convInfo.outShape[3] * convInfo.outShape[4];\n    const outputColStrides = convInfo.outShape[4];\n\n    for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n      const outputBatchOffset = batch * outputBatchStrides;\n      const inputBatchOffset = batch * x.strides[0];\n      for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n        for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {\n          const xDepthCorner = yDepth * strideDepth - padFront;\n          let xDepthMin = xDepthCorner;\n          while (xDepthMin < 0) {\n            xDepthMin += dilationDepth;\n          }\n          const xDepthMax =\n              Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);\n          const outputDepthOffset =\n              outputBatchOffset + yDepth * outputDepthStrides;\n          for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {\n            const xRowCorner = yRow * strideHeight - padTop;\n            let xRowMin = xRowCorner;\n            while (xRowMin < 0) {\n              xRowMin += dilationHeight;\n            }\n            const xRowMax =\n                Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);\n            const outputRowOffset = outputDepthOffset + yRow * outputRowStrides;\n            for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {\n              const xColCorner = yCol * strideWidth - padLeft;\n              let xColMin = xColCorner;\n              while (xColMin < 0) {\n                xColMin += dilationWidth;\n              }\n              const xColMax =\n                  Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);\n              // Shader code begins\n              const outputColOffset = outputRowOffset + yCol * outputColStrides;\n              let minMaxValue = initialValue;\n              let avgValue = 0;\n              let count = 0;\n              for (let xDepth = xDepthMin; xDepth < xDepthMax;\n                   xDepth += dilationDepth) {\n                const xDepthOffset = inputBatchOffset + xDepth * x.strides[1];\n                for (let xRow = xRowMin; xRow < xRowMax;\n                     xRow += dilationHeight) {\n                  const xRowOffset = xDepthOffset + xRow * x.strides[2];\n                  for (let xCol = xColMin; xCol < xColMax;\n                       xCol += dilationWidth) {\n                    const xColOffset = xRowOffset + xCol * x.strides[3];\n                    const pixel = xValues[xColOffset + channel];\n                    if ((poolType === 'max' && pixel > minMaxValue)) {\n                      minMaxValue = pixel;\n                    } else if (poolType === 'avg') {\n                      avgValue += pixel;\n                      count++;\n                    }\n                    if (isNaN(minMaxValue)) {\n                      break;\n                    }\n                  }\n                  if (isNaN(minMaxValue)) {\n                    break;\n                  }\n                }\n                if (isNaN(minMaxValue)) {\n                  break;\n                }\n              }\n              const outputOffset = outputColOffset + channel;\n              outputVals[outputOffset] =\n                  poolType === 'avg' ? avgValue / count : minMaxValue;\n            }\n          }\n        }\n      }\n    }\n    return output.toTensor() as Tensor5D;\n  }\n\n  avgPool3d(x: Tensor5D, convInfo: backend_util.Conv3DInfo): Tensor5D {\n    assertNotComplex(x, 'avgPool3d');\n\n    return this.pool3d(x, convInfo, 'avg').toFloat();\n  }\n\n  avgPool3dBackprop(\n      dy: Tensor5D, x: Tensor5D, convInfo: backend_util.Conv3DInfo): Tensor5D {\n    assertNotComplex([dy, x], 'avgPool3dBackprop');\n\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterDepth = convInfo.filterDepth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;\n    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n    const dx = tf.buffer<Rank.R5>(x.shape, 'float32');\n\n    const avgMultiplier = 1 / (filterDepth * filterHeight * filterWidth);\n\n    const dyBuf = this.bufferSync(dy);\n\n    for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n      for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n        for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {\n          for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {\n            for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {\n              // Shader code begins.\n              const dyDepthCorner = dxDepth - padFront;\n              const dyRowCorner = dxRow - padTop;\n              const dyColCorner = dxCol - padLeft;\n              let dotProd = 0;\n              for (let wDepth = 0; wDepth < effectiveFilterDepth;\n                   wDepth += dilationDepth) {\n                const dyDepth = (dyDepthCorner + wDepth) / strideDepth;\n                if (dyDepth < 0 || dyDepth >= convInfo.outDepth ||\n                    Math.floor(dyDepth) !== dyDepth) {\n                  continue;\n                }\n                for (let wRow = 0; wRow < effectiveFilterHeight;\n                     wRow += dilationHeight) {\n                  const dyRow = (dyRowCorner + wRow) / strideHeight;\n                  if (dyRow < 0 || dyRow >= convInfo.outHeight ||\n                      Math.floor(dyRow) !== dyRow) {\n                    continue;\n                  }\n                  for (let wCol = 0; wCol < effectiveFilterWidth;\n                       wCol += dilationWidth) {\n                    const dyCol = (dyColCorner + wCol) / strideWidth;\n                    if (dyCol < 0 || dyCol >= convInfo.outWidth ||\n                        Math.floor(dyCol) !== dyCol) {\n                      continue;\n                    }\n\n                    const pixel =\n                        dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                    dotProd += pixel;\n                  }\n                }\n              }\n              dx.set(\n                  dotProd * avgMultiplier, batch, dxDepth, dxRow, dxCol,\n                  channel);\n            }\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  maxPool3d(x: Tensor5D, convInfo: backend_util.Conv3DInfo): Tensor5D {\n    assertNotComplex(x, 'maxPool3d');\n\n    return this.pool3d(x, convInfo, 'max').toFloat();\n  }\n\n  private maxPool3dPositions(x: Tensor5D, convInfo: backend_util.Conv3DInfo):\n      Tensor5D {\n    const maxPositions = tf.buffer(convInfo.outShape, 'int32');\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padFront = convInfo.padInfo.front;\n    const padTop = convInfo.padInfo.top;\n    const padLeft = convInfo.padInfo.left;\n\n    const xBuf = this.bufferSync(x);\n    for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n      for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n        for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {\n          const xDepthCorner = yDepth * strideDepth - padFront;\n          let xDepthMin = xDepthCorner;\n          while (xDepthMin < 0) {\n            xDepthMin += dilationDepth;\n          }\n          const xDepthMax =\n              Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);\n          for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {\n            const xRowCorner = yRow * strideHeight - padTop;\n            let xRowMin = xRowCorner;\n            while (xRowMin < 0) {\n              xRowMin += dilationHeight;\n            }\n            const xRowMax =\n                Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);\n            for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {\n              const xColCorner = yCol * strideWidth - padLeft;\n              let xColMin = xColCorner;\n              while (xColMin < 0) {\n                xColMin += dilationWidth;\n              }\n              const xColMax =\n                  Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);\n\n              // Shader code begins\n              let maxValue = Number.NEGATIVE_INFINITY;\n              let maxPosition = -1;\n\n              for (let xDepth = xDepthMin; xDepth < xDepthMax;\n                   xDepth += dilationDepth) {\n                const wDepth = xDepth - xDepthCorner;\n                for (let xRow = xRowMin; xRow < xRowMax;\n                     xRow += dilationHeight) {\n                  const wRow = xRow - xRowCorner;\n                  for (let xCol = xColMin; xCol < xColMax;\n                       xCol += dilationWidth) {\n                    const wCol = xCol - xColCorner;\n                    const pixel = xBuf.get(batch, xDepth, xRow, xCol, channel);\n                    if (pixel >= maxValue) {\n                      maxValue = pixel;\n                      maxPosition = wDepth * effectiveFilterHeight *\n                              effectiveFilterWidth +\n                          wRow * effectiveFilterHeight + wCol;\n                    }\n                  }\n                }\n              }\n\n              maxPositions.set(maxPosition, batch, yDepth, yRow, yCol, channel);\n            }\n          }\n        }\n      }\n    }\n    return maxPositions.toTensor() as Tensor5D;\n  }\n\n  maxPool3dBackprop(\n      dy: Tensor5D, x: Tensor5D, y: Tensor5D,\n      convInfo: backend_util.Conv3DInfo): Tensor5D {\n    assertNotComplex([x, y], 'maxPool3dBackprop');\n\n    const maxPositions = this.maxPool3dPositions(x, convInfo);\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;\n    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n    const dx = tf.buffer<Rank.R5>(x.shape, 'float32');\n\n    const maxPosBuf = this.bufferSync(maxPositions);\n    const dyBuf = this.bufferSync(dy);\n\n    for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n      for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n        for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {\n          for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {\n            for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {\n              // Shader code begins\n              const dyDepthCorner = dxDepth - padFront;\n              const dyRowCorner = dxRow - padTop;\n              const dyColCorner = dxCol - padLeft;\n              let dotProd = 0;\n              for (let wDepth = 0; wDepth < effectiveFilterDepth;\n                   wDepth += dilationDepth) {\n                const dyDepth = (dyDepthCorner + wDepth) / strideDepth;\n                if (dyDepth < 0 || dyDepth >= convInfo.outDepth ||\n                    Math.floor(dyDepth) !== dyDepth) {\n                  continue;\n                }\n                for (let wRow = 0; wRow < effectiveFilterHeight;\n                     wRow += dilationHeight) {\n                  const dyRow = (dyRowCorner + wRow) / strideHeight;\n                  if (dyRow < 0 || dyRow >= convInfo.outHeight ||\n                      Math.floor(dyRow) !== dyRow) {\n                    continue;\n                  }\n                  for (let wCol = 0; wCol < effectiveFilterWidth;\n                       wCol += dilationWidth) {\n                    const dyCol = (dyColCorner + wCol) / strideWidth;\n                    if (dyCol < 0 || dyCol >= convInfo.outWidth ||\n                        Math.floor(dyCol) !== dyCol) {\n                      continue;\n                    }\n\n                    const maxPos = effectiveFilterDepth *\n                            effectiveFilterHeight * effectiveFilterWidth -\n                        1 -\n                        maxPosBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                    const curPos =\n                        wDepth * effectiveFilterHeight * effectiveFilterWidth +\n                        wRow * effectiveFilterWidth + wCol;\n\n                    const mask = maxPos === curPos ? 1 : 0;\n                    if (mask === 0) {\n                      continue;\n                    }\n\n                    const pixel =\n                        dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                    dotProd += pixel * mask;\n                  }\n                }\n              }\n              dx.set(dotProd, batch, dxDepth, dxRow, dxCol, channel);\n            }\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  resizeBilinear(\n      x: Tensor4D, newHeight: number, newWidth: number,\n      alignCorners: boolean): Tensor4D {\n    assertNotComplex(x, 'resizeBilinear');\n\n    const [batch, oldHeight, oldWidth, numChannels] = x.shape;\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const result = new Float32Array(\n        util.sizeFromShape([batch, newHeight, newWidth, numChannels]));\n\n    const effectiveInputSize: [number, number] = [\n      (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n      (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n    ];\n\n    const effectiveOutputSize: [number, number] = [\n      (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n      (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n    ];\n    let outputIdx = 0;\n    const effectiveRowSizeRatio =\n        effectiveInputSize[0] / effectiveOutputSize[0];\n    const effectiveColSizeRatio =\n        effectiveInputSize[1] / effectiveOutputSize[1];\n    for (let b = 0; b < batch; b++) {\n      for (let r = 0; r < newHeight; r++) {\n        const sourceFracRow = effectiveRowSizeRatio * r;\n        const sourceRowFloor = Math.floor(sourceFracRow);\n        const rowFrac = sourceFracRow - sourceRowFloor;\n        const sourceRowCeil = Math.min(oldHeight - 1, Math.ceil(sourceFracRow));\n        const topRowOffset = b * x.strides[0] + sourceRowFloor * x.strides[1];\n        const botRowOffset = b * x.strides[0] + sourceRowCeil * x.strides[1];\n        for (let c = 0; c < newWidth; c++) {\n          const sourceFracCol = effectiveColSizeRatio * c;\n          const sourceColFloor = Math.floor(sourceFracCol);\n          const colFrac = sourceFracCol - sourceColFloor;\n          const sourceColCeil =\n              Math.min(oldWidth - 1, Math.ceil(sourceFracCol));\n          const topLeftOffest = topRowOffset + sourceColFloor * x.strides[2];\n          const botLeftOffset = botRowOffset + sourceColFloor * x.strides[2];\n          const topRightOffset = topRowOffset + sourceColCeil * x.strides[2];\n          const botRightOffest = botRowOffset + sourceColCeil * x.strides[2];\n          for (let d = 0; d < numChannels; d++) {\n            // Begin shader.\n\n            // Compute the fractional index of the source.\n            const topLeft = xValues[topLeftOffest + d];\n            const bottomLeft = xValues[botLeftOffset + d];\n            const topRight = xValues[topRightOffset + d];\n            const bottomRight = xValues[botRightOffest + d];\n\n            const top = topLeft + (topRight - topLeft) * colFrac;\n            const bottom = bottomLeft + (bottomRight - bottomLeft) * colFrac;\n            const newValue = top + (bottom - top) * rowFrac;\n\n            result[outputIdx++] = newValue;\n          }\n        }\n      }\n    }\n    return tf.tensor(result, [batch, newHeight, newWidth, numChannels]);\n  }\n\n  resizeBilinearBackprop(dy: Tensor4D, x: Tensor4D, alignCorners: boolean) {\n    assertNotComplex([dy, x], 'resizeBilinearBackprop');\n\n    const [batch, xHeight, xWidth, depth] = x.shape;\n    const [, yHeight, yWidth] = dy.shape;\n\n    const output = new Float32Array(batch * xHeight * xWidth * depth);\n\n    // In the backwards pass, we want to find the pixels that were generated\n    // for each pixel in the input image the forward pass and add the\n    // corresponding coefficient from dy to the gradient (with some\n    // interpolation).\n\n    const effectiveXSize: [number, number] = [\n      (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n      (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n    ];\n\n    const effectiveYSize: [number, number] = [\n      (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n      (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n    ];\n\n    const heightScale = effectiveXSize[0] / effectiveYSize[0];\n    const widthScale = effectiveXSize[1] / effectiveYSize[1];\n\n    // Reference implementation\n    // tslint:disable-next-line:max-line-length\n    // https://github.com/tensorflow/tensorflow/blob/3039375c86a5bbc9610c7725dcaa95d635f87ba2/tensorflow/core/kernels/resize_bilinear_op.cc#L275\n\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    let offset = 0;\n    for (let b = 0; b < batch; b++) {\n      const bOffset = b * x.strides[0];\n      for (let r = 0; r < yHeight; r++) {\n        const dxR = r * heightScale;\n        const topDxRIndex = Math.floor(dxR);\n        const bottomDxRIndex = Math.min(Math.ceil(dxR), xHeight - 1);\n\n        const topDxROffset = bOffset + topDxRIndex * x.strides[1];\n        const bottomDxROffset = bOffset + bottomDxRIndex * x.strides[1];\n\n        const dxRLerp = dxR - topDxRIndex;\n        const inverseDxRLerp = 1.0 - dxRLerp;\n        for (let c = 0; c < yWidth; c++) {\n          const dxC = c * widthScale;\n          const leftDxCIndex = Math.floor(dxC);\n          const rightDxCIndex = Math.min(Math.ceil(dxC), xWidth - 1);\n          const dxCLerp = dxC - leftDxCIndex;\n          const inverseDxCLerp = 1.0 - dxCLerp;\n\n          const topLeftRCOffset = topDxROffset + leftDxCIndex * x.strides[2];\n          const topRightRCOffset = topDxROffset + rightDxCIndex * x.strides[2];\n          const bottomLeftRCOffset =\n              bottomDxROffset + leftDxCIndex * x.strides[2];\n          const bottomRightRCOffset =\n              bottomDxROffset + rightDxCIndex * x.strides[2];\n\n          const inverseDxRLerpTimesInverseDxCLerp =\n              inverseDxRLerp * inverseDxCLerp;\n          const inverseDxRLerpTimesDxCLerp = inverseDxRLerp * dxCLerp;\n          const dxRLerpTimesInverseDxCLerp = dxRLerp * inverseDxCLerp;\n          const dxRLerpTimesDxCLerp = dxRLerp * dxCLerp;\n          for (let d = 0; d < depth; d++) {\n            const dyVal = dyValues[offset++];\n            output[topLeftRCOffset + d] +=\n                dyVal * inverseDxRLerpTimesInverseDxCLerp;\n            output[topRightRCOffset + d] += dyVal * inverseDxRLerpTimesDxCLerp;\n            output[bottomLeftRCOffset + d] +=\n                dyVal * dxRLerpTimesInverseDxCLerp;\n            output[bottomRightRCOffset + d] += dyVal * dxRLerpTimesDxCLerp;\n          }\n        }\n      }\n    }\n    return tf.tensor4d(output, [batch, xWidth, xHeight, depth], x.dtype);\n  }\n\n  resizeNearestNeighbor(\n      x: Tensor4D, newHeight: number, newWidth: number,\n      alignCorners: boolean): Tensor4D {\n    assertNotComplex(x, 'resizeNearestNeighbor');\n\n    const [batch, oldHeight, oldWidth, numChannels] = x.shape;\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const output = new Float32Array(batch * newHeight * newWidth * numChannels);\n\n    const effectiveInputSize: [number, number] = [\n      (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n      (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n    ];\n\n    const effectiveOutputSize: [number, number] = [\n      (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n      (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n    ];\n\n    const effectiveRowSizeRatio =\n        effectiveInputSize[0] / effectiveOutputSize[0];\n    const effectiveColSizeRatio =\n        effectiveInputSize[1] / effectiveOutputSize[1];\n\n    let outputOffset = 0;\n    for (let b = 0; b < batch; b++) {\n      const batchOffset = b * x.strides[0];\n      for (let r = 0; r < newHeight; r++) {\n        const sourceFracRow = effectiveRowSizeRatio * r;\n        const sourceNearestRow = Math.min(\n            oldHeight - 1,\n            alignCorners ? Math.round(sourceFracRow) :\n                           Math.floor(sourceFracRow));\n        const rowOffset = batchOffset + sourceNearestRow * x.strides[1];\n        for (let c = 0; c < newWidth; c++) {\n          const sourceFracCol = effectiveColSizeRatio * c;\n          const sourceNearestCol = Math.min(\n              oldWidth - 1,\n              alignCorners ? Math.round(sourceFracCol) :\n                             Math.floor(sourceFracCol));\n          const colOffset = rowOffset + sourceNearestCol * x.strides[2];\n          for (let d = 0; d < numChannels; d++) {\n            // Begin shader.\n            // Compute the fractional index of the source.\n            const newVal = xValues[colOffset + d];\n            output[outputOffset++] = newVal;\n          }\n        }\n      }\n    }\n    return tf.tensor(\n        output, [batch, newHeight, newWidth, numChannels], x.dtype);\n  }\n\n  resizeNearestNeighborBackprop(\n      dy: Tensor4D, x: Tensor4D, alignCorners: boolean) {\n    assertNotComplex([dy, x], 'resizeNearestNeighborBackprop');\n\n    const [batch, xHeight, xWidth, depth] = x.shape;\n    const [, yHeight, yWidth] = dy.shape;\n\n    const output = new Float32Array(batch * xHeight * xWidth * depth);\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n\n    // In the backwards pass, we want to find the pixels that were generated\n    // for each pixel in the input image the forward pass\n\n    const effectiveXSize: [number, number] = [\n      (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n      (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n    ];\n\n    const effectiveYSize: [number, number] = [\n      (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n      (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n    ];\n\n    const heightScale = effectiveXSize[0] / effectiveYSize[0];\n    const widthScale = effectiveXSize[1] / effectiveYSize[1];\n\n    const invHeightScale = 1 / heightScale;\n    const invWidthScale = 1 / widthScale;\n\n    // This defines the size of the window of values around a particular\n    // index in dy that we want to search for contributions to dx.\n    const winHeight = (Math.ceil(invHeightScale) * 2) + 2;\n    const winWidth = (Math.ceil(invWidthScale) * 2) + 2;\n\n    // Loop over the output space.\n    for (let b = 0; b < batch; b++) {\n      const batchOffset = b * x.strides[0];\n      for (let r = 0; r < xHeight; r++) {\n        const rowOffset = batchOffset + r * x.strides[1];\n\n        // Compute bounds for where in dy we will look\n        const startRLerp = Math.floor(r * invHeightScale);\n        const startDyR = Math.floor(startRLerp - (winHeight / 2));\n        for (let c = 0; c < xWidth; c++) {\n          const colOffset = rowOffset + c * x.strides[2];\n\n          // Compute bounds for where in dy we will look\n          const startCLerp = Math.floor(c * invWidthScale);\n          const startDyC = Math.floor(startCLerp - (winWidth / 2));\n\n          for (let d = 0; d < depth; d++) {\n            let accum = 0;\n            // loop over dy\n\n            for (let dyRIndex = 0; dyRIndex < winHeight; dyRIndex++) {\n              const dyR = dyRIndex + startDyR;\n              // Guard against the window exceeding the bounds of dy\n              if (dyR < 0 || dyR >= yHeight) {\n                continue;\n              }\n\n              const dyROffset = batchOffset + dyR * dy.strides[1];\n              const sourceFracRow = dyR * heightScale;\n              const sourceNearestRow = Math.min(\n                  xHeight - 1,\n                  alignCorners ? Math.round(sourceFracRow) :\n                                 Math.floor(sourceFracRow));\n              if (r !== sourceNearestRow) {\n                continue;\n              }\n              for (let dyCIndex = 0; dyCIndex < winWidth; dyCIndex++) {\n                const dyC = dyCIndex + startDyC;\n                // Guard against the window exceeding the bounds of dy\n                if (dyC < 0 || dyC >= yWidth) {\n                  continue;\n                }\n\n                const dyCOffset = dyROffset + dyC * dy.strides[2];\n                const sourceFracCol = dyC * widthScale;\n                const sourceNearestCol = Math.min(\n                    xWidth - 1,\n                    alignCorners ? Math.round(sourceFracCol) :\n                                   Math.floor(sourceFracCol));\n\n                if (c === sourceNearestCol) {\n                  accum += dyValues[dyCOffset + d];\n                }\n              }\n            }\n            output[colOffset + d] = accum;\n          }\n        }\n      }\n    }\n    return tf.tensor4d(output, x.shape, x.dtype);\n  }\n\n  localResponseNormalization4D(\n      x: Tensor4D, depthRadius: number, bias: number, alpha: number,\n      beta: number): Tensor4D {\n    assertNotComplex(x, 'localResponseNormalization4D');\n\n    const channels = x.shape[3];\n    const maxD = channels - 1;\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const size = x.size;\n    const result = new Float32Array(size);\n\n    function sumAcrossChannels(offset: number) {\n      const currentChannel = offset % channels;\n      let beginSumOffset =\n          offset - currentChannel + Math.max(0, currentChannel - depthRadius);\n      const endSumOffset = offset - currentChannel +\n          Math.min(currentChannel + depthRadius, maxD);\n\n      let sum = 0.0;\n      for (; beginSumOffset <= endSumOffset; beginSumOffset++) {\n        const z = xValues[beginSumOffset];\n        sum += z * z;\n      }\n      return sum;\n    }\n\n    for (let offset = 0; offset < size; offset++) {\n      const sum = sumAcrossChannels(offset);\n      const val = xValues[offset] * Math.pow(bias + alpha * sum, -beta);\n      result[offset] = val;\n    }\n\n    return tf.tensor4d(result, x.shape);\n  }\n\n  LRNGrad(\n      dy: Tensor4D, inputImage: Tensor4D, outputImage: Tensor4D,\n      depthRadius: number, bias: number, alpha: number,\n      beta: number): Tensor4D {\n    assertNotComplex(dy, 'LRNGrad');\n    const channels = dy.shape[3];\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    const inputImageValues = this.readSync(inputImage.dataId) as TypedArray;\n    const outputImageValues = this.readSync(outputImage.dataId) as TypedArray;\n    const result = new Float32Array(dy.size);\n    const size = dy.size;\n\n    for (let offset = 0; offset < size; offset++) {\n      const currentChannel = offset % channels;\n      const depthBegin =\n          (offset - currentChannel) + Math.max(0, currentChannel - depthRadius);\n      const depthEnd = (offset - currentChannel) +\n          Math.min(channels, currentChannel + depthRadius + 1);\n\n      let norm = 0;\n      for (let k = depthBegin; k < depthEnd; k++) {\n        norm += Math.pow(inputImageValues[k], 2);\n      }\n      norm = alpha * norm + bias;\n\n      for (let k = depthBegin; k < depthEnd; k++) {\n        let dyi = -2 * alpha * beta * inputImageValues[k] *\n            outputImageValues[offset] / norm;\n        if (offset === k) {\n          dyi += Math.pow(norm, -beta);\n        }\n        dyi *= dyValues[offset];\n        result[k] += dyi;\n      }\n    }\n    return tf.tensor4d(result, dy.shape);\n  }\n\n  multinomial(\n      logits: Tensor2D, normalized: boolean, numSamples: number,\n      seed: number): Tensor2D {\n    assertNotComplex(logits, 'multinomial');\n\n    const probabilities = normalized ? logits : tf.softmax(logits);\n    const batchSize = probabilities.shape[0];\n    const numEvents = probabilities.shape[1];\n    const res = tf.zeros<Rank.R2>([batchSize, numSamples], 'int32');\n    const resVals = this.readSync(res.dataId) as TypedArray;\n    const probVals = this.readSync(probabilities.dataId) as TypedArray;\n\n    for (let b = 0; b < batchSize; ++b) {\n      const offset = b * numEvents;\n      // The cdf won't include the last event. It will be implicit if no other\n      // event happened.\n      const cdf = new Float32Array(numEvents - 1);\n      cdf[0] = probVals[offset];\n      for (let event = 1; event < cdf.length; ++event) {\n        cdf[event] = cdf[event - 1] + probVals[offset + event];\n      }\n\n      const random = seedrandom.alea(seed.toString());\n      const outOffset = b * numSamples;\n      for (let sampleId = 0; sampleId < numSamples; ++sampleId) {\n        const r = random();\n\n        // Assume last event happened by default.\n        resVals[outOffset + sampleId] = cdf.length;\n\n        for (let event = 0; event < cdf.length; event++) {\n          if (r < cdf[event]) {\n            resVals[outOffset + sampleId] = event;\n            break;\n          }\n        }\n      }\n    }\n    return res;\n  }\n\n  oneHot(indices: Tensor1D, depth: number, onValue: number, offValue: number):\n      Tensor2D {\n    assertNotComplex(indices, 'oneHot');\n\n    const res = new Float32Array(indices.size * depth);\n    res.fill(offValue);\n    const indicesVal = this.readSync(indices.dataId) as TypedArray;\n\n    for (let event = 0; event < indices.size; ++event) {\n      if (indicesVal[event] >= 0 && indicesVal[event] < depth) {\n        res[event * depth + indicesVal[event]] = onValue;\n      }\n    }\n    return tf.tensor2d(res, [indices.size, depth], 'int32');\n  }\n\n  nonMaxSuppression(\n      boxes: Tensor2D, scores: Tensor1D, maxOutputSize: number,\n      iouThreshold: number, scoreThreshold: number): Tensor1D {\n    assertNotComplex(boxes, 'nonMaxSuppression');\n\n    const boxesVals = this.readSync(boxes.dataId) as TypedArray;\n    const scoresVals = this.readSync(scores.dataId) as TypedArray;\n    return nonMaxSuppressionV3Impl(\n        boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);\n  }\n\n  depthToSpace(x: Tensor4D, blockSize: number, dataFormat: 'NHWC'|'NCHW'):\n      Tensor4D {\n    util.assert(\n        dataFormat === 'NHWC',\n        () => `Only NHWC dataFormat supported on CPU for depthToSpace. Got ${\n            dataFormat}`);\n    util.assert(\n        blockSize > 1,\n        () =>\n            `blockSize should be > 1 for depthToSpace, but was: ${blockSize}`);\n\n    const batchSize = x.shape[0];\n    const inputHeight = x.shape[1];\n    const inputWidth = x.shape[2];\n    const inputDepth = x.shape[3];\n\n    const outputHeight = inputHeight * blockSize;\n    const outputWidth = inputWidth * blockSize;\n    const outputDepth = inputDepth / (blockSize * blockSize);\n\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const result =\n        new Float32Array(batchSize * outputHeight * outputWidth * outputDepth);\n\n    let outputIdx = 0;\n    for (let b = 0; b < batchSize; ++b) {\n      for (let h = 0; h < outputHeight; ++h) {\n        const inH = Math.floor(h / blockSize);\n        const offsetH = (h % blockSize);\n        for (let w = 0; w < outputWidth; ++w) {\n          const inW = Math.floor(w / blockSize);\n          const offsetW = (w % blockSize);\n          const offsetD = (offsetH * blockSize + offsetW) * outputDepth;\n          for (let d = 0; d < outputDepth; ++d) {\n            const inD = d + offsetD;\n            const inputIdx =\n                inD + inputDepth * (inW + inputWidth * (inH + inputHeight * b));\n            result[outputIdx++] = xValues[inputIdx];\n          }\n        }\n      }\n    }\n    return tf.tensor4d(\n        result, [batchSize, outputHeight, outputWidth, outputDepth]);\n  }\n\n  private broadcastedBinaryOp(\n      a: Tensor, b: Tensor, dtype: DataType,\n      op: (a: number, b: number) => number): Tensor {\n    const newShape = backend_util.assertAndGetBroadcastShape(a.shape, b.shape);\n    const result = tf.buffer(newShape, dtype);\n    const aVals = this.readSync(a.dataId) as TypedArray;\n    const bVals = this.readSync(b.dataId) as TypedArray;\n    const aBroadcastDims = backend_util.getBroadcastDims(a.shape, newShape);\n    const bBroadcastDims = backend_util.getBroadcastDims(b.shape, newShape);\n\n    const resVals = result.values;\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n      for (let i = 0; i < resVals.length; ++i) {\n        resVals[i] = op(aVals[i % aVals.length], bVals[i % bVals.length]);\n      }\n    } else {\n      const aBuf = this.bufferSync(a);\n      const bBuf = this.bufferSync(b);\n      for (let i = 0; i < resVals.length; ++i) {\n        const loc = result.indexToLoc(i);\n\n        const aLoc = loc.slice(-a.rank);\n        aBroadcastDims.forEach(d => aLoc[d] = 0);\n        const aIndex = aBuf.locToIndex(aLoc);\n\n        const bLoc = loc.slice(-b.rank);\n        bBroadcastDims.forEach(d => bLoc[d] = 0);\n        const bIndex = bBuf.locToIndex(bLoc);\n\n        resVals[i] = op(aVals[aIndex], bVals[bIndex]);\n      }\n    }\n    return result.toTensor();\n  }\n\n  split<T extends Tensor>(x: T, sizeSplits: number[], axis: number): T[] {\n    return split(x, sizeSplits, axis);\n  }\n\n  dispose() {}\n\n  floatPrecision(): 16|32 {\n    return 32;\n  }\n\n  /** Returns the smallest representable number.  */\n  epsilon(): number {\n    return super.epsilon();\n  }\n\n  cropAndResize(\n      images: Tensor4D,\n      boxes: Tensor2D,\n      boxIndex: Tensor1D,\n      cropSize: [number, number],\n      method: string,\n      extrapolationValue: number,\n  ) {\n    const [batch, imageHeight, imageWidth, numChannels] = images.shape;\n    const numBoxes = boxes.shape[0];\n\n    const [cropHeight, cropWidth] = cropSize;\n    const output =\n        tf.buffer([numBoxes, cropHeight, cropWidth, numChannels], 'float32');\n\n    const boxVals = this.readSync(boxes.dataId) as TypedArray;\n    const boxIndVals = this.readSync(boxIndex.dataId) as TypedArray;\n    const imageVals = this.readSync(images.dataId) as TypedArray;\n\n    const inStride = images.strides;   // to calculate flat indexes into image\n    const outStride = output.strides;  // to calculate flat indexes into output\n\n    // Reference implementation\n    // tslint:disable-next-line:max-line-length\n    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/crop_and_resize_op.cc\n    for (let b = 0; b < numBoxes; b++) {\n      const startInd = b * 4;\n      const y1 = boxVals[startInd];\n      const x1 = boxVals[startInd + 1];\n      const y2 = boxVals[startInd + 2];\n      const x2 = boxVals[startInd + 3];\n\n      const bInd: number = boxIndVals[b];\n      if (bInd >= batch) {\n        continue;\n      }\n\n      const heightScale = (cropHeight > 1) ?\n          (y2 - y1) * (imageHeight - 1) / (cropHeight - 1) :\n          0;\n      const widthScale =\n          (cropWidth > 1) ? (x2 - x1) * (imageWidth - 1) / (cropWidth - 1) : 0;\n\n      for (let y = 0; y < cropHeight; y++) {\n        const yInd: number = (cropHeight > 1) ?\n            y1 * (imageHeight - 1) + y * (heightScale) :\n            0.5 * (y1 + y2) * (imageHeight - 1);\n\n        if (yInd < 0 || yInd > imageHeight - 1) {\n          for (let x = 0; x < cropWidth; x++) {\n            for (let c = 0; c < numChannels; c++) {\n              const ind =\n                  c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n              output.values[ind] = extrapolationValue;\n            }\n          }\n          continue;\n        }\n\n        if (method === 'bilinear') {\n          const topInd = Math.floor(yInd);\n          const bottomInd = Math.ceil(yInd);\n          const yLerp = yInd - topInd;\n\n          for (let x = 0; x < cropWidth; x++) {\n            const xInd = (cropWidth > 1) ?\n                x1 * (imageWidth - 1) + x * widthScale :\n                0.5 * (x1 + x2) * (imageWidth - 1);\n\n            if (xInd < 0 || xInd > imageWidth - 1) {\n              for (let c = 0; c < numChannels; c++) {\n                const ind =\n                    c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                output.values[ind] = extrapolationValue;\n              }\n              continue;\n            }\n\n            const leftInd = Math.floor(xInd);\n            const rightInd = Math.ceil(xInd);\n            const xLerp = xInd - leftInd;\n\n            for (let c = 0; c < numChannels; c++) {\n              let ind = c + leftInd * inStride[2] + topInd * inStride[1] +\n                  bInd * inStride[0];\n              const topLeft = imageVals[ind];\n\n              ind = c + rightInd * inStride[2] + topInd * inStride[1] +\n                  bInd * inStride[0];\n              const topRight = imageVals[ind];\n\n              ind = c + leftInd * inStride[2] + bottomInd * inStride[1] +\n                  bInd * inStride[0];\n              const bottomLeft = imageVals[ind];\n\n              ind = c + rightInd * inStride[2] + bottomInd * inStride[1] +\n                  bInd * inStride[0];\n              const bottomRight = imageVals[ind];\n\n              const top = topLeft + (topRight - topLeft) * xLerp;\n              const bottom = bottomLeft + (bottomRight - bottomLeft) * xLerp;\n\n              ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n              output.values[ind] = top + ((bottom - top) * yLerp);\n            }\n          }\n        } else {  // method == \"nearest\"\n          for (let x = 0; x < cropWidth; ++x) {\n            const xInd = (cropWidth > 1) ?\n                x1 * (imageWidth - 1) + x * widthScale :\n                0.5 * (x1 + x2) * (imageWidth - 1);\n\n            if (xInd < 0 || xInd > imageWidth - 1) {\n              for (let c = 0; c < numChannels; c++) {\n                const ind =\n                    c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                output.values[ind] = extrapolationValue;\n              }\n              continue;\n            }\n\n            const closestX = Math.round(xInd);\n            const closestY = Math.round(yInd);\n            for (let c = 0; c < numChannels; c++) {\n              const inInd = c + closestX * inStride[2] +\n                  closestY * inStride[1] + bInd * inStride[0];\n              const outInd =\n                  c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n              output.values[outInd] = imageVals[inInd];\n            }\n          }\n        }\n      }\n    }\n    return output.toTensor() as Tensor4D;\n  }\n\n  sparseToDense<R extends Rank>(\n      sparseIndices: Tensor, sparseValues: Tensor, outputShape: ShapeMap[R],\n      defaultValue: Scalar): Tensor<R> {\n    const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n        backend_util.calculateShapes(sparseValues, sparseIndices, outputShape);\n    const sumDupeIndices = false;\n    return this.scatter(\n        sparseIndices, sparseValues, outputShape, outputSize, sliceSize,\n        numUpdates, sliceRank, strides, defaultValue, sumDupeIndices);\n  }\n\n  gatherND(x: Tensor, indices: Tensor): Tensor {\n    const indicesShape = indices.shape;\n    const sliceRank = indicesShape[indicesShape.length - 1];\n\n    const [resultShape, numSlices, sliceSize, strides] =\n        backend_util.prepareAndValidate(x, indices);\n    if (numSlices === 0) {\n      return tf.tensor([], resultShape, x.dtype);\n    }\n\n    const buffer = new TensorBuffer([numSlices, sliceSize], x.dtype);\n    const indicesData = this.readSync(indices.dataId) as TypedArray;\n    const xData = this.readSync(x.dataId) as TypedArray;\n\n    for (let i = 0; i < numSlices; i++) {\n      const index = [];\n      let flattenIndex = 0;\n      for (let j = 0; j < sliceRank; j++) {\n        const dim = indicesData[i * sliceRank + j];\n        flattenIndex += dim * strides[j];\n        index.push(dim);\n      }\n      if (flattenIndex < 0 || flattenIndex >= x.size / sliceSize) {\n        throw new Error(\n            `Invalid indices: ${index} does not index into ${x.shape}`);\n      }\n\n      for (let k = 0; k < sliceSize; k++) {\n        buffer.values[i * sliceSize + k] = xData[flattenIndex * sliceSize + k];\n      }\n    }\n    return buffer.toTensor().reshape(resultShape);\n  }\n\n  scatterND<R extends Rank>(\n      indices: Tensor, updates: Tensor, shape: ShapeMap[R]): Tensor<R> {\n    const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n        backend_util.calculateShapes(updates, indices, shape);\n    const defaultValue = tf.scalar(0);\n    const sumDupeIndices = true;\n    return this.scatter(\n        indices, updates, shape, outputSize, sliceSize, numUpdates, sliceRank,\n        strides, defaultValue, sumDupeIndices);\n  }\n\n  fill<R extends Rank>(\n      shape: ShapeMap[R], value: number|string, dtype?: DataType): Tensor<R> {\n    dtype = dtype || util.inferDtype(value);\n    const values =\n        util.getArrayFromDType(dtype, util.sizeFromShape(shape)) as TypedArray;\n    values.fill(value as number);\n    return engine().makeTensor(values, shape, dtype, this) as Tensor<R>;\n  }\n\n  onesLike<R extends Rank>(x: Tensor<R>): Tensor<R> {\n    if (x.dtype === 'string') {\n      throw new Error('onesLike is not supported for string tensors');\n    } else {\n      return this.fill(x.shape, 1, x.dtype);\n    }\n  }\n\n  zerosLike<R extends Rank>(x: Tensor<R>): Tensor<R> {\n    const values = util.getArrayFromDType(\n                       x.dtype, util.sizeFromShape(x.shape)) as TypedArray;\n    return this.makeOutput(values, x.shape, x.dtype);\n  }\n\n  linspace(start: number, stop: number, num: number): Tensor1D {\n    return backend_util.linspaceImpl(start, stop, num);\n  }\n\n  private scatter<R extends Rank>(\n      indices: Tensor, updates: Tensor, shape: ShapeMap[R], outputSize: number,\n      sliceSize: number, numUpdates: number, sliceRank: number,\n      strides: number[], defaultValue: Scalar,\n      sumDupeIndices: boolean): Tensor<R> {\n    const flattenShape = [outputSize / sliceSize, sliceSize];\n\n    const indicesData = this.readSync(indices.dataId) as TypedArray;\n    const updatesData = this.readSync(updates.dataId) as TypedArray;\n\n    if (outputSize === 0) {\n      return tf.tensor([], shape, updates.dtype);\n    }\n\n    const buffer = new TensorBuffer(flattenShape, updates.dtype as 'float32');\n    buffer.values.fill((this.readSync(defaultValue.dataId) as TypedArray)[0]);\n\n    for (let i = 0; i < numUpdates; i++) {\n      const index = [];\n      let flattenIndex = 0;\n      for (let j = 0; j < sliceRank; j++) {\n        const dim = indicesData[i * sliceRank + j];\n        index.push(dim);\n        flattenIndex += dim * strides[j];\n      }\n\n      if (flattenIndex < 0 || flattenIndex >= outputSize / sliceSize) {\n        throw new Error(\n            `Invalid indices: ${index} does not index into ${shape}`);\n      }\n\n      for (let k = 0; k < sliceSize; k++) {\n        if (sumDupeIndices) {\n          buffer.values[flattenIndex * sliceSize + k] +=\n              updatesData[i * sliceSize + k];\n        } else {\n          buffer.values[flattenIndex * sliceSize + k] = updates.rank === 0 ?\n              updatesData[0] :\n              updatesData[i * sliceSize + k];\n        }\n      }\n    }\n    return buffer.toTensor().reshape(shape);\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Abs, AbsInputs, KernelConfig, KernelFunc, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function simpleAbsImpl(vals: TypedArray): Float32Array {\n  const resultValues = new Float32Array(vals.length);\n  for (let i = 0; i < vals.length; ++i) {\n    resultValues[i] = Math.abs(vals[i]);\n  }\n  return resultValues;\n}\n\nexport const absKernelFunc =\n    (args: {inputs: AbsInputs, backend: MathBackendCPU}) => {\n      const {x} = args.inputs;\n      const cpuBackend = args.backend;\n      let resultValues = new Float32Array(util.sizeFromShape(x.shape));\n      if (x.dtype !== 'complex64') {\n        const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n        resultValues = simpleAbsImpl(values);\n      } else {\n        const complexVals = cpuBackend.data.get(x.dataId);\n        const real = complexVals.complexTensorInfos.real;\n        const imag = complexVals.complexTensorInfos.imag;\n        const realVals =\n            cpuBackend.data.get(real.dataId).values as Float32Array;\n        const imagVals =\n            cpuBackend.data.get(imag.dataId).values as Float32Array;\n        for (let i = 0; i < realVals.length; i++) {\n          const real = realVals[i];\n          const imag = imagVals[i];\n          resultValues[i] = Math.hypot(real, imag);\n        }\n      }\n      return cpuBackend.makeOutput(resultValues, x.shape, 'float32');\n    };\n\nexport const absConfig: KernelConfig = {\n  kernelName: Abs,\n  backendName: 'cpu',\n  kernelFunc: absKernelFunc as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, NumericDataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {SimpleBinaryKernelImpl, SimpleBinaryOperation} from './binary_types';\n\n/**\n * Template that creates implementation for binary ops. Supports broadcast.\n */\nexport function createSimpleBinaryKernelImpl(op: SimpleBinaryOperation):\n    SimpleBinaryKernelImpl {\n  return (aShape: number[], bShape: number[], aVals: TypedArray,\n          bVals: TypedArray, dtype: DataType): [TypedArray, number[]] => {\n    const newShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n\n    const resultRank = newShape.length;\n    const resultStrides = util.computeStrides(newShape);\n    const resultSize = util.sizeFromShape(newShape);\n\n    const result =\n        util.getTypedArrayFromDType(dtype as NumericDataType, resultSize);\n\n    const aRank = aShape.length;\n    const bRank = bShape.length;\n\n    const aStrides = util.computeStrides(aShape);\n    const bStrides = util.computeStrides(bShape);\n\n    const aBroadcastDims = backend_util.getBroadcastDims(aShape, newShape);\n    const bBroadcastDims = backend_util.getBroadcastDims(bShape, newShape);\n\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n      for (let i = 0; i < result.length; ++i) {\n        result[i] = op(aVals[i % aVals.length], bVals[i % bVals.length]);\n      }\n    } else {\n      for (let i = 0; i < result.length; ++i) {\n        const loc = util.indexToLoc(i, resultRank, resultStrides);\n\n        const aLoc = loc.slice(-aRank);\n        aBroadcastDims.forEach(d => aLoc[d] = 0);\n        const aIndex = util.locToIndex(aLoc, aRank, aStrides);\n\n        const bLoc = loc.slice(-bRank);\n        bBroadcastDims.forEach(d => bLoc[d] = 0);\n        const bIndex = util.locToIndex(bLoc, bRank, bStrides);\n\n        result[i] = op(aVals[aIndex], bVals[bIndex]);\n      }\n    }\n\n    return [result, newShape];\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Complex, ComplexInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function complex(args: {inputs: ComplexInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {real, imag} = inputs;\n\n  const realVals = backend.data.get(real.dataId).values as TypedArray;\n  const imagVals = backend.data.get(imag.dataId).values as TypedArray;\n\n  const complexInfo = backend.makeTensorInfo(real.shape, 'complex64');\n\n  const complex = backend.data.get(complexInfo.dataId);\n\n  // The complex tensor owns the underlying real and imag tensorInfos, only the\n  // complex tensor tracks refCount, when complexData is disposed the\n  // underlying tensorData will be disposed.\n  complex.complexTensorInfos = {\n    real: backend.makeTensorInfo(real.shape, 'float32', realVals),\n    imag: backend.makeTensorInfo(imag.shape, 'float32', imagVals)\n  };\n\n  return complexInfo;\n}\n\nexport const complexConfig: KernelConfig = {\n  kernelName: Complex,\n  backendName: 'cpu',\n  kernelFunc: complex as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Identity, IdentityInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function identity(\n    args: {inputs: IdentityInputs, backend: MathBackendCPU}): TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  backend.incRef(x.dataId);\n\n  return {dataId: x.dataId, shape: x.shape, dtype: x.dtype};\n}\n\nexport const identityConfig: KernelConfig = {\n  kernelName: Identity,\n  backendName: 'cpu',\n  kernelFunc: identity as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Real, RealInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function real(args: {inputs: RealInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const real = backend.data.get(input.dataId).complexTensorInfos.real;\n  const realVal = backend.data.get(real.dataId).values;\n\n  // When complex tensor is disposed, its underlying parts will be disposed too.\n  // Make new tensor out of the real value of the complex. This makes sure the\n  // value is still accessible even if complex tensor is disposed.\n  return backend.makeTensorInfo(real.shape, real.dtype, realVal);\n}\n\nexport const realConfig: KernelConfig = {\n  kernelName: Real,\n  backendName: 'cpu',\n  kernelFunc: real as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as tf from '@tensorflow/tfjs-core';\nimport {Cast, CastAttrs, CastInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\n\nimport {complex} from './Complex';\nimport {identity} from './Identity';\nimport {real} from './Real';\n\nexport function cast(\n    args: {inputs: CastInputs, backend: MathBackendCPU, attrs: CastAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {dtype} = attrs;\n\n  // Casting to complex64.\n  if (dtype === 'complex64') {\n    if (x.dtype === 'complex64') {\n      return identity({inputs: {x}, backend});\n    }\n\n    // TODO(lina128): Import kernel function once zeros is modularized.\n    const zerosTensor = tf.zeros(x.shape);\n    const floatX = cast({inputs: {x}, backend, attrs: {dtype: 'float32'}});\n\n    const result =\n        complex({inputs: {real: floatX, imag: zerosTensor}, backend});\n\n    zerosTensor.dispose();\n    backend.disposeIntermediateTensorInfo(floatX);\n\n    return result;\n  }\n\n  // Casting from complex64\n  if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const result = cast({inputs: {x: realPart}, backend, attrs: {dtype}});\n\n    backend.disposeIntermediateTensorInfo(realPart);\n\n    return result;\n  }\n\n  if (!util.hasEncodingLoss(x.dtype, dtype)) {\n    // We don't change the underlying data, since we cast to higher\n    // precision.\n    const result = identity({inputs: {x}, backend});\n    return {dataId: result.dataId, shape: result.shape, dtype};\n  }\n\n  if (dtype === 'int32') {\n    const values = backend.data.get(x.dataId).values as TypedArray;\n    const resultValues = Int32Array.from(values);\n    return backend.makeTensorInfo(x.shape, 'int32', resultValues);\n  }\n\n  if (dtype === 'bool') {\n    // This is essentially the result of notEqual(x, 0). We avoid using\n    // kernel notEqual to avoid circular dependency, i.e. binary_utils ->\n    // cast -> notEqual -> binary_utils.\n    const xVals = backend.data.get(x.dataId).values as TypedArray;\n    const zero = util.toTypedArray([0], x.dtype);\n\n    const [resultData, resultShape] = createSimpleBinaryKernelImpl(\n        (a, b) => (a !== b) ? 1 : 0)(x.shape, [], xVals, zero, 'bool');\n\n    return backend.makeTensorInfo(resultShape, 'bool', resultData);\n  }\n\n  throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);\n}\n\nexport const castConfig: KernelConfig = {\n  kernelName: Cast,\n  backendName: 'cpu',\n  kernelFunc: cast as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BinaryInputs, DataType, KernelFunc, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {cast} from '../kernels/Cast';\nimport {complex} from '../kernels/Complex';\n\nimport {ComplexBinaryKernelImpl, ComplexBinaryOperation, SimpleBinaryKernelImpl} from './binary_types';\n\n/**\n * Template that creates a `KernelFunc` for binary ops.\n * @param name Kernel name.\n * @param binaryKernelImpl A `SimpleBinaryKernelImpl` for the kernel.\n * @param binaryKernelComplexImpl Optional. If exists, represents a\n *     `ComplexBinaryKernelImpl` for the kernel, will be used when input dtype\n *     is `complex64`.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\nexport function binaryKernelFunc(\n    name: string, simpleImpl: SimpleBinaryKernelImpl,\n    complexImpl?: ComplexBinaryKernelImpl, dtype?: DataType): KernelFunc {\n  if (complexImpl == null) {\n    return ({inputs, backend}) => {\n      const {a, b} = inputs as BinaryInputs;\n      const cpuBackend = backend as MathBackendCPU;\n\n      assertNotComplex([a, b], name);\n\n      const aVals = cpuBackend.data.get(a.dataId).values as TypedArray;\n      const bVals = cpuBackend.data.get(b.dataId).values as TypedArray;\n\n      const $dtype = dtype || a.dtype;\n\n      const [resultData, resultShape] =\n          simpleImpl(a.shape, b.shape, aVals, bVals, $dtype);\n\n      return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);\n    };\n  }\n\n  return ({inputs, backend}) => {\n    const {a, b} = inputs as BinaryInputs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    if (a.dtype === 'complex64' || b.dtype === 'complex64') {\n      const $aComplex = cast(\n          {inputs: {x: a}, backend: cpuBackend, attrs: {dtype: 'complex64'}});\n\n      const $aComplexVals = cpuBackend.data.get($aComplex.dataId);\n\n      const aReal = $aComplexVals.complexTensorInfos.real;\n      const aImag = $aComplexVals.complexTensorInfos.imag;\n\n      const aRealVals =\n          cpuBackend.data.get(aReal.dataId).values as Float32Array;\n      const aImagVals =\n          cpuBackend.data.get(aImag.dataId).values as Float32Array;\n\n      const $bComplex = cast(\n          {inputs: {x: b}, backend: cpuBackend, attrs: {dtype: 'complex64'}});\n\n      const $bComplexVals = cpuBackend.data.get($bComplex.dataId);\n\n      const bReal = $bComplexVals.complexTensorInfos.real;\n      const bImag = $bComplexVals.complexTensorInfos.imag;\n\n      const bRealVals =\n          cpuBackend.data.get(bReal.dataId).values as Float32Array;\n      const bImagVals =\n          cpuBackend.data.get(bImag.dataId).values as Float32Array;\n\n      const [resultRealData, resultImagData, resultShape] = complexImpl(\n          a.shape, b.shape, aRealVals, aImagVals, bRealVals, bImagVals);\n\n      const resultReal =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', resultRealData);\n\n      const resultImag =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', resultImagData);\n\n      const result = complex(\n          {inputs: {real: resultReal, imag: resultImag}, backend: cpuBackend});\n\n      cpuBackend.disposeIntermediateTensorInfo($aComplex);\n      cpuBackend.disposeIntermediateTensorInfo($bComplex);\n      cpuBackend.disposeIntermediateTensorInfo(resultReal);\n      cpuBackend.disposeIntermediateTensorInfo(resultImag);\n\n      return result;\n    } else {\n      const aVals = cpuBackend.data.get(a.dataId).values as TypedArray;\n      const bVals = cpuBackend.data.get(b.dataId).values as TypedArray;\n\n      const $dtype = dtype || a.dtype;\n\n      const [resultData, resultShape] =\n          simpleImpl(a.shape, b.shape, aVals, bVals, $dtype);\n\n      return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);\n    }\n  };\n}\n\n/**\n * Template that creates the complex type implementation for binary ops.\n * Supports broadcast.\n */\nexport function createComplexBinaryKernelImpl(op: ComplexBinaryOperation):\n    ComplexBinaryKernelImpl {\n  return (aShape: number[], bShape: number[], aRealVals: Float32Array,\n          aImagVals: Float32Array, bRealVals: Float32Array,\n          bImagVals: Float32Array): [TypedArray, TypedArray, number[]] => {\n    const resultShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n    const resultSize = util.sizeFromShape(resultShape);\n    const resultRank = resultShape.length;\n    const resultStrides = util.computeStrides(resultShape);\n\n    const resultRealVals = util.getTypedArrayFromDType('float32', resultSize);\n    const resultImagVals = util.getTypedArrayFromDType('float32', resultSize);\n\n    const aBroadcastDims = backend_util.getBroadcastDims(aShape, resultShape);\n    const bBroadcastDims = backend_util.getBroadcastDims(bShape, resultShape);\n\n    const aVals = backend_util.mergeRealAndImagArrays(aRealVals, aImagVals);\n    const bVals = backend_util.mergeRealAndImagArrays(bRealVals, bImagVals);\n\n    const aRank = aShape.length;\n    const aStrides = util.computeStrides(aShape);\n\n    const bRank = bShape.length;\n    const bStrides = util.computeStrides(bShape);\n\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n      for (let i = 0; i < resultRealVals.length; i++) {\n        const aIdx = i % aVals.length;\n        const bIdx = i % bVals.length;\n\n        const result =\n            op(aVals[aIdx * 2], aVals[aIdx * 2 + 1], bVals[bIdx * 2],\n               bVals[bIdx * 2 + 1]);\n\n        resultRealVals[i] = result.real;\n        resultImagVals[i] = result.imag;\n      }\n    } else {\n      for (let i = 0; i < resultRealVals.length; i++) {\n        const loc = util.indexToLoc(i, resultRank, resultStrides);\n\n        const aLoc = loc.slice(-aRank);\n        aBroadcastDims.forEach(d => aLoc[d] = 0);\n        const aIndex = util.locToIndex(aLoc, aRank, aStrides);\n\n        const bLoc = loc.slice(-bRank);\n        bBroadcastDims.forEach(d => bLoc[d] = 0);\n        const bIndex = util.locToIndex(bLoc, bRank, bStrides);\n\n        const opResult =\n            op(aVals[aIndex * 2], aVals[aIndex * 2 + 1], bVals[bIndex * 2],\n               bVals[bIndex * 2 + 1]);\n\n        resultRealVals[i] = opResult.real;\n        resultImagVals[i] = opResult.imag;\n      }\n    }\n    return [resultRealVals, resultImagVals, resultShape];\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Add, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/kernel_utils';\n\nexport const addImpl = createSimpleBinaryKernelImpl(((a, b) => a + b));\nexport const addComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {real: aReal + bReal, imag: aImag + bImag};\n    }));\n\nexport const add = binaryKernelFunc(Add, addImpl, addComplexImpl);\n\nexport const addConfig: KernelConfig = {\n  kernelName: Add,\n  backendName: 'cpu',\n  kernelFunc: add\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NumericDataType, util} from '@tensorflow/tfjs-core';\n\nimport {SimpleUnaryImpl, SimpleUnaryOperation} from './unary_types';\n\n/**\n * Template that creates implementation for unary op.\n */\nexport function createSimpleUnaryImpl(op: SimpleUnaryOperation):\n    SimpleUnaryImpl {\n  return (values, dtype, attrs) => {\n    const newValues =\n        util.getTypedArrayFromDType(dtype as NumericDataType, values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = op(values[i], attrs);\n    }\n    return newValues;\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, KernelFunc, TypedArray, UnaryInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {SimpleUnaryImpl, SimpleUnaryOperation} from './unary_types';\n\n/**\n * Template that creates a `KernelFunc` for unary ops.\n * @param name Kernel name.\n * @param op A `SimpleUnaryOperation` for the kernel.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the input. This is mainly used in certain\n *     kernels that return bool type, such as isFinite, isInf, etc.\n */\nexport function unaryKernelFunc(\n    name: string, op: SimpleUnaryOperation, dtype?: DataType): KernelFunc {\n  return ({inputs, attrs, backend}) => {\n    const {x} = inputs as UnaryInputs;\n    assertNotComplex(x, name);\n    if (x.dtype === 'string' || dtype === 'string') {\n      throw new Error('unaryKernelFunc does not support string input/output');\n    }\n\n    const cpuBackend = backend as MathBackendCPU;\n    const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const xSize = util.sizeFromShape(x.shape);\n    const $dtype = dtype || x.dtype;\n    const newValues = util.getArrayFromDType($dtype, xSize);\n    for (let i = 0; i < xSize; ++i) {\n      newValues[i] = op(values[i], attrs);\n    }\n    return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);\n  };\n}\n\n/**\n * Template that creates a `KernelFunc` for unary ops from the given\n * `SimpleUnaryImpl`..\n * @param name Kernel name.\n * @param unaryImpl A `SimpleUnaryImpl` that implements the op.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the input. This is mainly used in certain\n *     kernels that return bool type, such as isFinite, isInf, etc.\n */\nexport function unaryKernelFuncFromImpl(\n    name: string, unaryImpl: SimpleUnaryImpl, dtype?: DataType): KernelFunc {\n  return ({inputs, attrs, backend}) => {\n    const {x} = inputs as UnaryInputs;\n    assertNotComplex(x, name);\n    if (x.dtype === 'string' || dtype === 'string') {\n      throw new Error('unaryKernelFunc does not support string input/output');\n    }\n\n    const cpuBackend = backend as MathBackendCPU;\n    const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const $dtype = dtype || x.dtype;\n    const newValues = unaryImpl(values, $dtype, attrs);\n    return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Ceil, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const ceilImpl = createSimpleUnaryImpl((xi) => Math.ceil(xi));\nexport const ceilKernelFunc = unaryKernelFuncFromImpl(Ceil, ceilImpl);\n\nexport const ceilConfig: KernelConfig = {\n  kernelName: Ceil,\n  backendName: 'cpu',\n  kernelFunc: ceilKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Exp, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const expImpl = createSimpleUnaryImpl((xi) => Math.exp(xi));\nexport const expKernelFunc = unaryKernelFuncFromImpl(Exp, expImpl);\n\nexport const expConfig: KernelConfig = {\n  kernelName: Exp,\n  backendName: 'cpu',\n  kernelFunc: expKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Expm1, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const expm1Impl = createSimpleUnaryImpl((xi) => Math.expm1(xi));\nexport const expm1KernelFunc = unaryKernelFuncFromImpl(Expm1, expm1Impl);\n\nexport const expm1Config: KernelConfig = {\n  kernelName: Expm1,\n  backendName: 'cpu',\n  kernelFunc: expm1KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Floor, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const floorImpl = createSimpleUnaryImpl((xi) => Math.floor(xi));\nexport const floorKernelFunc = unaryKernelFuncFromImpl(Floor, floorImpl);\n\nexport const floorConfig: KernelConfig = {\n  kernelName: Floor,\n  backendName: 'cpu',\n  kernelFunc: floorKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Log} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const logImpl = createSimpleUnaryImpl((xi) => Math.log(xi));\nexport const logKernelFunc = unaryKernelFuncFromImpl(Log, logImpl);\n\nexport const logConfig: KernelConfig = {\n  kernelName: Log,\n  backendName: 'cpu',\n  kernelFunc: logKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NumericDataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function maxImpl(\n    aVals: TypedArray, reduceSize: number, outShape: number[],\n    dtype: DataType): TypedArray {\n  const vals = util.getTypedArrayFromDType(\n      dtype as NumericDataType, util.sizeFromShape(outShape));\n\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let max = aVals[offset];\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      if (value > max) {\n        max = value;\n      }\n    }\n    vals[i] = max;\n  }\n  return vals;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Multiply} from '@tensorflow/tfjs-core';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/kernel_utils';\n\nexport const multiplyImpl =\n    createSimpleBinaryKernelImpl(((aValue, bValue) => aValue * bValue));\nexport const multiplyComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {\n        real: aReal * bReal - aImag * bImag,\n        imag: aReal * bImag + aImag * bReal\n      };\n    }));\n\nexport const multiply =\n    binaryKernelFunc(Multiply, multiplyImpl, multiplyComplexImpl);\n\nexport const multiplyConfig: KernelConfig = {\n  kernelName: Multiply,\n  backendName: 'cpu',\n  kernelFunc: multiply\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Rsqrt} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const rsqrtImpl = createSimpleUnaryImpl((xi) => 1 / Math.sqrt(xi));\nexport const rsqrtKernelFunc = unaryKernelFuncFromImpl(Rsqrt, rsqrtImpl);\n\nexport const rsqrtConfig: KernelConfig = {\n  kernelName: Rsqrt,\n  backendName: 'cpu',\n  kernelFunc: rsqrtKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, KernelConfig, KernelFunc, NumericDataType, Slice, slice_util, SliceAttrs, SliceInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function sliceImpl(\n    vals: TypedArray, begin: number[], size: number[], shape: number[],\n    dtype: DataType): TypedArray {\n  const isContinous = slice_util.isSliceContinous(shape, begin, size);\n  const length = util.sizeFromShape(size);\n  const xStrides = util.computeStrides(shape);\n\n  if (isContinous) {\n    const flatOffset = slice_util.computeFlatOffset(begin, xStrides);\n    return vals.subarray(flatOffset, flatOffset + length);\n  }\n\n  const outVals = util.getTypedArrayFromDType(dtype as NumericDataType, length);\n  for (let i = 0; i < length; ++i) {\n    const rank = size.length;\n    const strides = util.computeStrides(size);\n    const loc = util.indexToLoc(i, rank, strides);\n    const xLoc = loc.map((idx: number, j) => idx + begin[j]);\n    const xIndex = util.locToIndex(xLoc, shape.length, xStrides);\n    outVals[i] = vals[xIndex];\n  }\n  return outVals;\n}\n\nexport function slice(\n    args: {inputs: SliceInputs, backend: MathBackendCPU, attrs: SliceAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {begin, size} = attrs;\n\n  assertNotComplex(x, 'slice');\n\n  const [$begin, $size] = slice_util.parseSliceParams(x, begin, size);\n  slice_util.assertParamsValid(x, $begin, $size);\n\n  const vals = backend.data.get(x.dataId).values as TypedArray;\n  const outVals = sliceImpl(vals, $begin, $size, x.shape, x.dtype);\n  return backend.makeTensorInfo($size, x.dtype, outVals);\n}\n\nexport const sliceConfig: KernelConfig = {\n  kernelName: Slice,\n  backendName: 'cpu',\n  kernelFunc: slice as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sub} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/kernel_utils';\n\nexport const subImpl =\n    createSimpleBinaryKernelImpl(((aValue, bValue) => aValue - bValue));\nexport const subComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {real: aReal - bReal, imag: aImag - bImag};\n    }));\nexport const sub = binaryKernelFunc(Sub, subImpl, subComplexImpl);\n\nexport const subConfig: KernelConfig = {\n  kernelName: Sub,\n  backendName: 'cpu',\n  kernelFunc: sub\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {util} from '@tensorflow/tfjs-core';\n\nexport function transposeImpl(\n    xVals: TypedArray, xShape: number[], dtype: DataType, perm: number[],\n    newShape: number[]): TypedArray {\n  const xRank = xShape.length;\n  const xSize = util.sizeFromShape(xShape);\n  const xStrides = util.computeStrides(xShape);\n  const newStrides = util.computeStrides(newShape);\n\n  const result = util.getTypedArrayFromDType(\n      dtype as NumericDataType, util.sizeFromShape(newShape));\n\n  for (let i = 0; i < xSize; ++i) {\n    const loc = util.indexToLoc(i, xRank, xStrides);\n\n    // Permute location.\n    const newLoc: number[] = new Array(loc.length);\n    for (let i = 0; i < newLoc.length; i++) {\n      newLoc[i] = loc[perm[i]];\n    }\n\n    const newIndex = util.locToIndex(newLoc, xRank, newStrides);\n    result[newIndex] = xVals[i];\n  }\n  return result;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BackendValues, DataType, TensorBuffer, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function uniqueImpl(\n    values: BackendValues, axis: number, shape: number[], dtype: DataType): {\n  outputValues: BackendValues,\n  outputShape: number[],\n  indices: BackendValues\n} {\n  // Normalize and validate axis.\n  const $axis = util.parseAxisParam(axis, shape)[0];\n\n  // Calculate the new shape that is suitable for extracting data along the\n  // given axis.\n  //\n  // The rank is 3.\n  // The size of the 1st dimension is the size of all the axes < the given axis.\n  // The size of the 2nd dimension is the same as the size of the given axis.\n  // The size of the 3rd dimension is the size of all the axes > the given axis.\n  //\n  // For example, for a 4D tensor with shape=[2, 3, 5, 4] and axis=2, the\n  // newShape would be: [2*3, 5, 4].\n  //\n  // Note that this is not the final output shape. This will be the shape for an\n  // intermediate TensorBuffer (see inputBuffer below) to allow us to extract\n  // values along the given axis. To demonstrate how it works, consider the\n  // following example:\n  //\n  // Input: a 3D tensor, with shape [1, 2, 3]\n  // [\n  //   [\n  //      [1,2,3],\n  //      [4,5,6]\n  //   ]\n  // ]\n  // Axis: 2 (the last axis).\n  // Along axis 2, we expect to extract 3 tensors: [1,4], [2,5], [3,6].\n  //\n  // For this example, newShape would be: [2, 3, 1], where 2 is calculated from\n  // 1*2. The re-shaped data would look like:\n  //\n  // [\n  //   [\n  //     [1], [2], [3]\n  //   ],\n  //   [\n  //     [4], [5], [6]\n  //   ]\n  // ]\n  //\n  // Then, we can construct a 3-level nested loop by the following dimension\n  // order to extract the values along the axis (dimension1):\n  // i: dimension1       // 0,1,2 (newShape[1])\n  //   m: dimension0     // 0,1   (newShape[0])\n  //     n: dimension2   // 0     (newShape[2])\n  //\n  //                       m, i, n\n  //                      ---------\n  // Iteration 0: data at [0, 0, 0] => \"1\"\n  // Iteration 1: data at [1, 0, 0] => \"4\"\n  // We got [1,4].\n  // Iteration 2: data at [0, 1, 0] => \"2\"\n  // Iteration 3: data at [1, 1, 0] => \"5\"\n  // We got [2,5].\n  // Iteration 4: data at [0, 2, 0] => \"3\"\n  // Iteration 5: data at [1, 2, 0] => \"6\"\n  // We got [3,6].\n  const newShape = [1, shape[0], 1];\n  for (let i = 0; i < $axis; i++) {\n    newShape[0] *= shape[i];\n  }\n  newShape[1] = shape[$axis];\n  for (let i = $axis + 1; i < shape.length; i++) {\n    newShape[2] *= shape[i];\n  }\n\n  // A map from unique elements (their string representations) to their values\n  // in \"indices\" (below).\n  const uniqueElements: {[key: string]: number} = {};\n  // The indices of each unique element in the original tensor along the given\n  // axis. It is 1D and has the same size as the given axis.\n  const indices = new Int32Array(shape[$axis]);\n  // Create a buffer so we can easily extract value at a given location.\n  const inputBuffer = new TensorBuffer(newShape, dtype, values as TypedArray);\n  // The indices along the given axis that have unique elements. This is a\n  // de-duped version of \"indices\" above.\n  const uniqueIndices: number[] = [];\n  const is1DTensor = newShape[0] === 1 && newShape[2] === 1;\n  for (let i = 0; i < shape[$axis]; i++) {\n    // Extract values along the axis.\n    let element: string;\n    if (is1DTensor) {\n      // Fast path for 1D tensor input.\n      element = values[i].toString();\n    } else {\n      const axisValues = [];\n      for (let m = 0; m < newShape[0]; m++) {\n        for (let n = 0; n < newShape[2]; n++) {\n          axisValues.push(inputBuffer.get(m, i, n));\n        }\n      }\n      element = axisValues.join(',');\n    }\n\n    // Dedup and update various indices.\n    if (uniqueElements[element] !== undefined) {\n      indices[i] = uniqueElements[element];\n    } else {\n      const uniqueIndex = Object.keys(uniqueElements).length;\n      uniqueElements[element] = uniqueIndex;\n      indices[i] = uniqueIndex;\n      uniqueIndices.push(i);\n    }\n  }\n\n  // Now we know where each of the unique elements are located along the axis\n  // (uniqueIndices). Extract them from input buffer and store them in the\n  // output buffer.\n  const outputTmpShape = newShape.slice();\n  outputTmpShape[1] = Object.keys(uniqueElements).length;\n  const outputBuffer = new TensorBuffer(outputTmpShape, dtype);\n  uniqueIndices.forEach((uniqueElementIndex, i) => {\n    for (let m = 0; m < newShape[0]; m++) {\n      for (let n = 0; n < newShape[2]; n++) {\n        outputBuffer.set(inputBuffer.get(m, uniqueElementIndex, n), m, i, n);\n      }\n    }\n  });\n\n  // The output shape can be calculated from the input shape with the size of\n  // the given axis replaced by the number of unique elements along that axis.\n  const outputShape = shape.slice();\n  outputShape[$axis] = outputTmpShape[1];\n\n  return {\n    outputValues: outputBuffer.values as BackendValues,\n    outputShape,\n    indices,\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/*\n * base.ts contains all the exports from tfjs-backend-cpu\n * without auto-kernel registration\n */\nimport {registerBackend} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from './backend_cpu';\nimport * as shared from './shared';\n\nexport {MathBackendCPU} from './backend_cpu';\nexport {version as version_cpu} from './version';\nexport {shared};\n\n// Side effects for default initialization of MathBackendCPU\nregisterBackend('cpu', () => new MathBackendCPU(), 1 /* priority */);\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Acos, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const acosKernelFunc = unaryKernelFunc(Acos, (xi) => Math.acos(xi));\n\nexport const acosConfig: KernelConfig = {\n  kernelName: Acos,\n  backendName: 'cpu',\n  kernelFunc: acosKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Acosh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const acoshKernelFunc = unaryKernelFunc(Acosh, (xi) => Math.acosh(xi));\n\nexport const acoshConfig: KernelConfig = {\n  kernelName: Acosh,\n  backendName: 'cpu',\n  kernelFunc: acoshKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Asin, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const asinKernelFunc = unaryKernelFunc(Asin, (xi) => Math.asin(xi));\n\nexport const asinConfig: KernelConfig = {\n  kernelName: Asin,\n  backendName: 'cpu',\n  kernelFunc: asinKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Asinh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const asinhKernelFunc = unaryKernelFunc(Asinh, (xi) => Math.asinh(xi));\n\nexport const asinhConfig: KernelConfig = {\n  kernelName: Asinh,\n  backendName: 'cpu',\n  kernelFunc: asinhKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atan, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const atanKernelFunc = unaryKernelFunc(Atan, (xi) => Math.atan(xi));\n\nexport const atanConfig: KernelConfig = {\n  kernelName: Atan,\n  backendName: 'cpu',\n  kernelFunc: atanKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atanh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const atanhKernelFunc = unaryKernelFunc(Atanh, (xi) => Math.atanh(xi));\n\nexport const atanhConfig: KernelConfig = {\n  kernelName: Atanh,\n  backendName: 'cpu',\n  kernelFunc: atanhKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, buffer, DataType, Rank, TensorBuffer, TypedArray} from '@tensorflow/tfjs-core';\n\nexport function pool(\n    xValues: TypedArray, xShape: number[], dtype: DataType, strides: number[],\n    convInfo: backend_util.Conv2DInfo,\n    poolType: 'max'|'avg'): TensorBuffer<Rank, DataType> {\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padTop = convInfo.padInfo.top;\n  const padLeft = convInfo.padInfo.left;\n\n  const initialValue =\n      (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n                            Number.POSITIVE_INFINITY);\n\n  const output = buffer(convInfo.outShape, dtype);\n  const outputVals = output.values;\n\n  const outputBatchStrides =\n      convInfo.outShape[1] * convInfo.outShape[2] * convInfo.outShape[3];\n  const outputRowStrides = convInfo.outShape[2] * convInfo.outShape[3];\n  const outputColStrides = convInfo.outShape[3];\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    const outputBatchOffset = b * outputBatchStrides;\n    const inputBatchOffset = b * strides[0];\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const xRCorner = yR * strideHeight - padTop;\n        const xRMin = Math.max(0, xRCorner);\n        const xRMax =\n            Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);\n        const outputRowOffset = outputBatchOffset + yR * outputRowStrides;\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const xCCorner = yC * strideWidth - padLeft;\n          const xCMin = Math.max(0, xCCorner);\n          const xCMax =\n              Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);\n          let minMaxValue = initialValue;\n          let avgValue = 0;\n          let count = 0;\n          for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {\n            const xROffset = inputBatchOffset + xR * strides[1];\n            for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {\n              const xCOffset = xROffset + xC * strides[2];\n              const pixel = xValues[xCOffset + d];\n              if ((poolType === 'max' && pixel > minMaxValue)) {\n                minMaxValue = pixel;\n              } else if (poolType === 'avg') {\n                avgValue += pixel;\n                count++;\n              }\n            }\n            if (isNaN(minMaxValue)) {\n              break;\n            }\n          }\n          const outputOffset = outputRowOffset + yC * outputColStrides + d;\n          outputVals[outputOffset] =\n              poolType === 'avg' ? avgValue / count : minMaxValue;\n        }\n      }\n    }\n  }\n  return output;\n}\n\nexport function maxPoolPositions(\n    xValues: TypedArray, xShape: number[], dtype: DataType,\n    convInfo: backend_util.Conv2DInfo, flattenPositions = false,\n    includeBatchInIndex = false): TensorBuffer<Rank, 'int32'> {\n  const maxPositions = buffer(convInfo.outShape, 'int32');\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padTop = convInfo.padInfo.top;\n  const padLeft = convInfo.padInfo.left;\n\n  const xBuf = buffer(xShape, dtype, xValues);\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const xRCorner = yR * strideHeight - padTop;\n        let xRMin = xRCorner;\n        while (xRMin < 0) {\n          xRMin += dilationHeight;\n        }\n        // const xRMin = Math.max(0, xRCorner);\n        const xRMax =\n            Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const xCCorner = yC * strideWidth - padLeft;\n          let xCMin = xCCorner;\n          while (xCMin < 0) {\n            xCMin += dilationWidth;\n          }\n          const xCMax =\n              Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);\n          let maxValue = Number.NEGATIVE_INFINITY;\n          let maxPosition = -1;\n\n          for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {\n            const wR = xR - xRCorner;\n            for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {\n              const wC = xC - xCCorner;\n              const pixel = xBuf.get(b, xR, xC, d);\n              if (pixel > maxValue) {\n                maxValue = pixel as number;\n                if (flattenPositions) {\n                  maxPosition = includeBatchInIndex ?\n                      ((b * convInfo.inHeight + xR) * convInfo.inWidth + xC) *\n                              convInfo.inChannels +\n                          d :\n                      (xR * convInfo.inWidth + xC) * convInfo.inChannels + d;\n                } else {\n                  maxPosition = wR * effectiveFilterWidth + wC;\n                }\n              }\n            }\n          }\n          maxPositions.set(maxPosition, b, yR, yC, d);\n        }\n      }\n    }\n  }\n  return maxPositions;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {AvgPool, AvgPoolAttrs, AvgPoolInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {pool} from '../utils/pool_utils';\nimport {identity} from './Identity';\n\nexport function avgPool(\n    args:\n        {inputs: AvgPoolInputs, backend: MathBackendCPU, attrs: AvgPoolAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  assertNotComplex(x, 'avgPool');\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n  const dilations = 1;\n\n  util.assert(\n      backend_util.eitherStridesOrDilationsAreOne(strides, dilations),\n      () => 'Error in avgPool: Either strides or dilations must be 1. ' +\n          `Got strides ${strides} and dilations '${dilations}'`);\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode);\n  let res: TensorInfo;\n\n  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 &&\n      util.arraysEqual(convInfo.inShape, convInfo.outShape)) {\n    res = identity({inputs: {x}, backend});\n  } else {\n    const xValues = backend.data.get(x.dataId).values as TypedArray;\n    const strides = util.computeStrides(x.shape);\n    const buffer = pool(xValues, x.shape, x.dtype, strides, convInfo, 'avg');\n    res = backend.makeTensorInfo(\n        convInfo.outShape, x.dtype, buffer.values as TypedArray);\n  }\n  return res;\n}\n\nexport const avgPoolConfig: KernelConfig = {\n  kernelName: AvgPool,\n  backendName: 'cpu',\n  kernelFunc: avgPool as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {AvgPoolBackprop, AvgPoolBackpropAttrs, AvgPoolBackpropInputs, backend_util, buffer, KernelConfig, KernelFunc, Rank, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function avgPoolBackprop(args: {\n  inputs: AvgPoolBackpropInputs,\n  backend: MathBackendCPU,\n  attrs: AvgPoolBackpropAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input} = inputs;\n  const x = input;\n  assertNotComplex([dy, input], 'avgPoolBackprop');\n  const {filterSize, strides, pad} = attrs;\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad);\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const filterHeight = convInfo.filterHeight;\n  const filterWidth = convInfo.filterWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n  const dx =\n      buffer<Rank.R4>(x.shape as [number, number, number, number], 'float32');\n\n  const avgMultiplier = 1 / (filterHeight * filterWidth);\n\n  const dyData = backend.data.get(dy.dataId).values as Float32Array;\n  const dyBuf = buffer<Rank.R4>(\n      dy.shape as [number, number, number, number], 'float32', dyData);\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n        for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n          // Shader code begins.\n          const dyRCorner = dxR - padTop;\n          const dyCCorner = dxC - padLeft;\n          let dotProd = 0;\n          for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {\n            const dyR = (dyRCorner + wR) / strideHeight;\n            if (dyR < 0 || dyR >= convInfo.outHeight ||\n                Math.floor(dyR) !== dyR) {\n              continue;\n            }\n            for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {\n              const dyC = (dyCCorner + wC) / strideWidth;\n              if (dyC < 0 || dyC >= convInfo.outWidth ||\n                  Math.floor(dyC) !== dyC) {\n                continue;\n              }\n\n              const pixel = dyBuf.get(b, dyR, dyC, d);\n              dotProd += pixel;\n            }\n          }\n          dx.set(dotProd * avgMultiplier, b, dxR, dxC, d);\n        }\n      }\n    }\n  }\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const avgPoolBackpropConfig: KernelConfig = {\n  kernelName: AvgPoolBackprop,\n  backendName: 'cpu',\n  kernelFunc: avgPoolBackprop as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FusedBatchNorm, FusedBatchNormAttrs, FusedBatchNormInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function batchNormKernelFunc(args: {\n  inputs: FusedBatchNormInputs,\n  backend: MathBackendCPU,\n  attrs: FusedBatchNormAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, scale, offset, mean, variance} = inputs;\n\n  util.assert(\n      mean.shape.length === variance.shape.length,\n      () => 'Batch normalization gradient requires mean and variance to have ' +\n          'equal ranks.');\n  util.assert(\n      offset == null || mean.shape.length === offset.shape.length,\n      () => 'Batch normalization gradient requires mean and offset to have ' +\n          'equal ranks.');\n  util.assert(\n      scale == null || mean.shape.length === scale.shape.length,\n      () => 'Batch normalization gradient requires mean and scale to have ' +\n          'equal ranks.');\n\n  assertNotComplex([x, mean, variance, scale, offset], 'batchNorm');\n\n  let {varianceEpsilon} = attrs;\n  if (varianceEpsilon == null) {\n    varianceEpsilon = 0.001;\n  }\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const mVals = backend.data.get(mean.dataId).values as TypedArray;\n  const varVals = backend.data.get(variance.dataId).values as TypedArray;\n  const sVals = scale ? backend.data.get(scale.dataId).values as TypedArray :\n                        new Float32Array([1]);\n  const offVals = offset ?\n      backend.data.get(offset.dataId).values as TypedArray :\n      new Float32Array([0]);\n  const outVals = new Float32Array(xVals.length);\n\n  const offValsLength = offVals.length;\n  const sValsLength = sVals.length;\n  const varValsLength = varVals.length;\n  const mValsLength = mVals.length;\n\n  let offi = 0;\n  let mi = 0;\n  let si = 0;\n  let vi = 0;\n  for (let i = 0; i < xVals.length; ++i) {\n    outVals[i] = offVals[offi++] +\n        (xVals[i] - mVals[mi++]) * sVals[si++] /\n            Math.sqrt(varVals[vi++] + varianceEpsilon);\n    if (offi >= offValsLength) {\n      offi = 0;\n    }\n    if (mi >= mValsLength) {\n      mi = 0;\n    }\n    if (si >= sValsLength) {\n      si = 0;\n    }\n    if (vi >= varValsLength) {\n      vi = 0;\n    }\n  }\n  return backend.makeTensorInfo(x.shape, x.dtype, outVals);\n}\n\nexport const batchNormConfig: KernelConfig = {\n  kernelName: FusedBatchNorm,\n  backendName: 'cpu',\n  kernelFunc: batchNormKernelFunc as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ClipByValue, ClipByValueAttrs, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const clipKernelFunc = unaryKernelFunc(ClipByValue, (xi, attrs) => {\n  const clipAttrs = attrs as {} as ClipByValueAttrs;\n  if (xi > clipAttrs.clipValueMax) {\n    return clipAttrs.clipValueMax;\n  }\n  return xi < clipAttrs.clipValueMin ? clipAttrs.clipValueMin : xi;\n});\n\nexport const clipConfig: KernelConfig = {\n  kernelName: ClipByValue,\n  backendName: 'cpu',\n  kernelFunc: clipKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Imag, ImagInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function imag(args: {inputs: ImagInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const imag = backend.data.get(input.dataId).complexTensorInfos.imag;\n  const imagVal = backend.data.get(imag.dataId).values;\n\n  // When complex tensor is disposed, its underlying parts will be disposed too.\n  // Make new tensor out of the imag value of the complex. This makes sure the\n  // value is still accessible even if complex tensor is disposed.\n  return backend.makeTensorInfo(imag.shape, imag.dtype, imagVal);\n}\n\nexport const imagConfig: KernelConfig = {\n  kernelName: Imag,\n  backendName: 'cpu',\n  kernelFunc: imag as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Reshape, ReshapeAttrs, ReshapeInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function reshape(\n    args:\n        {inputs: ReshapeInputs, backend: MathBackendCPU, attrs: ReshapeAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {shape} = attrs;\n\n  const xSize = util.sizeFromShape(x.shape);\n  const $shape = util.inferFromImplicitShape(shape, xSize);\n  const $xSize = util.sizeFromShape($shape);\n\n  util.assert(\n      xSize === $xSize,\n      () => `The new shape (${$shape}) has ${$xSize} elements and the old ` +\n          `shape (${x.shape}) has ${xSize} elements. The new shape and old ` +\n          `shape must have the same number of elements.`);\n\n  backend.incRef(x.dataId);\n\n  const xData = backend.data.get(x.dataId);\n\n  if (xData.complexTensorInfos != null) {\n    const real = xData.complexTensorInfos.real;\n    const imag = xData.complexTensorInfos.imag;\n\n    real.shape = $shape;\n    imag.shape = $shape;\n  }\n\n  return {dataId: x.dataId, shape: $shape, dtype: x.dtype};\n}\n\nexport const reshapeConfig: KernelConfig = {\n  kernelName: Reshape,\n  backendName: 'cpu',\n  kernelFunc: reshape as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Concat, ConcatAttrs, ConcatInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {complex} from './Complex';\nimport {imag} from './Imag';\nimport {real} from './Real';\nimport {reshape} from './Reshape';\n\nexport function concat(\n    args: {inputs: ConcatInputs, backend: MathBackendCPU, attrs: ConcatAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {axis} = attrs;\n\n  const $axis = util.parseAxisParam(axis, inputs[0].shape)[0];\n  let outShape = backend_util.computeOutShape(inputs.map(t => t.shape), $axis);\n\n  if (util.sizeFromShape(outShape) === 0) {\n    return backend.makeTensorInfo(outShape, inputs[0].dtype, []);\n  }\n\n  // Keep only non-empty tensors (ignore tensors with 0 in their shape).\n  const $inputs = inputs.filter(t => util.sizeFromShape(t.shape) > 0);\n  if ($inputs.length === 1) {\n    return $inputs[0];\n  }\n\n  const shapes = $inputs.map(t => t.shape);\n  backend_util.assertParamsConsistent(shapes, $axis);\n\n  if ($inputs[0].dtype === 'complex64') {\n    const reals = $inputs.map((t) => real({inputs: {input: t}, backend}));\n    const imags = $inputs.map((t) => imag({inputs: {input: t}, backend}));\n\n    const realConcated = concat({inputs: reals, backend, attrs: {axis}});\n    const imagConcated = concat({inputs: imags, backend, attrs: {axis}});\n\n    const result =\n        complex({inputs: {real: realConcated, imag: imagConcated}, backend});\n\n    reals.forEach(r => backend.disposeIntermediateTensorInfo(r));\n    imags.forEach(i => backend.disposeIntermediateTensorInfo(i));\n    backend.disposeIntermediateTensorInfo(realConcated);\n    backend.disposeIntermediateTensorInfo(imagConcated);\n\n    return result;\n  }\n\n  // Any concat of n-dimensional tensors across any axis can be reduced to\n  // a concatenation of two-dimensional tensors across the axis 1 by first\n  // partitioning the axes of the original tensors into those less than the\n  // axis to be concatenated and the rest. Then reshape the tensors\n  // into a two-dimensional tensor by collapsing these two sets of axes and\n  // concatenate the resulting matrices across the axis 1, finally reshaping\n  // the result to have the proper shape.\n  const inputs2D = $inputs.map(t => {\n    const innerSize = util.sizeFromShape(t.shape.slice($axis));\n    const shape = [-1, innerSize];\n    return reshape({inputs: {x: t}, backend, attrs: {shape}});\n  });\n\n  // Concats 2d tensors along axis=1.\n  outShape =\n      backend_util.computeOutShape(inputs2D.map(t => t.shape), 1 /* axis */);\n\n  const outVals = util.getTypedArrayFromDType(\n      $inputs[0].dtype as 'float32', util.sizeFromShape(outShape));\n\n  if (inputs2D[0].shape[0] === 1) {\n    // Use built-in TypedArray.set() method for speed.\n    let offset = 0;\n    inputs2D.forEach(t => {\n      const val = backend.data.get(t.dataId).values as TypedArray;\n      const size = util.sizeFromShape(t.shape);\n\n      outVals.set(val, offset);\n      offset += size;\n    });\n  } else {\n    let colOffset = 0;\n\n    inputs2D.forEach(t => {\n      const tVals = backend.data.get(t.dataId).values as TypedArray;\n\n      let tIdx = 0;\n\n      for (let row = 0; row < t.shape[0]; ++row) {\n        const resIdx = row * outShape[1] + colOffset;\n        for (let col = 0; col < t.shape[1]; ++col) {\n          outVals[resIdx + col] = tVals[tIdx++];\n        }\n      }\n\n      colOffset += t.shape[1];\n    });\n  }\n\n  const finalOutShape =\n      backend_util.computeOutShape($inputs.map(t => t.shape), $axis);\n\n  const outInfo =\n      backend.makeTensorInfo(finalOutShape, inputs[0].dtype, outVals);\n\n  inputs2D.forEach(t => backend.disposeIntermediateTensorInfo(t));\n\n  return outInfo;\n}\n\nexport const concatConfig: KernelConfig = {\n  kernelName: Concat,\n  backendName: 'cpu',\n  kernelFunc: concat as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cos, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const cosKernelFunc = unaryKernelFunc(Cos, (xi) => Math.cos(xi));\n\nexport const cosConfig: KernelConfig = {\n  kernelName: Cos,\n  backendName: 'cpu',\n  kernelFunc: cosKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cosh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const coshKernelFunc = unaryKernelFunc(Cosh, (xi) => Math.cosh(xi));\n\nexport const coshConfig: KernelConfig = {\n  kernelName: Cosh,\n  backendName: 'cpu',\n  kernelFunc: coshKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2D, Dilation2DAttrs, Dilation2DInputs, KernelConfig, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const dilation2dConfig: KernelConfig = {\n  kernelName: Dilation2D,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {x, filter} = inputs as Dilation2DInputs;\n    const {strides, pad, dilations} = attrs as {} as Dilation2DAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const xVals = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const xRank = x.shape.length;\n\n    const filterVals = cpuBackend.data.get(filter.dataId).values as TypedArray;\n    const filterRank = filter.shape.length;\n\n    const {\n      batchSize,\n      inHeight,\n      inWidth,\n      inChannels,\n      outHeight,\n      outWidth,\n      padInfo,\n      strideHeight,\n      strideWidth,\n      filterHeight,\n      filterWidth,\n      dilationHeight,\n      dilationWidth,\n      outShape\n    } =\n        backend_util.computeDilation2DInfo(\n            x.shape as [number, number, number, number],\n            filter.shape as [number, number, number], strides, pad,\n            'NHWC' /* dataFormat */, dilations);\n\n    const outSize = util.sizeFromShape(outShape);\n    const outRank = outShape.length;\n    const outputVals = util.getArrayFromDType(x.dtype, outSize);\n\n    // Upsampling the input by fill in `dilation size - 1` values between each\n    // input value.\n    // This implementation follows the TF c++ implementation:\n    // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n    for (let b = 0; b < batchSize; ++b) {\n      for (let hOut = 0; hOut < outHeight; ++hOut) {\n        const hBeg = hOut * strideHeight - padInfo.top;\n        for (let wOut = 0; wOut < outWidth; ++wOut) {\n          const wBeg = wOut * strideWidth - padInfo.left;\n          for (let d = 0; d < inChannels; ++d) {\n            let curVal = Number.MIN_SAFE_INTEGER;\n            for (let h = 0; h < filterHeight; ++h) {\n              const hIn = hBeg + h * dilationHeight;\n              if (hIn >= 0 && hIn < inHeight) {\n                for (let w = 0; w < filterWidth; ++w) {\n                  const wIn = wBeg + w * dilationWidth;\n                  if (wIn >= 0 && wIn < inWidth) {\n                    const xIndex = util.locToIndex(\n                        [b, hIn, wIn, d], xRank, util.computeStrides(x.shape));\n                    const filterIndex = util.locToIndex(\n                        [h, w, d], filterRank,\n                        util.computeStrides(filter.shape));\n                    const val = xVals[xIndex] + filterVals[filterIndex];\n                    if (val > curVal) {\n                      curVal = val;\n                    }\n                  }\n                }\n              }\n            }\n            const outputIndex = util.locToIndex(\n                [b, hOut, wOut, d], outRank, util.computeStrides(outShape));\n            outputVals[outputIndex] = curVal;\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(\n        util.toTypedArray(outputVals, x.dtype), outShape, x.dtype);\n\n    return {dataId, shape: outShape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2DAttrs, Dilation2DBackpropFilter, Tensor3D, Tensor4D, TypedArray, util} from '@tensorflow/tfjs-core';\nimport {KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const dilation2dBackpropFilterConfig: KernelConfig = {\n  kernelName: Dilation2DBackpropFilter,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {x, filter, dy} =\n        inputs as {x: Tensor4D, filter: Tensor3D, dy: Tensor4D};\n    const {strides, pad, dilations} = attrs as {} as Dilation2DAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const $x =\n        util.toNestedArray(\n            x.shape, cpuBackend.data.get(x.dataId).values as TypedArray) as\n        number[][][][];\n\n    const $filter = util.toNestedArray(\n                        filter.shape,\n                        cpuBackend.data.get(filter.dataId).values as\n                            TypedArray) as number[][][];\n\n    const {\n      batchSize,\n      inHeight,\n      inWidth,\n      inChannels,\n      outHeight,\n      outWidth,\n      padInfo,\n      strideHeight,\n      strideWidth,\n      filterHeight,\n      filterWidth,\n      dilationHeight,\n      dilationWidth,\n      outShape\n    } =\n        backend_util.computeDilation2DInfo(\n            x.shape as [number, number, number, number],\n            filter.shape as [number, number, number], strides, pad,\n            'NHWC' /* dataFormat */, dilations);\n\n    util.assert(\n        dy.rank === outShape.length,\n        () => `Error in ${Dilation2DBackpropFilter}, dy ` +\n            `must have the same rank as output ${outShape.length}, but got ` +\n            `${dy.rank}`);\n\n    const $dy =\n        util.toNestedArray(\n            outShape, cpuBackend.data.get(dy.dataId).values as TypedArray) as\n        number[][][][];\n\n    // The computed filter gradients has the same dimensions as the filter:\n    // [filterHeight, filterWidth, depth]\n    const gradients = util.makeZerosNestedTypedArray(\n                          filter.shape, filter.dtype) as number[][][];\n\n    // In the case of multiple argmax branches, we only back-propagate along the\n    // last branch, i.e., the one with largest value of `h * filter_cols + w`,\n    // similarly to the max-pooling backward routines.\n    // This implementation follows the TF c++ implementation:\n    // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n    for (let b = 0; b < batchSize; ++b) {\n      for (let hOut = 0; hOut < outHeight; ++hOut) {\n        const hBeg = hOut * strideHeight - padInfo.top;\n        for (let wOut = 0; wOut < outWidth; ++wOut) {\n          const wBeg = wOut * strideWidth - padInfo.left;\n          for (let d = 0; d < inChannels; ++d) {\n            let curVal = Number.MIN_SAFE_INTEGER;\n            let hMax = 0;\n            let wMax = 0;\n            for (let h = 0; h < filterHeight; ++h) {\n              const hIn = hBeg + h * dilationHeight;\n              if (hIn >= 0 && hIn < inHeight) {\n                for (let w = 0; w < filterWidth; ++w) {\n                  const wIn = wBeg + w * dilationWidth;\n                  if (wIn >= 0 && wIn < inWidth) {\n                    const val = $x[b][hIn][wIn][d] + $filter[h][w][d];\n                    if (val > curVal) {\n                      curVal = val;\n                      hMax = h;\n                      wMax = w;\n                    }\n                  }\n                }\n              }\n            }\n            gradients[hMax][wMax][d] += $dy[b][hOut][wOut][d];\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(\n        util.toTypedArray(gradients, x.dtype), filter.shape, filter.dtype);\n\n    return {dataId, shape: filter.shape, dtype: filter.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2DAttrs, Dilation2DBackpropInput, Tensor3D, Tensor4D, TypedArray, util} from '@tensorflow/tfjs-core';\nimport {KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const dilation2dBackpropInputConfig: KernelConfig = {\n  kernelName: Dilation2DBackpropInput,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {x, filter, dy} =\n        inputs as {x: Tensor4D, filter: Tensor3D, dy: Tensor4D};\n    const {strides, pad, dilations} = attrs as {} as Dilation2DAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const $x =\n        util.toNestedArray(\n            x.shape, cpuBackend.data.get(x.dataId).values as TypedArray) as\n        number[][][][];\n\n    const $filter = util.toNestedArray(\n                        filter.shape,\n                        cpuBackend.data.get(filter.dataId).values as\n                            TypedArray) as number[][][];\n\n    const {\n      batchSize,\n      inHeight,\n      inWidth,\n      inChannels,\n      outHeight,\n      outWidth,\n      padInfo,\n      strideHeight,\n      strideWidth,\n      filterHeight,\n      filterWidth,\n      dilationHeight,\n      dilationWidth,\n      outShape\n    } =\n        backend_util.computeDilation2DInfo(\n            x.shape as [number, number, number, number],\n            filter.shape as [number, number, number], strides, pad,\n            'NHWC' /* dataFormat */, dilations);\n\n    util.assert(\n        dy.rank === outShape.length,\n        () => `Error in ${Dilation2DBackpropInput}, dy ` +\n            `must have the same rank as output ${outShape.length}, but got ` +\n            `${dy.rank}`);\n\n    const $dy =\n        util.toNestedArray(\n            outShape, cpuBackend.data.get(dy.dataId).values as TypedArray) as\n        number[][][][];\n\n    // The computed gradients has the same dimensions as the input:\n    // [batch, inputHeight, inputCols, inChannel]\n    const gradients =\n        util.makeZerosNestedTypedArray(x.shape, x.dtype) as number[][][][];\n\n    // In the case of multiple argmax branches, we only back-propagate along the\n    // last branch, i.e., the one with largest value of `h * filter_cols + w`,\n    // similarly to the max-pooling backward routines.\n    // This implementation follows the TF c++ implementation:\n    // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n    for (let b = 0; b < batchSize; ++b) {\n      for (let hOut = 0; hOut < outHeight; ++hOut) {\n        const hBeg = hOut * strideHeight - padInfo.top;\n        for (let wOut = 0; wOut < outWidth; ++wOut) {\n          const wBeg = wOut * strideWidth - padInfo.left;\n          for (let d = 0; d < inChannels; ++d) {\n            let curVal = Number.MIN_SAFE_INTEGER;\n            let hInMax = (hBeg < 0) ? 0 : hBeg;\n            let wInMax = (wBeg < 0) ? 0 : wBeg;\n            for (let h = 0; h < filterHeight; ++h) {\n              const hIn = hBeg + h * dilationHeight;\n              if (hIn >= 0 && hIn < inHeight) {\n                for (let w = 0; w < filterWidth; ++w) {\n                  const wIn = wBeg + w * dilationWidth;\n                  if (wIn >= 0 && wIn < inWidth) {\n                    const val = $x[b][hIn][wIn][d] + $filter[h][w][d];\n                    if (val > curVal) {\n                      curVal = val;\n                      hInMax = hIn;\n                      wInMax = wIn;\n                    }\n                  }\n                }\n              }\n            }\n            gradients[b][hInMax][wInMax][d] += $dy[b][hOut][wOut][d];\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(\n        util.toTypedArray(gradients, x.dtype), x.shape, x.dtype);\n\n    return {dataId, shape: x.shape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Div, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/kernel_utils';\n\nexport const divImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => a / b);\nexport const div = binaryKernelFunc(Div, divImpl);\n\nexport const divConfig: KernelConfig = {\n  kernelName: Div,\n  backendName: 'cpu',\n  kernelFunc: div\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Elu, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const eluKernelFunc =\n    unaryKernelFunc(Elu, (xi) => xi >= 0 ? xi : (Math.exp(xi) - 1));\n\nexport const eluConfig: KernelConfig = {\n  kernelName: Elu,\n  backendName: 'cpu',\n  kernelFunc: eluKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Erf, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nconst p = backend_util.ERF_P;\nconst a1 = backend_util.ERF_A1;\nconst a2 = backend_util.ERF_A2;\nconst a3 = backend_util.ERF_A3;\nconst a4 = backend_util.ERF_A4;\nconst a5 = backend_util.ERF_A5;\n\nexport const erfKernelFunc = unaryKernelFunc(\n    Erf,\n    (xi) => {\n      const sign = Math.sign(xi);\n      const v = Math.abs(xi);\n      const t = 1.0 / (1.0 + p * v);\n      return sign *\n          (1.0 -\n           (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t *\n               Math.exp(-v * v));\n    },\n);\n\nexport const erfConfig: KernelConfig = {\n  kernelName: Erf,\n  backendName: 'cpu',\n  kernelFunc: erfKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Tensor, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {add} from '../kernels/Add';\nimport {complex} from '../kernels/Complex';\nimport {concat} from '../kernels/Concat';\nimport {divConfig} from '../kernels/Div';\nimport {identity} from '../kernels/Identity';\nimport {imag} from '../kernels/Imag';\nimport {multiply} from '../kernels/Multiply';\nimport {real} from '../kernels/Real';\nimport {slice} from '../kernels/Slice';\nimport {sub} from '../kernels/Sub';\n\n/**\n * Calculate FFT of inner most elements of batch tensor.\n */\nexport function fftBatch(\n    input: TensorInfo, inverse: boolean,\n    cpuBackend: MathBackendCPU): TensorInfo {\n  const inputShape = input.shape;\n  const batch = inputShape[0];\n  const innerDim = inputShape[1];\n\n  const inputVals = cpuBackend.data.get(input.dataId);\n\n  const real2D = inputVals.complexTensorInfos.real;\n  const imag2D = inputVals.complexTensorInfos.imag;\n\n  // Collects real and imaginary values separately.\n  const resultShape = [batch, innerDim];\n  const resultSize = util.sizeFromShape(resultShape);\n  const resultReal = util.getTypedArrayFromDType('float32', resultSize);\n  const resultImag = util.getTypedArrayFromDType('float32', resultSize);\n\n  for (let b = 0; b < batch; b++) {\n    // TODO: Support slice ops for complex type.\n    const r = slice({\n      inputs: {x: real2D},\n      backend: cpuBackend,\n      attrs: {begin: [b, 0], size: [1, innerDim]}\n    });\n    const i = slice({\n      inputs: {x: imag2D},\n      backend: cpuBackend,\n      attrs: {begin: [b, 0], size: [1, innerDim]}\n    });\n\n    const input = complex({inputs: {real: r, imag: i}, backend: cpuBackend});\n\n    // Run FFT by batch element.\n    const {real, imag} = fftImpl(input, inverse, cpuBackend);\n    const res = backend_util.mergeRealAndImagArrays(real, imag);\n\n    for (let d = 0; d < innerDim; d++) {\n      const c = backend_util.getComplexWithIndex(res, d);\n      resultReal[b * innerDim + d] = c.real;\n      resultImag[b * innerDim + d] = c.imag;\n    }\n\n    cpuBackend.disposeIntermediateTensorInfo(r);\n    cpuBackend.disposeIntermediateTensorInfo(i);\n    cpuBackend.disposeIntermediateTensorInfo(input);\n  }\n\n  const $realInfo: TensorInfo =\n      cpuBackend.makeTensorInfo(resultShape, 'float32', resultReal);\n  const $imagInfo: TensorInfo =\n      cpuBackend.makeTensorInfo(resultShape, 'float32', resultImag);\n\n  const result = complex(\n      {inputs: {real: $realInfo, imag: $imagInfo}, backend: cpuBackend});\n\n  cpuBackend.disposeIntermediateTensorInfo($realInfo);\n  cpuBackend.disposeIntermediateTensorInfo($imagInfo);\n\n  return result;\n}\n\nexport function fftImpl(\n    input: TensorInfo, inverse: boolean,\n    cpuBackend: MathBackendCPU): {real: Float32Array, imag: Float32Array} {\n  const inputSize = util.sizeFromShape(input.shape);\n\n  const inputVals = cpuBackend.data.get(input.dataId);\n\n  const realVals =\n      cpuBackend.data.get(inputVals.complexTensorInfos.real.dataId).values as\n      Float32Array;\n\n  const imagVals =\n      cpuBackend.data.get(inputVals.complexTensorInfos.imag.dataId).values as\n      Float32Array;\n\n  if (isExponentOf2(inputSize)) {\n    const result =\n        fftRadix2(realVals, imagVals, inputSize, inverse, cpuBackend);\n\n    const resultShape = [input.shape[0], input.shape[1]];\n\n    if (inverse) {\n      const realInfo: TensorInfo =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', result.real);\n      const imagInfo: TensorInfo =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', result.imag);\n\n      const sizeInfo: TensorInfo = cpuBackend.makeTensorInfo(\n          [], 'float32',\n          util.createScalarValue(inputSize as {} as 'float32', 'float32'));\n      const sizeInfoCopy =\n          identity({inputs: {x: sizeInfo}, backend: cpuBackend});\n\n      const divRealInfo =\n          divConfig.kernelFunc(\n              {inputs: {a: realInfo, b: sizeInfo}, backend: cpuBackend}) as\n          TensorInfo;\n      const divImagInfo =\n          divConfig.kernelFunc(\n              {inputs: {a: imagInfo, b: sizeInfoCopy}, backend: cpuBackend}) as\n          TensorInfo;\n\n      const divRealVals =\n          cpuBackend.data.get(divRealInfo.dataId).values as Float32Array;\n      const divImagVals =\n          cpuBackend.data.get(divImagInfo.dataId).values as Float32Array;\n\n      cpuBackend.disposeIntermediateTensorInfo(realInfo);\n      cpuBackend.disposeIntermediateTensorInfo(imagInfo);\n      cpuBackend.disposeIntermediateTensorInfo(sizeInfo);\n      cpuBackend.disposeIntermediateTensorInfo(sizeInfoCopy);\n      cpuBackend.disposeIntermediateTensorInfo(divRealInfo);\n      cpuBackend.disposeIntermediateTensorInfo(divImagInfo);\n\n      return {real: divRealVals, imag: divImagVals};\n    }\n\n    return result;\n  } else {\n    const data = backend_util.mergeRealAndImagArrays(realVals, imagVals);\n\n    const rawOutput =\n        fourierTransformByMatmul(data, inputSize, inverse) as Float32Array;\n\n    return backend_util.splitRealAndImagArrays(rawOutput);\n  }\n}\n\nfunction isExponentOf2(size: number): boolean {\n  return (size & size - 1) === 0;\n}\n\n// FFT using Cooley-Tukey algorithm on radix 2 dimensional input.\nfunction fftRadix2(\n    realVals: Float32Array, imagVals: Float32Array, size: number,\n    inverse: boolean,\n    cpuBackend: MathBackendCPU): {real: Float32Array, imag: Float32Array} {\n  if (size === 1) {\n    return {real: realVals, imag: imagVals};\n  }\n\n  const data = backend_util.mergeRealAndImagArrays(realVals, imagVals);\n\n  const half = size / 2;\n\n  const evenComplex = backend_util.complexWithEvenIndex(data);\n\n  const evenRealVals = evenComplex.real;\n  const evenImagVals = evenComplex.imag;\n\n  const evenShape = [evenRealVals.length];\n\n  const evenRealInfo =\n      cpuBackend.makeTensorInfo(evenShape, 'float32', evenRealVals);\n  const evenImagInfo =\n      cpuBackend.makeTensorInfo(evenShape, 'float32', evenImagVals);\n\n  const evenTensorInfo = complex(\n      {inputs: {real: evenRealInfo, imag: evenImagInfo}, backend: cpuBackend});\n\n  const oddComplex = backend_util.complexWithOddIndex(data);\n\n  const oddRealVals = oddComplex.real;\n  const oddImagVals = oddComplex.imag;\n\n  const oddShape = [oddRealVals.length];\n\n  const oddRealInfo =\n      cpuBackend.makeTensorInfo(oddShape, 'float32', oddRealVals);\n  const oddImagInfo =\n      cpuBackend.makeTensorInfo(oddShape, 'float32', oddImagVals);\n\n  const oddTensorInfo = complex(\n      {inputs: {real: oddRealInfo, imag: oddImagInfo}, backend: cpuBackend});\n\n  // Recursive call for half part of original input.\n  const $evenComplex =\n      fftRadix2(evenRealVals, evenImagVals, half, inverse, cpuBackend);\n\n  const $evenRealVals = $evenComplex.real;\n  const $evenImagVals = $evenComplex.imag;\n\n  const $evenShape = [$evenRealVals.length];\n\n  const $evenRealInfo =\n      cpuBackend.makeTensorInfo($evenShape, 'float32', $evenRealVals);\n  const $evenImagInfo =\n      cpuBackend.makeTensorInfo($evenShape, 'float32', $evenImagVals);\n\n  const $evenTensorInfo = complex({\n    inputs: {real: $evenRealInfo, imag: $evenImagInfo},\n    backend: cpuBackend\n  });\n\n  const $oddComplex =\n      fftRadix2(oddRealVals, oddImagVals, half, inverse, cpuBackend);\n\n  const $oddRealVals = $oddComplex.real;\n  const $oddImagVals = $oddComplex.imag;\n\n  const $oddShape = [$oddRealVals.length];\n\n  const $oddRealInfo =\n      cpuBackend.makeTensorInfo($oddShape, 'float32', $oddRealVals);\n  const $oddImagInfo =\n      cpuBackend.makeTensorInfo($oddShape, 'float32', $oddImagVals);\n\n  const $oddTensorInfo = complex(\n      {inputs: {real: $oddRealInfo, imag: $oddImagInfo}, backend: cpuBackend});\n\n  const e = backend_util.exponents(size, inverse);\n  const eShape = [e.real.length];\n\n  const eRealInfo = cpuBackend.makeTensorInfo(eShape, 'float32', e.real);\n  const eImagInfo = cpuBackend.makeTensorInfo(eShape, 'float32', e.imag);\n\n  const complexInfo = complex(\n      {inputs: {real: eRealInfo, imag: eImagInfo}, backend: cpuBackend});\n\n  const exponentInfo =\n      multiply(\n          {inputs: {a: complexInfo, b: $oddTensorInfo}, backend: cpuBackend}) as\n      TensorInfo;\n\n  const addPart = add({\n                    inputs: {a: $evenTensorInfo, b: exponentInfo},\n                    backend: cpuBackend\n                  }) as TensorInfo;\n  const subPart = sub({\n                    inputs: {a: $evenTensorInfo, b: exponentInfo},\n                    backend: cpuBackend\n                  }) as TensorInfo;\n\n  const addPartReal = real({inputs: {input: addPart}, backend: cpuBackend});\n  const subPartReal = real({inputs: {input: subPart}, backend: cpuBackend});\n\n  const addPartImag = imag({inputs: {input: addPart}, backend: cpuBackend});\n  const subPartImag = imag({inputs: {input: subPart}, backend: cpuBackend});\n\n  const $real = concat({\n    inputs: [addPartReal as Tensor, subPartReal as Tensor],\n    backend: cpuBackend,\n    attrs: {axis: 0}\n  });\n  const $imag = concat({\n    inputs: [addPartImag as Tensor, subPartImag as Tensor],\n    backend: cpuBackend,\n    attrs: {axis: 0}\n  });\n\n  const $realVals = cpuBackend.data.get($real.dataId).values as Float32Array;\n  const $imagVals = cpuBackend.data.get($imag.dataId).values as Float32Array;\n\n  cpuBackend.disposeIntermediateTensorInfo(evenRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo(evenImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo(evenTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo(oddRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo(oddImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo(oddTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo($evenRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo($evenImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo($evenTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo($oddRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo($oddImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo($oddTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo(eRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo(eImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo(complexInfo);\n  cpuBackend.disposeIntermediateTensorInfo(exponentInfo);\n  cpuBackend.disposeIntermediateTensorInfo(addPart);\n  cpuBackend.disposeIntermediateTensorInfo(subPart);\n  cpuBackend.disposeIntermediateTensorInfo(addPartReal);\n  cpuBackend.disposeIntermediateTensorInfo(addPartImag);\n  cpuBackend.disposeIntermediateTensorInfo(subPartReal);\n  cpuBackend.disposeIntermediateTensorInfo(subPartImag);\n  cpuBackend.disposeIntermediateTensorInfo($real);\n  cpuBackend.disposeIntermediateTensorInfo($imag);\n\n  return {real: $realVals, imag: $imagVals};\n}\n\n// Calculate fourier transform by multplying sinusoid matrix.\nfunction fourierTransformByMatmul(\n    data: TypedArray, size: number, inverse: boolean): TypedArray {\n  const ret = new Float32Array(size * 2);\n  // TODO: Use matmul instead once it supports complex64 type.\n  for (let r = 0; r < size; r++) {\n    let real = 0.0;\n    let imag = 0.0;\n    for (let c = 0; c < size; c++) {\n      const e = backend_util.exponent(r * c, size, inverse);\n      const term = backend_util.getComplexWithIndex(data as Float32Array, c);\n      real += term.real * e.real - term.imag * e.imag;\n      imag += term.real * e.imag + term.imag * e.real;\n    }\n    if (inverse) {\n      real /= size;\n      imag /= size;\n    }\n    backend_util.assignToTypedArray(ret, real, imag, r);\n  }\n  return ret;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FFT, FFTInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {fftBatch} from '../utils/fft_utils';\nimport {reshape} from './Reshape';\n\nexport function fft(args: {inputs: FFTInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const inputSize = util.sizeFromShape(input.shape);\n\n  // Collapse all outer dimensions to a single batch dimension.\n  const innerDimensionSize = input.shape[input.shape.length - 1];\n  const batch = inputSize / innerDimensionSize;\n\n  const input2D = reshape({\n    inputs: {x: input},\n    backend,\n    attrs: {shape: [batch, innerDimensionSize]}\n  });\n\n  const result = fftBatch(input2D, false, backend);\n\n  const resultReshaped =\n      reshape({inputs: {x: result}, backend, attrs: {shape: input.shape}});\n\n  backend.disposeIntermediateTensorInfo(input2D);\n  backend.disposeIntermediateTensorInfo(result);\n\n  return resultReshaped;\n}\n\nexport const fftConfig: KernelConfig = {\n  kernelName: FFT,\n  backendName: 'cpu',\n  kernelFunc: fft as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {FlipLeftRight, FlipLeftRightInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const flipLeftRightConfig: KernelConfig = {\n  kernelName: FlipLeftRight,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {image} = inputs as FlipLeftRightInputs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const output = util.getTypedArrayFromDType(\n        image.dtype as NumericDataType, util.sizeFromShape(image.shape));\n    const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n\n    const imageVals = cpuBackend.data.get(image.dataId).values as TypedArray;\n\n    for (let batchIdx = 0; batchIdx < batch; batchIdx++) {\n      const batchOffset = batchIdx * imageWidth * imageHeight * numChannels;\n\n      for (let row = 0; row < imageHeight; row++) {\n        const rowOffset = row * (imageWidth * numChannels);\n\n        for (let col = 0; col < imageWidth; col++) {\n          const colOffset = col * numChannels;\n\n          for (let channel = 0; channel < numChannels; channel++) {\n            const coords = [batch, row, col, channel];\n\n            const x = coords[2];\n\n            const coordX = Math.round(imageWidth - x);\n            const outIdx = batchOffset + rowOffset + colOffset + channel;\n\n            let outputValue = imageVals[outIdx];\n            // If the coordinate position falls within the image boundaries...\n            if (coordX >= 0 && coordX < imageWidth) {\n              // set the output to the image value at the coordinate position.\n              const rotatedColOffset = coordX * numChannels;\n              const imageIdx =\n                  batchOffset + rowOffset + rotatedColOffset + channel;\n              outputValue = imageVals[imageIdx];\n            }\n            output[outIdx] = outputValue;\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(output, image.shape, image.dtype);\n    return {dataId, shape: image.shape, dtype: image.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IFFT, IFFTInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {fftBatch} from '../utils/fft_utils';\nimport {reshape} from './Reshape';\n\nexport function ifft(args: {inputs: IFFTInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const inputSize = util.sizeFromShape(input.shape);\n\n  // Collapse all outer dimensions to a single batch dimension.\n  const innerDimensionSize = input.shape[input.shape.length - 1];\n  const batch = inputSize / innerDimensionSize;\n\n  const input2D = reshape({\n    inputs: {x: input},\n    backend,\n    attrs: {shape: [batch, innerDimensionSize]}\n  });\n\n  const result = fftBatch(input2D, true, backend);\n\n  const resultReshaped =\n      reshape({inputs: {x: result}, backend, attrs: {shape: input.shape}});\n\n  backend.disposeIntermediateTensorInfo(input2D);\n  backend.disposeIntermediateTensorInfo(result);\n\n  return resultReshaped;\n}\n\nexport const ifftConfig: KernelConfig = {\n  kernelName: IFFT,\n  backendName: 'cpu',\n  kernelFunc: ifft as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsFinite, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const isFiniteKernelFunc =\n    unaryKernelFunc(IsFinite, (xi) => Number.isFinite(xi) ? 1 : 0, 'bool');\n\nexport const isFiniteConfig: KernelConfig = {\n  kernelName: IsFinite,\n  backendName: 'cpu',\n  kernelFunc: isFiniteKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsInf, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const isInfKernelFunc =\n    unaryKernelFunc(IsInf, (xi) => Math.abs(xi) === Infinity ? 1 : 0, 'bool');\n\nexport const isInfConfig: KernelConfig = {\n  kernelName: IsInf,\n  backendName: 'cpu',\n  kernelFunc: isInfKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsNan, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const isNaNKernelFunc =\n    unaryKernelFunc(IsNan, (xi) => Number.isNaN(xi) ? 1 : 0, 'bool');\n\nexport const isNaNConfig: KernelConfig = {\n  kernelName: IsNan,\n  backendName: 'cpu',\n  kernelFunc: isNaNKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Log1p} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const log1pKernelFunc = unaryKernelFunc(Log1p, (xi) => Math.log1p(xi));\n\nexport const log1pConfig: KernelConfig = {\n  kernelName: Log1p,\n  backendName: 'cpu',\n  kernelFunc: log1pKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LogicalNot} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const logicalNotKernelFunc =\n    unaryKernelFunc(LogicalNot, (xi) => xi ? 0 : 1, 'bool');\n\nexport const logicalNotConfig: KernelConfig = {\n  kernelName: LogicalNot,\n  backendName: 'cpu',\n  kernelFunc: logicalNotKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Max, MaxAttrs, MaxInputs} from '@tensorflow/tfjs-core';\nimport {backend_util, KernelConfig} from '@tensorflow/tfjs-core';\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {maxImpl} from './Max_impl';\nimport {transposeImpl} from './Transpose_impl';\n\nexport const maxConfig: KernelConfig = {\n  kernelName: Max,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {x} = inputs as MaxInputs;\n    const {reductionIndices, keepDims} = attrs as {} as MaxAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n    let xShape = x.shape;\n    const xRank = xShape.length;\n\n    const origAxes = util.parseAxisParam(reductionIndices, xShape);\n    let axes = origAxes;\n    const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n    let xVals = cpuBackend.data.get(x.dataId).values as TypedArray;\n    if (permutedAxes != null) {\n      const newShape: number[] = new Array(xRank);\n      for (let i = 0; i < newShape.length; i++) {\n        newShape[i] = xShape[permutedAxes[i]];\n      }\n\n      xVals = transposeImpl(xVals, xShape, x.dtype, permutedAxes, newShape);\n      axes = backend_util.getInnerMostAxes(axes.length, xRank);\n\n      xShape = newShape;\n    }\n\n    assertNotComplex(x, 'max');\n    backend_util.assertAxesAreInnerMostDims('max', axes, xRank);\n    const [maxOutShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(xShape, axes);\n\n    const reduceSize = util.sizeFromShape(reduceShape);\n\n    const result = maxImpl(xVals, reduceSize, maxOutShape, x.dtype);\n    const dataId = cpuBackend.write(result, maxOutShape, x.dtype);\n\n    let outShape = maxOutShape;\n    if (keepDims) {\n      // reshape\n      const newShape = backend_util.expandShapeToKeepDim(maxOutShape, origAxes);\n      outShape = newShape;\n    }\n\n    return {dataId, shape: outShape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, KernelConfig, KernelFunc, MaxPool, MaxPoolAttrs, MaxPoolInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {pool} from '../utils/pool_utils';\nimport {identity} from './Identity';\n\nexport function maxPool(\n    args:\n        {inputs: MaxPoolInputs, backend: MathBackendCPU, attrs: MaxPoolAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  assertNotComplex(x, 'maxPool');\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n  const dilations = 1;\n\n  util.assert(\n      backend_util.eitherStridesOrDilationsAreOne(strides, dilations),\n      () => 'Error in maxPool: Either strides or dilations must be 1. ' +\n          `Got strides ${strides} and dilations '${dilations}'`);\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode);\n  let res: TensorInfo;\n\n  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 &&\n      util.arraysEqual(convInfo.inShape, convInfo.outShape)) {\n    res = identity({inputs: {x}, backend});\n  } else {\n    const xValues = backend.data.get(x.dataId).values as TypedArray;\n    const strides = util.computeStrides(x.shape);\n    const buffer = pool(xValues, x.shape, x.dtype, strides, convInfo, 'max');\n    res = backend.makeTensorInfo(\n        convInfo.outShape, x.dtype, buffer.values as TypedArray);\n  }\n  return res;\n}\n\nexport const maxPoolConfig: KernelConfig = {\n  kernelName: MaxPool,\n  backendName: 'cpu',\n  kernelFunc: maxPool as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, buffer, KernelConfig, KernelFunc, MaxPoolBackprop, MaxPoolBackpropAttrs, MaxPoolBackpropInputs, Rank, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {maxPoolPositions} from '../utils/pool_utils';\n\nexport function maxPoolBackprop(args: {\n  inputs: MaxPoolBackpropInputs,\n  backend: MathBackendCPU,\n  attrs: MaxPoolBackpropAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input, output} = inputs;\n  const x = input;\n  assertNotComplex([input, output], 'maxPoolBackprop');\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad, dimRoundingMode);\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const maxPosBuf = buffer(\n      convInfo.outShape, x.dtype,\n      maxPoolPositions(xValues, x.shape, x.dtype, convInfo).values);\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n  const dx =\n      buffer<Rank.R4>(x.shape as [number, number, number, number], 'float32');\n\n  const dyData = backend.data.get(dy.dataId).values as Float32Array;\n  const dyBuf = buffer<Rank.R4>(\n      dy.shape as [number, number, number, number], 'float32', dyData);\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n        for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n          // Shader code begins.\n          const dyRCorner = dxR - padTop;\n          const dyCCorner = dxC - padLeft;\n          let dotProd = 0;\n          for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {\n            const dyR = (dyRCorner + wR) / strideHeight;\n            if (dyR < 0 || dyR >= convInfo.outHeight ||\n                Math.floor(dyR) !== dyR) {\n              continue;\n            }\n            for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {\n              const dyC = (dyCCorner + wC) / strideWidth;\n              if (dyC < 0 || dyC >= convInfo.outWidth ||\n                  Math.floor(dyC) !== dyC) {\n                continue;\n              }\n              const maxPos = effectiveFilterHeight * effectiveFilterWidth - 1 -\n                  (maxPosBuf.get(b, dyR, dyC, d) as number);\n              const curPos = wR * effectiveFilterWidth + wC;\n\n              const mask = maxPos === curPos ? 1 : 0;\n              if (mask === 0) {\n                continue;\n              }\n\n              const pixel = dyBuf.get(b, dyR, dyC, d);\n              dotProd += pixel * mask;\n            }\n          }\n          dx.set(dotProd, b, dxR, dxC, d);\n        }\n      }\n    }\n  }\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const maxPoolBackpropConfig: KernelConfig = {\n  kernelName: MaxPoolBackprop,\n  backendName: 'cpu',\n  kernelFunc: maxPoolBackprop as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {MaxPoolWithArgmax, MaxPoolWithArgmaxAttrs, MaxPoolWithArgmaxInputs} from '@tensorflow/tfjs-core';\nimport {backend_util, KernelConfig, TypedArray} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {maxPoolWithArgmaxImpl} from './MaxPoolWithArgmax_impl';\n\nexport const maxPoolWithArgmaxConfig: KernelConfig = {\n  kernelName: MaxPoolWithArgmax,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {x} = inputs as MaxPoolWithArgmaxInputs;\n    const {filterSize, strides, pad, includeBatchInIndex} =\n        attrs as {} as MaxPoolWithArgmaxAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n    assertNotComplex(x, 'MaxPoolWithArgmax');\n\n    const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const convInfo = backend_util.computePool2DInfo(\n        x.shape as [number, number, number, number], filterSize, strides,\n        [1, 1], pad);\n    const [pooled, indexes] = maxPoolWithArgmaxImpl(\n        values, x.shape, x.dtype, includeBatchInIndex, convInfo);\n\n    const pooledDataId =\n        cpuBackend.write(pooled as Float32Array, convInfo.outShape, x.dtype);\n    const indexesDataId =\n        cpuBackend.write(indexes as Int32Array, convInfo.outShape, x.dtype);\n    return [\n      {dataId: pooledDataId, shape: convInfo.outShape, dtype: x.dtype},\n      {dataId: indexesDataId, shape: convInfo.outShape, dtype: 'int32'}\n    ];\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {maxPoolPositions, pool} from '../utils/pool_utils';\nexport function maxPoolWithArgmaxImpl(\n    xValues: TypedArray, xShape: number[], dtype: DataType,\n    includeBatchInIndex: boolean, convInfo: backend_util.Conv2DInfo) {\n  const strides = util.computeStrides(xShape);\n  const maxPools = pool(xValues, xShape, dtype, strides, convInfo, 'max');\n  const maxPositions = maxPoolPositions(\n      xValues, xShape, dtype, convInfo, true, includeBatchInIndex);\n\n  return [maxPools.values, maxPositions.values];\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NonMaxSuppressionV4, NonMaxSuppressionV4Attrs, NonMaxSuppressionV4Inputs} from '@tensorflow/tfjs-core';\nimport {KernelConfig, TypedArray} from '@tensorflow/tfjs-core';\nimport {kernel_impls} from '@tensorflow/tfjs-core';\nconst nonMaxSuppressionV4Impl = kernel_impls.nonMaxSuppressionV4Impl;\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport const nonMaxSuppressionV4Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV4,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {boxes, scores} = inputs as NonMaxSuppressionV4Inputs;\n    const {maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize} =\n        attrs as unknown as NonMaxSuppressionV4Attrs;\n\n    const cpuBackend = backend as MathBackendCPU;\n\n    assertNotComplex(boxes, 'NonMaxSuppressionPadded');\n\n    const boxesVals = cpuBackend.data.get(boxes.dataId).values as TypedArray;\n    const scoresVals = cpuBackend.data.get(scores.dataId).values as TypedArray;\n\n    const {selectedIndices, validOutputs} = nonMaxSuppressionV4Impl(\n        boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold,\n        padToMaxOutputSize);\n\n    return [selectedIndices, validOutputs];\n  }\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NonMaxSuppressionV5, NonMaxSuppressionV5Attrs, NonMaxSuppressionV5Inputs} from '@tensorflow/tfjs-core';\nimport {KernelConfig, TypedArray} from '@tensorflow/tfjs-core';\nimport {kernel_impls} from '@tensorflow/tfjs-core';\nconst nonMaxSuppressionV5Impl = kernel_impls.nonMaxSuppressionV5Impl;\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport const nonMaxSuppressionV5Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV5,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {boxes, scores} = inputs as NonMaxSuppressionV5Inputs;\n    const {maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma} =\n        attrs as unknown as NonMaxSuppressionV5Attrs;\n\n    const cpuBackend = backend as MathBackendCPU;\n\n    assertNotComplex(boxes, 'NonMaxSuppressionWithScore');\n\n    const boxesVals = cpuBackend.data.get(boxes.dataId).values as TypedArray;\n    const scoresVals = cpuBackend.data.get(scores.dataId).values as TypedArray;\n\n    const maxOutputSizeVal = maxOutputSize;\n    const iouThresholdVal = iouThreshold;\n    const scoreThresholdVal = scoreThreshold;\n    const softNmsSigmaVal = softNmsSigma;\n\n    const {selectedIndices, selectedScores} = nonMaxSuppressionV5Impl(\n        boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal,\n        scoreThresholdVal, softNmsSigmaVal);\n\n    return [selectedIndices, selectedScores];\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NotEqual} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/kernel_utils';\n\nexport const notEqualImpl =\n    createSimpleBinaryKernelImpl(((a, b) => (a !== b) ? 1 : 0));\nexport const notEqual =\n    binaryKernelFunc(NotEqual, notEqualImpl, null /* complexOp */, 'bool');\n\nexport const notEqualConfig: KernelConfig = {\n  kernelName: NotEqual,\n  backendName: 'cpu',\n  kernelFunc: notEqual\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, NumericDataType, PadV2, PadV2Attrs, PadV2Inputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function padV2(\n    args: {inputs: PadV2Inputs, backend: MathBackendCPU, attrs: PadV2Attrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {paddings, constantValue} = attrs;\n\n  assertNotComplex(x, 'pad');\n\n  const outShape = paddings.map(\n      (p, i) => p[0] /* beforePad */ + x.shape[i] + p[1] /* afterPad */);\n\n  const start = paddings.map(p => p[0]);\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const xSize = util.sizeFromShape(x.shape);\n  const xRank = x.shape.length;\n  const xStrides = util.computeStrides(x.shape);\n\n  const resultSize = util.sizeFromShape(outShape);\n  const resultRank = outShape.length;\n  const resultStrides = util.computeStrides(outShape);\n  const resVals =\n      util.getTypedArrayFromDType(x.dtype as NumericDataType, resultSize);\n\n  if (constantValue !== 0) {\n    resVals.fill(constantValue);\n  }\n\n  for (let i = 0; i < xSize; i++) {\n    const coords = util.indexToLoc(i, xRank, xStrides);\n    const outCoords = coords.map((c, i) => c + start[i]);\n    const outIndex = util.locToIndex(outCoords, resultRank, resultStrides);\n\n    resVals[outIndex] = xVals[i];\n  }\n\n  const outId = backend.write(resVals, outShape, x.dtype);\n\n  return {dataId: outId, shape: outShape, dtype: x.dtype};\n}\n\nexport const padV2Config: KernelConfig = {\n  kernelName: PadV2,\n  backendName: 'cpu',\n  kernelFunc: padV2 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Reciprocal} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const reciprocalKernelFunc = unaryKernelFunc(Reciprocal, (xi) => 1 / xi);\n\nexport const reciprocalConfig: KernelConfig = {\n  kernelName: Reciprocal,\n  backendName: 'cpu',\n  kernelFunc: reciprocalKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {backend_util, RotateWithOffset, RotateWithOffsetAttrs, RotateWithOffsetInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const rotateWithOffsetConfig: KernelConfig = {\n  kernelName: RotateWithOffset,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {image} = inputs as RotateWithOffsetInputs;\n    const {radians, fillValue, center} = attrs as {} as RotateWithOffsetAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const output = util.getTypedArrayFromDType(\n        image.dtype as NumericDataType, util.sizeFromShape(image.shape));\n    const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n\n    const [centerX, centerY] =\n        backend_util.getImageCenter(center, imageHeight, imageWidth);\n    const fullOpacityValue = 255;\n\n    const sinFactor = Math.sin(radians);\n    const cosFactor = Math.cos(radians);\n    const imageVals = cpuBackend.data.get(image.dataId).values as TypedArray;\n\n    for (let batchIdx = 0; batchIdx < batch; batchIdx++) {\n      const batchOffset = batchIdx * imageWidth * imageHeight * numChannels;\n\n      for (let row = 0; row < imageHeight; row++) {\n        const rowOffset = row * (imageWidth * numChannels);\n\n        for (let col = 0; col < imageWidth; col++) {\n          const colOffset = col * numChannels;\n\n          for (let channel = 0; channel < numChannels; channel++) {\n            const coords = [batch, row, col, channel];\n\n            const x = coords[2];\n            const y = coords[1];\n\n            // coordX/coordY are the result of rotating and translating x/y.\n            let coordX = (x - centerX) * cosFactor - (y - centerY) * sinFactor;\n            let coordY = (x - centerX) * sinFactor + (y - centerY) * cosFactor;\n            coordX = Math.round(coordX + centerX);\n            coordY = Math.round(coordY + centerY);\n\n            let outputValue = fillValue;\n            if (typeof fillValue !== 'number') {\n              if (channel === 3) {\n                outputValue = fullOpacityValue;\n              } else {\n                outputValue = fillValue[channel];\n              }\n            }\n\n            // If the coordinate position falls within the image boundaries...\n            if (coordX >= 0 && coordX < imageWidth && coordY >= 0 &&\n                coordY < imageHeight) {\n              // set the output to the image value at the coordinate position.\n              const rotatedRowOffset = coordY * (imageWidth * numChannels);\n              const rotatedColOffset = coordX * numChannels;\n              const imageIdx =\n                  batchOffset + rotatedRowOffset + rotatedColOffset + channel;\n              outputValue = imageVals[imageIdx];\n            }\n\n            const outIdx = batchOffset + rowOffset + colOffset + channel;\n            output[outIdx] = outputValue as number;\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(output, image.shape, image.dtype);\n    return {dataId, shape: image.shape, dtype: image.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Round} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const roundKernelFunc = unaryKernelFunc(Round, (xi) => {\n  // The algorithm is based on banker's rounding.\n  const base = Math.floor(xi);\n  if (xi - base < 0.5) {\n    return Math.floor(xi);\n  } else if (xi - base > 0.5) {\n    return Math.ceil(xi);\n  } else {\n    if (base % 2.0 === 0.0) {\n      return base;\n    } else {\n      return base + 1.0;\n    }\n  }\n});\n\nexport const roundConfig: KernelConfig = {\n  kernelName: Round,\n  backendName: 'cpu',\n  kernelFunc: roundKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, Selu} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nconst scaleAlpha = backend_util.SELU_SCALEALPHA;\nconst scale = backend_util.SELU_SCALE;\n\nexport const seluKernelFunc = unaryKernelFunc(Selu, (xi) => {\n  if (xi >= 0) {\n    return scale * xi;\n  } else {\n    return scaleAlpha * (Math.exp(xi) - 1);\n  }\n});\n\nexport const seluConfig: KernelConfig = {\n  kernelName: Selu,\n  backendName: 'cpu',\n  kernelFunc: seluKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sigmoid} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sigmoidKernelFunc =\n    unaryKernelFunc(Sigmoid, (xi) => 1 / (1 + Math.exp(-xi)));\n\nexport const sigmoidConfig: KernelConfig = {\n  kernelName: Sigmoid,\n  backendName: 'cpu',\n  kernelFunc: sigmoidKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sign} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const signKernelFunc = unaryKernelFunc(Sign, (xi) => {\n  if (xi < 0) {\n    return -1;\n  } else if (xi > 0) {\n    return 1;\n  } else {\n    return 0;\n  }\n});\n\nexport const signConfig: KernelConfig = {\n  kernelName: Sign,\n  backendName: 'cpu',\n  kernelFunc: signKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sin} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sinKernelFunc = unaryKernelFunc(Sin, (xi) => Math.sin(xi));\n\nexport const sinConfig: KernelConfig = {\n  kernelName: Sin,\n  backendName: 'cpu',\n  kernelFunc: sinKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sinh} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sinhKernelFunc = unaryKernelFunc(Sinh, (xi) => Math.sinh(xi));\n\nexport const sinhConfig: KernelConfig = {\n  kernelName: Sinh,\n  backendName: 'cpu',\n  kernelFunc: sinhKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Softplus} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\n// mirrors the implementation of tf.nn.softplus: https://goo.gl/vkcvwX\n\n// epsilon is the difference between 1.0 and the next representable float.\n// For a single precision 32 bit float this should be 2^-23, see:\n// https://math.byu.edu/~schow/work/IEEEFloatingPoint.htm\nconst epsilon = 1.1920928955078125e-7;\nconst threshold = Math.log(epsilon) + 2.0;\n\nexport const softplusKernelFunc = unaryKernelFunc(Softplus, (xi) => {\n  // Value above which exp(x) may overflow, but softplus(x) == x\n  // is within machine epsilon.\n  const tooLarge = xi > -threshold;\n\n  // Value below which exp(x) may underflow, but softplus(x) == exp(x)\n  // is within machine epsilon.\n  const tooSmall = xi < threshold;\n\n  const expX = Math.exp(xi);\n  let result;\n\n  if (tooSmall) {\n    result = expX;\n  } else if (tooLarge) {\n    result = xi;\n  } else {\n    result = Math.log(1.0 + expX);\n  }\n  return result;\n});\n\nexport const softplusConfig: KernelConfig = {\n  kernelName: Softplus,\n  backendName: 'cpu',\n  kernelFunc: softplusKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Transpose, TransposeAttrs, TransposeInputs, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {transposeImpl} from './Transpose_impl';\n\nexport function transpose(args: {\n  inputs: TransposeInputs,\n  attrs: TransposeAttrs,\n  backend: MathBackendCPU\n}): TensorInfo {\n  const {inputs, attrs, backend} = args;\n  const {x} = inputs;\n  const {perm} = attrs;\n\n  assertNotComplex(x, 'transpose');\n\n  const xRank = x.shape.length;\n\n  const newShape: number[] = new Array(xRank);\n  for (let i = 0; i < newShape.length; i++) {\n    newShape[i] = x.shape[perm[i]];\n  }\n\n  const values = backend.data.get(x.dataId).values as TypedArray;\n  const result = transposeImpl(values, x.shape, x.dtype, perm, newShape);\n\n  const dataId = backend.write(result, newShape, x.dtype);\n  return {dataId, shape: newShape, dtype: x.dtype};\n}\n\nexport const transposeConfig: KernelConfig = {\n  kernelName: Transpose,\n  backendName: 'cpu',\n  kernelFunc: transpose as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, ReshapeAttrs, ReshapeInputs, SpaceToBatchND, SpaceToBatchNDAttrs, SpaceToBatchNDInputs, TensorInfo, TransposeAttrs, TransposeInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {padV2Config} from './PadV2';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\nexport function spaceToBatchND(args: {\n  inputs: SpaceToBatchNDInputs,\n  backend: MathBackendCPU,\n  attrs: SpaceToBatchNDAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockShape, paddings} = attrs;\n\n  assertNotComplex([x], 'spaceToBatchND');\n\n  const prod = util.sizeFromShape(blockShape);\n\n  const completePaddings: Array<[number, number]> = [[0, 0]];\n  completePaddings.push(...(paddings as Array<[number, number]>));\n\n  for (let i = 1 + blockShape.length; i < x.shape.length; ++i) {\n    completePaddings.push([0, 0]);\n  }\n\n  const paddedX = padV2Config.kernelFunc({\n    inputs: {x},\n    backend,\n    attrs: {paddings: completePaddings, constantValue: 0}\n  }) as TensorInfo;\n\n  const reshapedPaddedShape =\n      backend_util.getReshaped(paddedX.shape, blockShape, prod, false);\n\n  const permutedReshapedPaddedPermutation = backend_util.getPermuted(\n      reshapedPaddedShape.length, blockShape.length, false);\n\n  const flattenShape =\n      backend_util.getReshapedPermuted(paddedX.shape, blockShape, prod, false);\n\n  const reshapeInputs: ReshapeInputs = {x: paddedX};\n  const reshapeAttrs: ReshapeAttrs = {shape: reshapedPaddedShape};\n  const paddedXReshaped =\n      reshape({inputs: reshapeInputs, backend, attrs: reshapeAttrs});\n\n  const transposeInputs: TransposeInputs = {x: paddedXReshaped};\n  const transposeAttrs:\n      TransposeAttrs = {perm: permutedReshapedPaddedPermutation};\n  const paddedXT =\n      transpose({inputs: transposeInputs, backend, attrs: transposeAttrs});\n\n  const resultReshapeInputs: ReshapeInputs = {x: paddedXT};\n  const resultReshapeAttrs: ReshapeAttrs = {shape: flattenShape};\n  const result = reshape(\n      {inputs: resultReshapeInputs, backend, attrs: resultReshapeAttrs});\n\n  backend.disposeIntermediateTensorInfo(paddedX);\n  backend.disposeIntermediateTensorInfo(paddedXReshaped);\n  backend.disposeIntermediateTensorInfo(paddedXT);\n\n  return result;\n}\n\nexport const spaceToBatchNDConfig: KernelConfig = {\n  kernelName: SpaceToBatchND,\n  backendName: 'cpu',\n  kernelFunc: spaceToBatchND as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sqrt} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sqrtKernelFunc = unaryKernelFunc(Sqrt, (xi) => Math.sqrt(xi));\n\nexport const sqrtConfig: KernelConfig = {\n  kernelName: Sqrt,\n  backendName: 'cpu',\n  kernelFunc: sqrtKernelFunc,\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Square, SquareInputs} from '@tensorflow/tfjs-core';\nimport {KernelConfig} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport const squareConfig: KernelConfig = {\n  kernelName: Square,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend}) => {\n    const {x} = inputs as SquareInputs;\n    const cpuBackend = backend as MathBackendCPU;\n    assertNotComplex(x, 'square');\n\n    const values = cpuBackend.data.get(x.dataId).values as Float32Array;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      newValues[i] = value * value;\n    }\n    const dataId = cpuBackend.write(newValues, x.shape, x.dtype);\n    return {dataId, shape: x.shape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, SquaredDifference} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/kernel_utils';\n\nexport const squaredDifferenceImpl = createSimpleBinaryKernelImpl(((a, b) => {\n  const diff = a - b;\n  return diff * diff;\n}));\nexport const squaredDifference =\n    binaryKernelFunc(SquaredDifference, squaredDifferenceImpl);\n\nexport const squaredDifferenceConfig: KernelConfig = {\n  kernelName: SquaredDifference,\n  backendName: 'cpu',\n  kernelFunc: squaredDifference\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Step, StepAttrs} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const stepKernelFunc = unaryKernelFunc(Step, (xi, attrs) => {\n  const stepAttrs = attrs as {} as StepAttrs;\n  if (isNaN(xi)) {\n    return NaN;\n  } else {\n    return xi > 0 ? 1 : stepAttrs.alpha;\n  }\n});\n\nexport const stepConfig: KernelConfig = {\n  kernelName: Step,\n  backendName: 'cpu',\n  kernelFunc: stepKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Tan} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const tanKernelFunc = unaryKernelFunc(Tan, (xi) => Math.tan(xi));\n\nexport const tanConfig: KernelConfig = {\n  kernelName: Tan,\n  backendName: 'cpu',\n  kernelFunc: tanKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Tanh} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const tanhKernelFunc = unaryKernelFunc(Tanh, (xi) => Math.tanh(xi));\n\nexport const tanhConfig: KernelConfig = {\n  kernelName: Tanh,\n  backendName: 'cpu',\n  kernelFunc: tanhKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// We explicitly import the modular kernels so they get registered in the\n// global registry when we compile the library. A modular build would replace\n// the contents of this file and import only the kernels that are needed.\nimport {KernelConfig, registerKernel} from '@tensorflow/tfjs-core';\n\nimport {absConfig} from './kernels/Abs';\nimport {acosConfig} from './kernels/Acos';\nimport {acoshConfig} from './kernels/Acosh';\nimport {addConfig} from './kernels/Add';\nimport {asinConfig} from './kernels/Asin';\nimport {asinhConfig} from './kernels/Asinh';\nimport {atanConfig} from './kernels/Atan';\nimport {atanhConfig} from './kernels/Atanh';\nimport {avgPoolConfig} from './kernels/AvgPool';\nimport {avgPoolBackpropConfig} from './kernels/AvgPoolBackprop';\nimport {batchNormConfig} from './kernels/BatchNorm';\nimport {castConfig} from './kernels/Cast';\nimport {ceilConfig} from './kernels/Ceil';\nimport {clipConfig} from './kernels/Clip';\nimport {complexConfig} from './kernels/Complex';\nimport {concatConfig} from './kernels/Concat';\nimport {cosConfig} from './kernels/Cos';\nimport {coshConfig} from './kernels/Cosh';\nimport {dilation2dConfig} from './kernels/Dilation2D';\nimport {dilation2dBackpropFilterConfig} from './kernels/Dilation2DBackpropFilter';\nimport {dilation2dBackpropInputConfig} from './kernels/Dilation2DBackpropInput';\nimport {divConfig} from './kernels/Div';\nimport {eluConfig} from './kernels/Elu';\nimport {erfConfig} from './kernels/Erf';\nimport {expConfig} from './kernels/Exp';\nimport {expm1Config} from './kernels/Expm1';\nimport {fftConfig} from './kernels/FFT';\nimport {flipLeftRightConfig} from './kernels/FlipLeftRight';\nimport {floorConfig} from './kernels/Floor';\nimport {identityConfig} from './kernels/Identity';\nimport {ifftConfig} from './kernels/IFFT';\nimport {imagConfig} from './kernels/Imag';\nimport {isFiniteConfig} from './kernels/IsFinite';\nimport {isInfConfig} from './kernels/IsInf';\nimport {isNaNConfig} from './kernels/IsNaN';\nimport {logConfig} from './kernels/Log';\nimport {log1pConfig} from './kernels/Log1p';\nimport {logicalNotConfig} from './kernels/LogicalNot';\nimport {maxConfig} from './kernels/Max';\nimport {maxPoolConfig} from './kernels/MaxPool';\nimport {maxPoolBackpropConfig} from './kernels/MaxPoolBackprop';\nimport {maxPoolWithArgmaxConfig} from './kernels/MaxPoolWithArgmax';\nimport {multiplyConfig} from './kernels/Multiply';\nimport {nonMaxSuppressionV4Config} from './kernels/NonMaxSuppressionV4';\nimport {nonMaxSuppressionV5Config} from './kernels/NonMaxSuppressionV5';\nimport {notEqualConfig} from './kernels/NotEqual';\nimport {padV2Config} from './kernels/PadV2';\nimport {realConfig} from './kernels/Real';\nimport {reciprocalConfig} from './kernels/Reciprocal';\nimport {reshapeConfig} from './kernels/Reshape';\nimport {rotateWithOffsetConfig} from './kernels/RotateWithOffset';\nimport {roundConfig} from './kernels/Round';\nimport {rsqrtConfig} from './kernels/Rsqrt';\nimport {seluConfig} from './kernels/Selu';\nimport {sigmoidConfig} from './kernels/Sigmoid';\nimport {signConfig} from './kernels/Sign';\nimport {sinConfig} from './kernels/Sin';\nimport {sinhConfig} from './kernels/Sinh';\nimport {sliceConfig} from './kernels/Slice';\nimport {softplusConfig} from './kernels/Softplus';\nimport {spaceToBatchNDConfig} from './kernels/SpaceToBatchND';\nimport {sqrtConfig} from './kernels/Sqrt';\nimport {squareConfig} from './kernels/Square';\nimport {squaredDifferenceConfig} from './kernels/SquaredDifference';\nimport {stepConfig} from './kernels/Step';\nimport {subConfig} from './kernels/Sub';\nimport {tanConfig} from './kernels/Tan';\nimport {tanhConfig} from './kernels/Tanh';\nimport {transposeConfig} from './kernels/Transpose';\nimport {uniqueConfig} from './kernels/Unique';\n\n// List all kernel configs here\nconst kernelConfigs: KernelConfig[] = [\n  absConfig,\n  acosConfig,\n  acoshConfig,\n  addConfig,\n  asinConfig,\n  asinhConfig,\n  atanConfig,\n  atanhConfig,\n  avgPoolConfig,\n  avgPoolBackpropConfig,\n  batchNormConfig,\n  castConfig,\n  ceilConfig,\n  clipConfig,\n  complexConfig,\n  concatConfig,\n  cosConfig,\n  coshConfig,\n  dilation2dConfig,\n  dilation2dBackpropInputConfig,\n  dilation2dBackpropFilterConfig,\n  divConfig,\n  eluConfig,\n  erfConfig,\n  expConfig,\n  expm1Config,\n  fftConfig,\n  flipLeftRightConfig,\n  floorConfig,\n  identityConfig,\n  ifftConfig,\n  imagConfig,\n  isFiniteConfig,\n  isInfConfig,\n  isNaNConfig,\n  logConfig,\n  log1pConfig,\n  logicalNotConfig,\n  maxPoolConfig,\n  maxPoolBackpropConfig,\n  maxPoolWithArgmaxConfig,\n  maxConfig,\n  multiplyConfig,\n  nonMaxSuppressionV4Config,\n  nonMaxSuppressionV5Config,\n  notEqualConfig,\n  padV2Config,\n  realConfig,\n  reciprocalConfig,\n  reshapeConfig,\n  rotateWithOffsetConfig,\n  roundConfig,\n  rsqrtConfig,\n  seluConfig,\n  sigmoidConfig,\n  signConfig,\n  sinConfig,\n  sinhConfig,\n  sliceConfig,\n  softplusConfig,\n  spaceToBatchNDConfig,\n  sqrtConfig,\n  squareConfig,\n  squaredDifferenceConfig,\n  stepConfig,\n  subConfig,\n  tanConfig,\n  tanhConfig,\n  transposeConfig,\n  uniqueConfig,\n];\n\nfor (const kernelConfig of kernelConfigs) {\n  registerKernel(kernelConfig);\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Unique, UniqueAttrs, UniqueInputs} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {uniqueImpl} from './Unique_impl';\n\nexport function unique(\n    args: {inputs: UniqueInputs, attrs: UniqueAttrs, backend: MathBackendCPU}):\n    TensorInfo[] {\n  const {inputs, attrs, backend} = args;\n  const {axis} = attrs;\n  const {x} = inputs;\n  assertNotComplex(x, 'unique');\n\n  const values = backend.data.get(x.dataId).values;\n  const {outputValues, outputShape, indices} =\n      uniqueImpl(values, axis, x.shape, x.dtype);\n  return [\n    backend.makeTensorInfo(outputShape, x.dtype, outputValues),\n    backend.makeTensorInfo([indices.length], 'int32', indices),\n  ];\n}\n\nexport const uniqueConfig: KernelConfig = {\n  kernelName: Unique,\n  backendName: 'cpu',\n  kernelFunc: unique as {} as KernelFunc,\n};\n","/** @license See the LICENSE file. */\n\n// This code is auto-generated, do not modify this file!\nconst version = '2.6.0';\nexport {version};\n"],"names":["assertNotComplex","tensor","opName","Array","isArray","forEach","t","util","assert","dtype","nonMaxSuppressionV3Impl","kernel_impls","split","tile","topkImpl","whereImpl","mapActivation","backend","x","activation","preluActivationWeights","linear","relu","tf.elu","relu6","prelu","Error","_super","_this","data","DataStorage","engine","tslib_1.__extends","MathBackendCPU","values","shape","this","firstUse","env","get","backend_util","warn","dataId","set","refCount","write","has","numDataIds","readSync","_a","complexTensorInfos","realValues","real","imagValues","imag","mergeRealAndImagArrays","decodedData","map","d","decodeString","tf.buffer","makeTensorFromDataId","disposeData","delete","tensorInfo","tensorData","f","start","now","kernelMs","unreliable","reasons","begin","end","strides","outShape","slice_util","computeOutShape","some","axis","tf.tensor","buffer","xBuf","bufferSync","i","size","loc","indexToLoc","newLoc","length","j","toTensor","xVals","vals","num","rank","outIndex","fill","slice","res","tf.slice","reshape","outLoc","inLoc","ax","tf.mul","tf.scalar","tensors","result","resultVals","currVals","logits","dim","axes","parseAxisParam","maxLogit","max","expandedShape","expandShapeToKeepDim","a","tf.sub","b","tf.exp","sumExp","sum","tf.div","broadcastedBinaryOp","aValue","bValue","Math","pow","transposeA","transposeB","sharedDim","leftDim","rightDim","batchDim","aValues","bValues","aBatch","aOuterStep","aInnerStep","_b","bInnerStep","bOuterStep","bBatch","resVals","blockSize","b_1","i0","j0","k0","iBlock","min","jBlock","kBlock","k","bias","batchMatMul","tf.add","floor","assertAxesAreInnerMostDims","reduceShape","resultDtype","upcastType","tf.zeros","reduceSize","sizeFromShape","aVals","offset","prod","segmentIds","numSegments","numIters","expandDims","segmentId","tf.equal","asType","mul","push","tf.stack","minIndex","value","max_1","maxIndex","exclusive","reverse","finalDim","indexAdjuster","idx","prevIdx","aVal","bVal","condition","newValues","index","condVals","sorted","rem","all","anyVal","diff","inVals","xValue","dy","y","resultValues","Float32Array","dyValues","v","makeOutput","atan2","input","filter","convInfo","conv2d","filterHeight","filterWidth","dilationHeight","dilationWidth","padLeft","padInfo","left","padTop","top","isChannelsLast","dataFormat","xBatchStride","xRowStride","xColStride","xChannelStride","yBatchStride","yRowStride","yColStride","yChannelStride","wVals","yVals","batchSize","xOffset1","yOffset1","yR","outHeight","yOffset2","xRCorner","strideHeight","wR","xR","inHeight","wOffset1","xOffset2","yC","outWidth","yOffset3","xCCorner","strideWidth","wC","xC","inWidth","xOffset3","wOffset3","d1","inChannels","xVal","d2","outChannels","filterDepth","dilationDepth","padFront","front","yF","outDepth","xFCorner","strideDepth","wF","xF","inDepth","wOffset2","yOffset4","xOffset4","wOffset4","dx","inShape","dxValues","fltValues","fltS0","fltS1","fltS2","topPad","leftPad","xRMin","ceil","yRMax","xCMin","yCMax","dotProd","dyOffset","fltOffset","dxS0","dxS1","dxS2","dxS3","dyS0","dyS1","dyS2","dyS3","_c","fltS3","frontPad","xFMin","yFMax","dW","filterShape","dyBuf","yRMin","yCMin","dw","dwValues","dwS0","dwS1","dwS2","dwS3","xValues","xS0","xS1","xS2","xS3","yFMin","depthwiseConv2D","chMul","q","dm","trunc","reps","indices","newShape","indicesValues","originalLoc","originalIndex","locToIndex","blockShape","crops","reduce","reshaped","getReshaped","permuted","getPermuted","reshapedPermuted","getReshapedPermuted","sliceBeginCoords","getSliceBeginCoords","sliceSize","getSliceSize","tf.transpose","poolType","effectiveFilterDepth","effectiveFilterHeight","effectiveFilterWidth","initialValue","Number","NEGATIVE_INFINITY","POSITIVE_INFINITY","output","outputVals","outputBatchStrides","outputDepthStrides","outputRowStrides","outputColStrides","batch","outputBatchOffset","inputBatchOffset","channel","yDepth","xDepthCorner","xDepthMin","xDepthMax","outputDepthOffset","yRow","xRowCorner","xRowMin","xRowMax","outputRowOffset","yCol","xColCorner","xColMin","xColMax","outputColOffset","minMaxValue","avgValue","count","xDepth","xDepthOffset","xRow","xRowOffset","xCol","pixel","isNaN","pool3d","toFloat","avgMultiplier","dxDepth","dxRow","dxCol","dyDepthCorner","dyRowCorner","dyColCorner","wDepth","dyDepth","wRow","dyRow","wCol","dyCol","maxPositions","maxValue","maxPosition","maxPool3dPositions","maxPosBuf","mask","newHeight","newWidth","alignCorners","oldHeight","oldWidth","numChannels","effectiveInputSize","effectiveOutputSize","outputIdx","effectiveRowSizeRatio","effectiveColSizeRatio","r","sourceFracRow","sourceRowFloor","rowFrac","sourceRowCeil","topRowOffset","botRowOffset","c","sourceFracCol","sourceColFloor","colFrac","sourceColCeil","topLeftOffest","botLeftOffset","topRightOffset","botRightOffest","topLeft","bottomLeft","top_1","newValue","xHeight","xWidth","depth","yHeight","yWidth","effectiveXSize","effectiveYSize","heightScale","widthScale","bOffset","dxR","topDxRIndex","bottomDxRIndex","topDxROffset","bottomDxROffset","dxRLerp","inverseDxRLerp","dxC","leftDxCIndex","rightDxCIndex","dxCLerp","inverseDxCLerp","topLeftRCOffset","topRightRCOffset","bottomLeftRCOffset","bottomRightRCOffset","inverseDxRLerpTimesInverseDxCLerp","inverseDxRLerpTimesDxCLerp","dxRLerpTimesInverseDxCLerp","dxRLerpTimesDxCLerp","dyVal","tf.tensor4d","outputOffset","batchOffset","rowOffset","round","colOffset","newVal","invHeightScale","invWidthScale","winHeight","winWidth","startRLerp","startDyR","startCLerp","startDyC","accum","dyRIndex","dyR","dyROffset","dyCIndex","dyC","dyCOffset","depthRadius","alpha","beta","channels","maxD","sumAcrossChannels","currentChannel","beginSumOffset","endSumOffset","z","val","inputImage","outputImage","inputImageValues","outputImageValues","depthBegin","depthEnd","norm","dyi","normalized","numSamples","seed","probabilities","tf.softmax","numEvents","probVals","cdf","event_1","random","seedrandom.alea","toString","outOffset","sampleId","event_2","onValue","offValue","indicesVal","event_3","tf.tensor2d","boxes","scores","maxOutputSize","iouThreshold","scoreThreshold","boxesVals","scoresVals","inputHeight","inputWidth","inputDepth","outputHeight","outputWidth","outputDepth","h","inH","offsetH","w","inW","offsetD","inputIdx","op","assertAndGetBroadcastShape","bVals","aBroadcastDims","getBroadcastDims","bBroadcastDims","aBuf","bBuf","aLoc","aIndex","bLoc","bIndex","sizeSplits","epsilon","images","boxIndex","cropSize","method","extrapolationValue","imageHeight","imageWidth","numBoxes","cropHeight","cropWidth","boxVals","boxIndVals","imageVals","inStride","outStride","startInd","y1","x1","y2","x2","bInd","yInd","ind","topInd","bottomInd","yLerp","xInd","leftInd","rightInd","xLerp","topRight","top_2","bottom","closestX","closestY","inInd","outInd","sparseIndices","sparseValues","outputShape","defaultValue","sliceRank","numUpdates","outputSize","scatter","indicesShape","resultShape","numSlices","TensorBuffer","indicesData","xData","flattenIndex","updates","inferDtype","getArrayFromDType","makeTensor","stop","linspaceImpl","sumDupeIndices","flattenShape","updatesData","KernelBackend","simpleAbsImpl","abs","absConfig","kernelName","Abs","backendName","kernelFunc","args","cpuBackend","complexVals","realVals","imagVals","real_1","imag_1","hypot","createSimpleBinaryKernelImpl","aShape","bShape","resultRank","resultStrides","computeStrides","resultSize","getTypedArrayFromDType","aRank","bRank","aStrides","bStrides","complex","inputs","complexInfo","makeTensorInfo","complexConfig","Complex","identity","incRef","identityConfig","Identity","realVal","realConfig","Real","cast","attrs","zerosTensor","floatX","dispose","disposeIntermediateTensorInfo","realPart","hasEncodingLoss","Int32Array","from","zero","toTypedArray","resultData","castConfig","Cast","binaryKernelFunc","name","simpleImpl","complexImpl","$dtype","$aComplex","$aComplexVals","aReal","aImag","aRealVals","aImagVals","$bComplex","$bComplexVals","bReal","bImag","bRealVals","bImagVals","resultRealData","resultImagData","resultReal","resultImag","_d","createComplexBinaryKernelImpl","resultRealVals","resultImagVals","aIdx","bIdx","opResult","addImpl","addComplexImpl","add","Add","addConfig","createSimpleUnaryImpl","unaryKernelFunc","xSize","unaryKernelFuncFromImpl","unaryImpl","ceilImpl","xi","ceilKernelFunc","Ceil","ceilConfig","expImpl","exp","expKernelFunc","Exp","expConfig","expm1Impl","expm1","expm1KernelFunc","Expm1","expm1Config","floorImpl","floorKernelFunc","Floor","floorConfig","logImpl","log","logKernelFunc","Log","logConfig","maxImpl","multiplyImpl","multiplyComplexImpl","multiply","Multiply","multiplyConfig","rsqrtImpl","sqrt","rsqrtKernelFunc","Rsqrt","rsqrtConfig","sliceImpl","isContinous","isSliceContinous","xStrides","flatOffset","computeFlatOffset","subarray","outVals","xLoc","xIndex","$begin","$size","assertParamsValid","sliceConfig","Slice","subImpl","subComplexImpl","sub","Sub","subConfig","transposeImpl","xShape","perm","xRank","newStrides","i_1","uniqueImpl","$axis","uniqueElements","inputBuffer","uniqueIndices","is1DTensor","element","axisValues","m","n","join","undefined","uniqueIndex","Object","keys","outputTmpShape","outputBuffer","uniqueElementIndex","outputValues","acosKernelFunc","Acos","acos","acosConfig","acoshKernelFunc","Acosh","acosh","acoshConfig","asinKernelFunc","Asin","asin","asinConfig","asinhKernelFunc","Asinh","asinh","asinhConfig","atanKernelFunc","Atan","atan","atanConfig","atanhKernelFunc","Atanh","atanh","atanhConfig","pool","xRMax","xCMax","xROffset","maxPoolPositions","flattenPositions","includeBatchInIndex","avgPoolConfig","AvgPool","filterSize","pad","dimRoundingMode","eitherStridesOrDilationsAreOne","computePool2DInfo","arraysEqual","strides_1","avgPoolBackpropConfig","AvgPoolBackprop","dyData","dyRCorner","dyCCorner","batchNormConfig","FusedBatchNorm","scale","mean","variance","varianceEpsilon","mVals","varVals","sVals","offVals","offValsLength","sValsLength","varValsLength","mValsLength","offi","mi","si","vi","clipKernelFunc","ClipByValue","clipAttrs","clipValueMax","clipValueMin","clipConfig","imagVal","imagConfig","Imag","$shape","inferFromImplicitShape","$xSize","reshapeConfig","Reshape","concat","$inputs","shapes","assertParamsConsistent","reals","imags","realConcated","imagConcated","inputs2D","innerSize","offset_1","colOffset_1","tVals","tIdx","row","resIdx","col","finalOutShape","outInfo","concatConfig","Concat","cosKernelFunc","Cos","cos","cosConfig","coshKernelFunc","Cosh","cosh","coshConfig","dilation2dConfig","Dilation2D","dilations","filterVals","filterRank","outSize","outRank","hOut","hBeg","wOut","wBeg","curVal","MIN_SAFE_INTEGER","hIn","wIn","filterIndex","dilation2dBackpropFilterConfig","Dilation2DBackpropFilter","$x","toNestedArray","$filter","$dy","gradients","makeZerosNestedTypedArray","hMax","wMax","dilation2dBackpropInputConfig","Dilation2DBackpropInput","hInMax","wInMax","divImpl","div","Div","divConfig","eluKernelFunc","Elu","eluConfig","p","ERF_P","a1","ERF_A1","a2","ERF_A2","a3","ERF_A3","a4","ERF_A4","a5","ERF_A5","erfKernelFunc","Erf","sign","erfConfig","fftBatch","inverse","inputShape","innerDim","inputVals","real2D","imag2D","input_1","getComplexWithIndex","$realInfo","$imagInfo","fftImpl","inputSize","fftRadix2","half","evenComplex","complexWithEvenIndex","evenRealVals","evenImagVals","evenShape","evenRealInfo","evenImagInfo","evenTensorInfo","oddComplex","complexWithOddIndex","oddRealVals","oddImagVals","oddShape","oddRealInfo","oddImagInfo","oddTensorInfo","$evenComplex","$evenRealVals","$evenImagVals","$evenShape","$evenRealInfo","$evenImagInfo","$evenTensorInfo","$oddComplex","$oddRealVals","$oddImagVals","$oddShape","$oddRealInfo","$oddImagInfo","$oddTensorInfo","e","exponents","eShape","eRealInfo","eImagInfo","exponentInfo","addPart","subPart","addPartReal","subPartReal","addPartImag","subPartImag","$real","$imag","$realVals","$imagVals","realInfo","imagInfo","sizeInfo","createScalarValue","sizeInfoCopy","divRealInfo","divImagInfo","divRealVals","divImagVals","rawOutput","ret","real_2","imag_2","exponent","term","assignToTypedArray","fourierTransformByMatmul","splitRealAndImagArrays","fftConfig","FFT","innerDimensionSize","input2D","resultReshaped","flipLeftRightConfig","FlipLeftRight","image","batchIdx","coordX","outIdx","outputValue","ifftConfig","IFFT","isFiniteKernelFunc","IsFinite","isFinite","isFiniteConfig","isInfKernelFunc","IsInf","Infinity","isInfConfig","isNaNKernelFunc","IsNan","isNaNConfig","log1pKernelFunc","Log1p","log1p","log1pConfig","logicalNotKernelFunc","LogicalNot","logicalNotConfig","maxConfig","Max","reductionIndices","keepDims","origAxes","permutedAxes","getAxesPermutation","getInnerMostAxes","maxOutShape","maxPoolConfig","MaxPool","maxPoolBackpropConfig","MaxPoolBackprop","maxPoolWithArgmaxConfig","MaxPoolWithArgmax","maxPools","pooled","indexes","pooledDataId","indexesDataId","nonMaxSuppressionV4Impl","nonMaxSuppressionV4Config","NonMaxSuppressionV4","padToMaxOutputSize","nonMaxSuppressionV5Impl","nonMaxSuppressionV5Config","NonMaxSuppressionV5","softNmsSigma","notEqualImpl","notEqual","NotEqual","notEqualConfig","padV2Config","PadV2","paddings","constantValue","outCoords","reciprocalKernelFunc","Reciprocal","reciprocalConfig","rotateWithOffsetConfig","RotateWithOffset","radians","fillValue","center","centerX","centerY","sinFactor","sin","cosFactor","coords","coordY","roundKernelFunc","Round","base","roundConfig","scaleAlpha","SELU_SCALEALPHA","SELU_SCALE","seluKernelFunc","Selu","seluConfig","sigmoidKernelFunc","Sigmoid","sigmoidConfig","signKernelFunc","Sign","signConfig","sinKernelFunc","Sin","sinConfig","sinhKernelFunc","Sinh","sinh","sinhConfig","threshold","softplusKernelFunc","Softplus","tooLarge","tooSmall","expX","softplusConfig","transpose","transposeConfig","Transpose","spaceToBatchNDConfig","SpaceToBatchND","completePaddings","paddedX","reshapedPaddedShape","permutedReshapedPaddedPermutation","paddedXReshaped","paddedXT","sqrtKernelFunc","Sqrt","sqrtConfig","squareConfig","Square","squaredDifferenceImpl","squaredDifference","SquaredDifference","squaredDifferenceConfig","stepKernelFunc","Step","stepAttrs","NaN","stepConfig","tanKernelFunc","Tan","tan","tanConfig","tanhKernelFunc","Tanh","tanh","tanhConfig","uniqueConfig","Unique","kernelConfigs_1","_i","kernelConfig","registerKernel"],"mappings":";;;;;;;;;;;;;;;;o0DAmBgBA,EACZC,EAAiCC,GAC9BC,MAAMC,QAAQH,KACjBA,EAAS,CAACA,IAEZA,EAAOI,SAAQ,SAAAC,GACJ,MAALA,GACFC,OAAKC,OACW,cAAZF,EAAEG,OACF,WAAM,OACFP,kECTd,IAAMQ,EAA0BC,eAAaD,wBACvCE,EAAQD,eAAaC,MACrBC,EAAOF,eAAaE,KACpBC,EAAWH,eAAaG,SACxBC,EAAYJ,eAAaI,UAM/B,SAASC,EACLC,EAAyBC,EAAWC,EACpCC,GACF,GAAmB,WAAfD,EACF,OAAOF,EAAQI,OAAOH,GACjB,GAAmB,SAAfC,EACT,OAAOF,EAAQK,KAAKJ,GACf,GAAmB,QAAfC,EACT,OAAOI,MAAOL,GACT,GAAmB,UAAfC,EACT,OAAOF,EAAQO,MAAMN,GAChB,GAAmB,UAAfC,EACT,OAAOF,EAAQQ,MAAMP,EAAGE,GAE1B,MAAM,IAAIM,MACN,cAAcP,sEAqBlB,aAAA,MACEQ,0BANKC,YAAY,GAGXA,YAAW,EAIjBA,EAAKC,KAAO,IAAIC,cAAYF,EAAMG,cAijFtC,kIAzjFoCC,MAWlCC,kBAAA,SAAMC,EAAoCC,EAAiB1B,GAErD2B,KAAKC,WACPD,KAAKC,UAAW,EACZC,QAAMC,IAAI,YACZC,eAAaC,KACT,4dAYR,IAAMC,EAAS,GAIf,OAFAN,KAAKP,KAAKc,IAAID,EAAQ,CAACR,SAAQzB,QAAOmC,SAAU,IAEzCF,GASTT,2BAAA,SACIE,EAAiB1B,EACjByB,GAGF,MAAO,CAACQ,OAFMN,KAAKS,MAAMX,EAAQC,EAAO1B,GAEjB0B,QAAO1B,UAIhCwB,mBAAA,SAAOS,GACcN,KAAKP,KAAKU,IAAIG,GACtBE,YAIbX,mBAAA,SAAOS,GACDN,KAAKP,KAAKiB,IAAIJ,IACGN,KAAKP,KAAKU,IAAIG,GACtBE,YAIfX,iBAAA,SACIS,EAAgBR,EAAoCC,EACpD1B,GACF2B,KAAKP,KAAKc,IAAID,EAAQ,CAACR,SAAQzB,QAAOmC,SAAU,KAGlDX,uBAAA,WACE,OAAOG,KAAKP,KAAKkB,cAGbd,iBAAN,SAAWS,sEACT,SAAON,KAAKY,SAASN,WAEvBT,qBAAA,SAASS,GACD,IAAAO,mBAACxC,UAAOyC,uBAEd,GAAc,cAAVzC,EAAuB,CACzB,IAAM0C,EACFf,KAAKY,SAASE,EAAmBE,KAAKV,QACpCW,EACFjB,KAAKY,SAASE,EAAmBI,KAAKZ,QAC1C,OAAOF,eAAae,uBAAuBJ,EAAYE,GAGzD,OAAOjB,KAAKP,KAAKU,IAAIG,GAAQR,QAGvBD,uBAAR,SAAmC3B,GACjC,IAAMuB,EAAOO,KAAKY,SAAS1C,EAAEoC,QACzBc,EAAc3B,EAClB,GAAgB,WAAZvB,EAAEG,MACJ,IAEE+C,EAAe3B,EAAsB4B,KAAI,SAAAC,GAAK,OAAAnD,OAAKoD,aAAaD,MAChE,SACA,MAAM,IAAIhC,MAAM,oDAGpB,OAAOkC,SAAUtD,EAAE6B,MAAO7B,EAAEG,MAAO+C,IAGrCvB,uBAAA,SACIC,EAAoCC,EAAiB1B,GACvD,IAAMiC,EAASN,KAAKS,MAAMX,EAAQC,EAAO1B,GACzC,OAAOsB,WAAS8B,qBAAqBnB,EAAQP,EAAO1B,EAAO2B,OAG7DH,wBAAA,SAAYS,GACV,GAAIN,KAAKP,KAAKiB,IAAIJ,GAAS,CAClB,IAAAQ,sCAEmB,MAAtBA,IACFd,KAAK0B,YAAYZ,EAAmBE,KAAKV,QACzCN,KAAK0B,YAAYZ,EAAmBI,KAAKZ,SAG3CN,KAAKP,KAAKkC,OAAOrB,KAIrBT,0CAAA,SAA8B+B,GAC5B,IAAMtB,EAASsB,EAAWtB,OAE1B,GAAIN,KAAKP,KAAKiB,IAAIJ,GAAS,CACzB,IAAMuB,EAAa7B,KAAKP,KAAKU,IAAIG,GAEjCuB,EAAWrB,WAEPqB,EAAWrB,SAAW,GACxBR,KAAK0B,YAAYpB,KAKjBT,iBAAN,SAAWiC,4EAIT,OAHMC,EAAQ5D,OAAK6D,MACnBF,OAEO,CAACG,SADS9D,OAAK6D,MAAQD,WAIhClC,mBAAA,WACE,MAAO,CAELqC,YAAY,EACZC,QACI,CAAC,wHAKTtC,yBAAA,SACIf,EAAMsD,EAAiBC,EAAeC,GACxC1E,EAAiBkB,EAAG,gBAEpB,IAAMyD,EAAWC,aAAWC,gBAAgBL,EAAOC,EAAKC,GAExD,GAAIC,EAASG,MAAK,SAAAC,GAAQ,OAAS,IAATA,KACxB,OAAOC,SAAU,GAAIL,GAKvB,IAFA,IAAMM,EAASrB,SAAUe,EAAUzD,EAAET,OAC/ByE,EAAO9C,KAAK+C,WAAWjE,GACpBkE,EAAI,EAAGA,EAAIH,EAAOI,KAAMD,IAAK,CAIpC,IAHA,IAAME,EAAML,EAAOM,WAAWH,GAExBI,EAAmB,IAAIrF,MAAMmF,EAAIG,QAC9BC,EAAI,EAAGA,EAAIF,EAAOC,OAAQC,IACjCF,EAAOE,GAAKJ,EAAII,GAAKhB,EAAQgB,GAAKlB,EAAMkB,GAE1CT,EAAOtC,UAAPsC,GAAWC,EAAK3C,UAAL2C,EAAYM,WAAYF,IAGrC,OAAOL,EAAOU,YAGhB1D,iBAAA,SAAKf,GAIH,IAHA,IAAM0E,EAAQxD,KAAKY,SAAS9B,EAAEwB,QACxBuC,EAASrB,SAAU,CAAC1C,EAAEmE,KAAMnE,EAAEmE,MAAOnE,EAAET,OACvCoF,EAAOZ,EAAO/C,OACXkD,EAAI,EAAGA,EAAIQ,EAAMH,OAAQL,IAChCS,EAAKT,EAAIlE,EAAEmE,KAAOD,GAAKQ,EAAMR,GAE/B,OAAOH,EAAOU,YAGhB1D,oBAAA,SAAQf,EAAW6D,GAIjB,IAHA,IAAMe,EAAM5E,EAAEiB,MAAM4C,GACdJ,EAAqB,IAAIxE,MAAMe,EAAE6E,KAAO,GAC1CC,EAAW,EACNZ,EAAI,EAAGA,EAAIlE,EAAE6E,KAAMX,IACtBA,IAAML,IACRJ,EAASqB,KAAc9E,EAAEiB,MAAMiD,IAInC,IAAMZ,EAAQ,IAAIrE,MAAMe,EAAE6E,MAAME,KAAK,GAC/BZ,EAAOnE,EAAEiB,MAAM+D,QACrBb,EAAKN,GAAQ,EACb,IAAMoB,EAAM,IAAIhG,MAAM2F,GACtB,IAASV,EAAI,EAAGA,EAAIe,EAAIV,OAAQL,IAC9BZ,EAAMO,GAAQK,EACde,EAAIf,GAAKgB,QAASlF,EAAGsD,EAAOa,GAAMgB,QAAQ1B,GAE5C,OAAOwB,GAGTlE,oBAAA,SAA0Bf,EAAM6D,GAC9B/E,EAAiBkB,EAAG,WAKpB,IAHA,IAAM+D,EAASrB,SAAU1C,EAAEiB,MAAOjB,EAAET,OAC9ByE,EAAO9C,KAAK+C,WAAWjE,cAEpBkE,GACP,IAAMkB,EAASrB,EAAOM,WAAWH,GAC3BmB,EAAQD,EAAOJ,QACrBnB,EAAK1E,SAAQ,SAAAmG,GAAM,OAAAD,EAAMC,GAAMtF,EAAEiB,MAAMqE,GAAM,EAAID,EAAMC,MACvDvB,EAAOtC,UAAPsC,GAAWC,EAAK3C,UAAL2C,EAAYqB,WAAWD,KAJ3BlB,EAAI,EAAGA,EAAIH,EAAOI,KAAMD,MAAxBA,GAOT,OAAOH,EAAOU,YAGhB1D,gBAAA,SAAsBf,GAIpB,OAHAlB,EAAiBkB,EAAG,OAGbuF,MAAOC,UAAW,GAAIxF,IAG/Be,iBAAA,SAAuB0E,GAAvB,WACE3G,EAAiB2G,EAAS,QAK1B,IAHA,IAAMd,EAAOc,EAAQlD,KAAI,SAAAnD,GAAK,OAAAsB,EAAKoB,SAAS1C,EAAEoC,WACxCkE,EAAShD,SAAU+C,EAAQ,GAAGxE,MAAOwE,EAAQ,GAAGlG,OAChDoG,EAAaD,EAAO1E,OACjBkD,EAAI,EAAGA,EAAIuB,EAAQlB,OAAQL,IAElC,IADA,IAAM0B,EAAWjB,EAAKT,GACbM,EAAI,EAAGA,EAAImB,EAAWpB,OAAQC,IACrCmB,EAAWnB,IAAMoB,EAASpB,GAG9B,OAAOkB,EAAOjB,YAGhB1D,oBAAA,SAA0B8E,EAAWC,GACnC,IAAMC,EAAO1G,OAAK2G,eAAe,CAACF,GAAMD,EAAO5E,OAGzCgF,EAAWC,MAAIL,EAAQE,GACvBI,EACF7E,eAAa8E,qBAAqBH,EAAShF,MAAO8E,GAGhDM,EAAIC,MAAOT,EAAQI,EAASd,QAAQgB,IACpCI,EAAIC,MAAOH,GACXI,EAASvF,KAAKwF,IAAIH,EAAGR,GAAMZ,QAAQgB,GAIzC,OAAOQ,MAAOJ,EAAGE,IAGnB1F,gBAAA,SAAsBsF,EAAME,GAG1B,OAFAzH,EAAiB,CAACuH,EAAGE,GAAI,OAElBrF,KAAK0F,oBACDP,EAAGE,EAAGF,EAAE9G,OAAO,SAACsH,EAAQC,GAAW,OAAAC,KAAKC,IAAIH,EAAQC,OAIjE/F,wBAAA,SACIsF,EAAaE,EAAaU,EAC1BC,GACFpI,EAAiB,CAACuH,EAAGE,GAAI,UAqBzB,IAnBA,IAAMY,EAAYF,EAAaZ,EAAEpF,MAAM,GAAKoF,EAAEpF,MAAM,GAC9CmG,EAAUH,EAAaZ,EAAEpF,MAAM,GAAKoF,EAAEpF,MAAM,GAC5CoG,EAAWH,EAAaX,EAAEtF,MAAM,GAAKsF,EAAEtF,MAAM,GAC7CqG,EAAWjB,EAAEpF,MAAM,GAEnBsG,EAAUrG,KAAKY,SAASuE,EAAE7E,QAC1BgG,EAAUtG,KAAKY,SAASyE,EAAE/E,QAC1BO,gEAAC0F,OAAQC,OAAYC,OAGrBC,gEAACC,OAAYC,OAAYC,OAIzB5D,EAAOiD,EAAUC,EACjB3B,EAAShD,SAAU,CAAC4E,EAAUF,EAASC,GAAWhB,EAAE9G,OACpDyI,EAAUtC,EAAO1E,OACjBiH,EAAY/G,KAAK+G,UAEdC,EAAI,EAAGA,EAAIZ,EAAUY,IAC5B,IAAK,IAAIC,EAAK,EAAGA,EAAKf,EAASe,GAAMF,EACnC,IAAK,IAAIG,EAAK,EAAGA,EAAKf,EAAUe,GAAMH,EACpC,IAAK,IAAII,EAAK,EAAGA,EAAKlB,EAAWkB,GAAMJ,EAMrC,IAJA,IAAMK,EAASvB,KAAKwB,IAAIJ,EAAKF,EAAWb,GAClCoB,EAASzB,KAAKwB,IAAIH,EAAKH,EAAWZ,GAClCoB,EAAS1B,KAAKwB,IAAIF,EAAKJ,EAAWd,GAE/BjD,EAAIiE,EAAIjE,EAAIoE,EAAQpE,IAC3B,IAAK,IAAIM,EAAI4D,EAAI5D,EAAIgE,EAAQhE,IAAK,CAGhC,IAFA,IAAIkC,EAAM,EAEDgC,EAAIL,EAAIK,EAAID,EAAQC,IAC3BhC,GAAOa,EAAQW,EAAIT,EAASvD,EAAIwD,EAAagB,EAAIf,GAC7CH,EAAQkB,EAAIb,EAAarD,EAAIsD,EAAaI,EAAIH,GAEpDC,EAAQE,EAAI/D,GAAQD,EAAImD,EAAW7C,KAAOkC,EAOtD,OAAOhB,EAAOjB,YAGhB1D,6BAAA,SACIgB,OAACsE,MAAGE,MAAGU,eAAYC,eAAYyB,SAAM1I,eAAYC,2BAE/CwF,EAASxE,KAAK0H,YAAYvC,EAAGE,EAAGU,EAAYC,GAWhD,OAVIyB,IAEFjD,EAASmD,MAAOnD,EAAQiD,IAEtB1I,IACFyF,EACI5F,EAAcoB,KAAMwE,EAAQzF,EAAYC,IAIvCwF,GAGT3E,qBAAA,SAASsF,EAAWE,GAClBzH,EAAiB,CAACuH,EAAGE,GAAI,YAIzB,OAAOrF,KAAK0F,oBAAoBP,EAAGE,EADf,SADT,SAACF,EAAWE,GAAc,OAAAQ,KAAK+B,MAAMzC,EAAIE,OAKtDxF,gBAAA,SAAIf,EAAW+F,GACbjH,EAAiBkB,EAAG,OAEpBsB,eAAayH,2BAA2B,MAAOhD,EAAM/F,EAAE6E,MASvD,IARM,IAAA9C,sDAAC0B,OAAUuF,OAEXC,EAAcC,aAAWlJ,EAAET,MAAO,SAClCmG,EAASyD,QAAS1F,EAAUwF,GAC5BG,EAAa/J,OAAKgK,cAAcL,GAChCrE,EAAOzD,KAAKY,SAAS4D,EAAOlE,QAE5B8H,EAAQpI,KAAKY,SAAS9B,EAAEwB,QACrB0C,EAAI,EAAGA,EAAIS,EAAKJ,SAAUL,EAAG,CAGpC,IAFA,IAAMqF,EAASrF,EAAIkF,EACf1C,EAAM,EACDlC,EAAI,EAAGA,EAAI4E,IAAc5E,EAChCkC,GAAO4C,EAAMC,EAAS/E,GAExBG,EAAKT,GAAKwC,EAEZ,OAAOhB,GAGT3E,iBAAA,SAAKf,EAAW+F,GACdjH,EAAiBkB,EAAG,OAUpB,IARM,IAAA+B,sDAAC0B,OAAUuF,OAEXC,EAAcC,aAAWlJ,EAAET,MAAO,SAClCmG,EAASyD,QAAS1F,EAAUwF,GAC5BG,EAAa/J,OAAKgK,cAAcL,GAChCrE,EAAOzD,KAAKY,SAAS4D,EAAOlE,QAE5B8H,EAAQpI,KAAKY,SAAS9B,EAAEwB,QACrB0C,EAAI,EAAGA,EAAIS,EAAKJ,SAAUL,EAAG,CAGpC,IAFA,IAAMqF,EAASrF,EAAIkF,EACfI,EAAO,EACFhF,EAAI,EAAGA,EAAI4E,IAAc5E,EAChCgF,GAAQF,EAAMC,EAAS/E,GAEzBG,EAAKT,GAAKsF,EAEZ,OAAO9D,GAGT3E,+BAAA,SACIf,EAAMyJ,EAAsBC,GAC9B5K,EAAiBkB,EAAG,sBAOpB,IALA,IAAMiF,EAAM,GAIN0E,EAAW3J,EAAE6E,KAAO4E,EAAW5E,KAC5BX,EAAI,EAAGA,EAAIyF,IAAYzF,EAC9BuF,EAAaA,EAAWG,WAAW1F,EAAI,GAGzC,IAASA,EAAI,EAAGA,EAAIwF,IAAexF,EAAG,CACpC,IAAM2F,EAAYrE,SAAUtB,EAAG,SAEzBwC,EADOoD,QAASD,EAAWJ,GAAYM,OAAO,WACnCC,IAAIhK,GAAG0G,IAAI,GAC5BzB,EAAIgF,KAAKvD,GAGX,OAAOwD,QAASjF,IAGlBlE,mBAAA,SAAOf,EAAW6D,GAChB/E,EAAiBkB,EAAG,UAEpB,IAAM+F,EAAO,CAAClC,GACdvC,eAAayH,2BAA2B,SAAUhD,EAAM/F,EAAE6E,MAQ1D,IAPM,IAAA9C,sDAAC0B,OAAUuF,OAEXtD,EAASyD,QAAS1F,EAAU,SAC5B2F,EAAa/J,OAAKgK,cAAcL,GAChCrE,EAAOzD,KAAKY,SAAS4D,EAAOlE,QAE5B8H,EAAQpI,KAAKY,SAAS9B,EAAEwB,QACrB0C,EAAI,EAAGA,EAAIS,EAAKJ,SAAUL,EAAG,CAIpC,IAHA,IAAMqF,EAASrF,EAAIkF,EACfb,EAAMe,EAAMC,GACZY,EAAW,EACN3F,EAAI,EAAGA,EAAI4E,IAAc5E,EAAG,CACnC,IAAM4F,EAAQd,EAAMC,EAAS/E,GACzB4F,EAAQ7B,IACVA,EAAM6B,EACND,EAAW3F,GAGfG,EAAKT,GAAKiG,EAEZ,OAAOzE,GAGT3E,mBAAA,SAAOf,EAAW6D,GAChB/E,EAAiBkB,EAAG,UAEpB,IAAM+F,EAAO,CAAClC,GACdvC,eAAayH,2BAA2B,SAAUhD,EAAM/F,EAAE6E,MAQ1D,IAPM,IAAA9C,sDAAC0B,OAAUuF,OAEXtD,EAASyD,QAAS1F,EAAU,SAC5B2F,EAAa/J,OAAKgK,cAAcL,GAChCrE,EAAOzD,KAAKY,SAAS4D,EAAOlE,QAE5B8H,EAAQpI,KAAKY,SAAS9B,EAAEwB,QACrB0C,EAAI,EAAGA,EAAIS,EAAKJ,SAAUL,EAAG,CAIpC,IAHA,IAAMqF,EAASrF,EAAIkF,EACfiB,EAAMf,EAAMC,GACZe,EAAW,EACN9F,EAAI,EAAGA,EAAI4E,IAAc5E,EAAG,CACnC,IAAM4F,EAAQd,EAAMC,EAAS/E,GACzB4F,EAAQC,IACVA,EAAMD,EACNE,EAAW9F,GAGfG,EAAKT,GAAKoG,EAEZ,OAAO5E,GAGT3E,mBAAA,SAAOf,EAAW6D,EAAc0G,EAAoBC,GAIlD,GAFA1L,EAAiBkB,EAAG,UAEhB6D,IAAS7D,EAAE6E,KAAO,EACpB,MAAM,IAAIrE,MACN,qDAAoDR,EAAE6E,KAAO,oBAC7ChB,GAWtB,IATA,IAAMoF,EAAcC,aAAWlJ,EAAET,MAAO,SAClCmG,EAASyD,QAASnJ,EAAEiB,MAAOgI,GAC3BtE,EAAOzD,KAAKY,SAAS4D,EAAOlE,QAE5B8H,EAAQpI,KAAKY,SAAS9B,EAAEwB,QACxBiJ,EAAWzK,EAAEiB,MAAMjB,EAAE6E,KAAO,GAC5B6F,EAAgBF,EAClB,SAACtG,EAAWM,GAAc,OAAAN,EAAIuG,EAAWjG,EAAI,GAC7C,SAACN,EAAWM,GAAc,OAAAN,EAAIM,GACzBN,EAAI,EAAGA,EAAIoF,EAAM/E,OAAQL,GAAKuG,EACrC,IAAK,IAAIjG,EAAI,EAAGA,EAAIiG,EAAUjG,IAAK,CACjC,IAAMmG,EAAMD,EAAcxG,EAAGM,GAC7B,GAAU,IAANA,EACFG,EAAKgG,GAAOJ,EAAY,EAAIjB,EAAMqB,OAC7B,CACL,IAAMC,EAAUF,EAAcxG,EAAGM,EAAI,GACrCG,EAAKgG,GAAOJ,EAAYjB,EAAMsB,GAAWjG,EAAKiG,GACtBtB,EAAMqB,GAAOhG,EAAKiG,IAIhD,OAAOlF,GAGT3E,kBAAA,SAAMsF,EAAWE,GAGf,OAFAzH,EAAiB,CAACuH,EAAGE,GAAI,SAElBrF,KAAK0F,oBAAoBP,EAAGE,EAAG,QAAQ,SAACsE,EAAMC,GACnD,OAAQD,IAASC,EAAQ,EAAI,MAIjC/J,qBAAA,SAASsF,EAAWE,GAGlB,OAFAzH,EAAiB,CAACuH,EAAGE,GAAI,YAElBrF,KAAK0F,oBAAoBP,EAAGE,EAAG,QAAQ,SAACsE,EAAMC,GACnD,OAAQD,IAASC,EAAQ,EAAI,MAIjC/J,iBAAA,SAAKsF,EAAWE,GAGd,OAFAzH,EAAiB,CAACuH,EAAGE,GAAI,QAElBrF,KAAK0F,oBAAoBP,EAAGE,EAAG,QAAQ,SAACsE,EAAMC,GACnD,OAAQD,EAAOC,EAAQ,EAAI,MAI/B/J,sBAAA,SAAUsF,EAAWE,GAGnB,OAFAzH,EAAiB,CAACuH,EAAGE,GAAI,aAElBrF,KAAK0F,oBAAoBP,EAAGE,EAAG,QAAQ,SAACsE,EAAMC,GACnD,OAAQD,GAAQC,EAAQ,EAAI,MAIhC/J,oBAAA,SAAQsF,EAAWE,GAGjB,OAFAzH,EAAiB,CAACuH,EAAGE,GAAI,WAElBrF,KAAK0F,oBAAoBP,EAAGE,EAAG,QAAQ,SAACsE,EAAMC,GACnD,OAAQD,EAAOC,EAAQ,EAAI,MAI/B/J,yBAAA,SAAasF,EAAWE,GAGtB,OAFAzH,EAAiB,CAACuH,EAAGE,GAAI,gBAElBrF,KAAK0F,oBAAoBP,EAAGE,EAAG,QAAQ,SAACsE,EAAMC,GACnD,OAAQD,GAAQC,EAAQ,EAAI,MAIhC/J,uBAAA,SAAWsF,EAAWE,GAGpB,OAFAzH,EAAiB,CAACuH,EAAGE,GAAI,cAElBrF,KAAK0F,oBAAoBP,EAAGE,EAAG,QAAQ,SAACsE,EAAMC,GACnD,OAAOD,GAAQC,MAInB/J,sBAAA,SAAUsF,EAAWE,GAGnB,OAFAzH,EAAiB,CAACuH,EAAGE,GAAI,aAElBrF,KAAK0F,oBAAoBP,EAAGE,EAAG,QAAQ,SAACsE,EAAMC,GACnD,OAAOD,GAAQC,MAInB/J,mBAAA,SAAOgK,EAAmB1E,EAAWE,GACnCzH,EAAiB,CAACiM,EAAW1E,EAAGE,GAAI,UAYpC,IAVA,IAAMvF,EAASE,KAAKY,SAASiJ,EAAUvJ,QACjC+F,EAAUrG,KAAKY,SAASuE,EAAE7E,QAC1BgG,EAAUtG,KAAKY,SAASyE,EAAE/E,QAC1BkE,EAASyD,QAAS9C,EAAEpF,MAAOiI,aAAW7C,EAAE9G,MAAOgH,EAAEhH,QACjDyL,EAAY9J,KAAKY,SAAS4D,EAAOlE,QACnCyJ,EAAQ,EACN1B,EAA4B,IAAnBwB,EAAUlG,MAAckG,EAAUlG,KAAO,GAAgB,IAAXwB,EAAExB,KAC3D,EACAxF,OAAKgK,cAAchD,EAAEpF,MAAM+D,MAAM,IAE5Bd,EAAI,EAAGA,EAAIlD,EAAOuD,OAAQL,IACjC,IAAK,IAAIM,EAAI,EAAGA,EAAI+E,EAAQ/E,IACR,IAAdxD,EAAOkD,GACT8G,EAAUC,KAAW1D,EAAQrD,GAE7B8G,EAAUC,KAAWzD,EAAQtD,GAKnC,OAAOwB,GAGT3E,kBAAA,SAAMgK,GACJjM,EAAiB,CAACiM,GAAY,SAE9B,IAAMG,EAAWhK,KAAKY,SAASiJ,EAAUvJ,QACzC,OAAO3B,EAAUkL,EAAU9J,MAAOiK,IAGpCnK,iBAAA,SAAuBf,EAAM0I,EAAWyC,GACtCrM,EAAiBkB,EAAG,QAEpB,IAAM0E,EAAQxD,KAAKY,SAAS9B,EAAEwB,QAC9B,OAAO5B,EAAS8E,EAAO1E,EAAEiB,MAAOjB,EAAET,MAA0BmJ,EAAGyC,IAGjEpK,gBAAA,SAAIf,EAAW+F,GACbjH,EAAiBkB,EAAG,OAEpBsB,eAAayH,2BAA2B,MAAOhD,EAAM/F,EAAE6E,MAQvD,IAPM,IAAA9C,sDAAC0B,OAAUuF,OAEXtD,EAASyD,QAAS1F,EAAUzD,EAAET,OAC9B6J,EAAa/J,OAAKgK,cAAcL,GAChCrE,EAAOzD,KAAKY,SAAS4D,EAAOlE,QAE5B8H,EAAQpI,KAAKY,SAAS9B,EAAEwB,QACrB0C,EAAI,EAAGA,EAAIS,EAAKJ,SAAUL,EAAG,CAGpC,IAFA,IAAMqF,EAASrF,EAAIkF,EACfb,EAAMe,EAAMC,GACP/E,EAAI,EAAGA,EAAI4E,IAAc5E,EAAG,CACnC,IAAM4F,EAAQd,EAAMC,EAAS/E,GACzB4F,EAAQ7B,IACVA,EAAM6B,GAGVzF,EAAKT,GAAKqE,EAEZ,OAAO7C,GAGT3E,oBAAA,SAAQsF,EAAWE,GAGjB,OAFAzH,EAAiB,CAACuH,EAAGE,GAAI,WAElBrF,KAAK0F,oBACRP,EAAGE,EAAGF,EAAE9G,OAAO,SAACsL,EAAMC,GAAS,OAAA/D,KAAKwB,IAAIsC,EAAMC,OAGpD/J,gBAAA,SAAIsF,EAAWE,GAGb,OAFAzH,EAAiB,CAACuH,EAAGE,GAAI,OAElBrF,KAAK0F,oBAAoBP,EAAGE,EAAGF,EAAE9G,OAAO,SAACsL,EAAMC,GACpD,IAAMM,EAAMP,EAAOC,EACnB,OAAKD,EAAO,GAAKC,EAAO,GAAOD,GAAQ,GAAKC,GAAQ,EAC3CM,GAECA,EAAMN,GAAQA,MAK5B/J,oBAAA,SAAQsF,EAAWE,GAGjB,OAFAzH,EAAiB,CAACuH,EAAGE,GAAI,WAElBrF,KAAK0F,oBACRP,EAAGE,EAAGF,EAAE9G,OAAO,SAACsL,EAAMC,GAAS,OAAA/D,KAAKb,IAAI2E,EAAMC,OAGpD/J,gBAAA,SAAIf,EAAW+F,GACbjH,EAAiBkB,EAAG,OAEpBsB,eAAayH,2BAA2B,MAAOhD,EAAM/F,EAAE6E,MAQvD,IAPM,IAAA9C,sDAAC0B,OAAUuF,OAEXtD,EAASyD,QAAS1F,EAAUzD,EAAET,OAC9B6J,EAAa/J,OAAKgK,cAAcL,GAChCrE,EAAOzD,KAAKY,SAAS4D,EAAOlE,QAE5B8H,EAAQpI,KAAKY,SAAS9B,EAAEwB,QACrB0C,EAAI,EAAGA,EAAIS,EAAKJ,SAAUL,EAAG,CAGpC,IAFA,IAAMqF,EAASrF,EAAIkF,EACfiC,EAAM/B,EAAMC,GACP/E,EAAI,EAAGA,EAAI4E,IAAc5E,EAAG,CACnC,IAAM4F,EAAQd,EAAMC,EAAS/E,GAC7B6G,EAAMA,GAAOjB,EAEfzF,EAAKT,GAAKmH,EAEZ,OAAO3F,GAGT3E,gBAAA,SAAIf,EAAW+F,GACbjH,EAAiBkB,EAAG,OAEpBsB,eAAayH,2BAA2B,MAAOhD,EAAM/F,EAAE6E,MAQvD,IAPM,IAAA9C,sDAAC0B,OAAUuF,OAEXtD,EAASyD,QAAS1F,EAAUzD,EAAET,OAC9B6J,EAAa/J,OAAKgK,cAAcL,GAChCrE,EAAOzD,KAAKY,SAAS4D,EAAOlE,QAE5B8H,EAAQpI,KAAKY,SAAS9B,EAAEwB,QACrB0C,EAAI,EAAGA,EAAIS,EAAKJ,SAAUL,EAAG,CAGpC,IAFA,IAAMqF,EAASrF,EAAIkF,EACfkC,EAAShC,EAAMC,GACV/E,EAAI,EAAGA,EAAI4E,IAAc5E,EAAG,CACnC,IAAM4F,EAAQd,EAAMC,EAAS/E,GAC7B8G,EAASA,GAAUlB,EAErBzF,EAAKT,GAAKoH,EAEZ,OAAO5F,GAGT3E,8BAAA,SAAkBsF,EAAWE,GAG3B,OAFAzH,EAAiB,CAACuH,EAAGE,GAAI,qBAElBrF,KAAK0F,oBAAoBP,EAAGE,EAAGF,EAAE9G,OAAO,SAACsL,EAAMC,GACpD,IAAMS,EAAOV,EAAOC,EACpB,OAAOS,EAAOA,MAIlBxK,mBAAA,SAAyBf,GACvB,OAAOA,GAGTe,iBAAA,SAAuBf,GACrBlB,EAAiBkB,EAAG,QAKpB,IAHA,IAAMiF,EAAMkE,QAASnJ,EAAEiB,MAAOjB,EAAET,OAC1ByI,EAAU9G,KAAKY,SAASmD,EAAIzD,QAC5BgK,EAAStK,KAAKY,SAAS9B,EAAEwB,QACtB0C,EAAI,EAAGA,EAAIsH,EAAOjH,SAAUL,EACnC8D,EAAQ9D,GAAK6C,KAAKb,IAAI,EAAGsF,EAAOtH,IAElC,OAAOe,GAGTlE,kBAAA,SAAwBf,GACtBlB,EAAiBkB,EAAG,QAKpB,IAHA,IAAMiF,EAAMkE,QAASnJ,EAAEiB,MAAOjB,EAAET,OAC1ByI,EAAU9G,KAAKY,SAASmD,EAAIzD,QAC5BgK,EAAStK,KAAKY,SAAS9B,EAAEwB,QACtB0C,EAAI,EAAGA,EAAIsH,EAAOjH,SAAUL,EACnC8D,EAAQ9D,GAAK6C,KAAKwB,IAAIxB,KAAKb,IAAI,EAAGsF,EAAOtH,IAAK,GAEhD,OAAOe,GAGTlE,kBAAA,SAAwBf,EAAMqG,GAG5B,OAFAvH,EAAiB,CAACkB,EAAGqG,GAAI,SAElBnF,KAAK0F,oBACD5G,EAAGqG,EAAGrG,EAAET,OACR,SAACkM,EAAQ5E,GAAW,OAAA4E,EAAS,EAAI5E,EAAS4E,EAASA,MAGhE1K,mBAAA,SAAyB2K,EAAOC,GAC9B7M,EAAiB,CAAC4M,EAAIC,GAAI,UAK1B,IAHA,IAAMC,EAAe,IAAIC,aAAaF,EAAExH,MAClCnD,EAASE,KAAKY,SAAS6J,EAAEnK,QACzBsK,EAAW5K,KAAKY,SAAS4J,EAAGlK,QACzB0C,EAAI,EAAGA,EAAIlD,EAAOuD,SAAUL,EAAG,CACtC,IAAM6H,EAAI/K,EAAOkD,GAEf0H,EAAa1H,GADX6H,GAAK,EACWD,EAAS5H,GAET4H,EAAS5H,IAAM6H,EAAI,GAGzC,OAAO7K,KAAK8K,WAAWJ,EAAcD,EAAE1K,MAAO,YAGhDF,kBAAA,SAAwBsF,EAAME,GAG5B,OAFAzH,EAAiB,CAACuH,EAAGE,GAAI,SAElBrF,KAAK0F,oBACDP,EAAGE,EAAGF,EAAE9G,OAAO,SAACsH,EAAQC,GAAW,OAAAC,KAAKkF,MAAMpF,EAAQC,OAInE/F,wBAAA,SACIgB,OAACmK,UAAOC,WAAQC,aAAUzD,SAAM1I,eAAYC,2BAE1CwF,EAASxE,KAAKmL,OAAOH,EAAOC,EAAQC,GAWxC,OATIzD,IAEFjD,EAASmD,MAAOnD,EAAQiD,IAEtB1I,IACFyF,EACI5F,EAAcoB,KAAMwE,EAAQzF,EAAYC,IAGvCwF,GAGT3E,mBAAA,SAAOf,EAAamM,EAAkBC,GAEpCtN,EAAiB,CAACkB,EAAGmM,GAAS,UAyB9B,IAvBA,IAAMG,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAUN,EAASO,QAAQC,KAC3BC,EAAST,EAASO,QAAQG,IAC1BC,EAAyC,iBAAxBX,EAASY,WAE1BrB,EAAIjJ,SAAU0J,EAAS3I,SAAUzD,EAAET,OAEnC0N,EAAejN,EAAEwD,QAAQ,GACzB0J,EAAaH,EAAiB/M,EAAEwD,QAAQ,GAAKxD,EAAEwD,QAAQ,GACvD2J,EAAaJ,EAAiB/M,EAAEwD,QAAQ,GAAK,EAC7C4J,EAAiBL,EAAiB,EAAI/M,EAAEwD,QAAQ,GAChD6J,EAAe1B,EAAEnI,QAAQ,GACzB8J,EAAaP,EAAiBpB,EAAEnI,QAAQ,GAAKmI,EAAEnI,QAAQ,GACvD+J,EAAaR,EAAiBpB,EAAEnI,QAAQ,GAAK,EAC7CgK,EAAiBT,EAAiB,EAAIpB,EAAEnI,QAAQ,GAEhDkB,EAAQxD,KAAKY,SAAS9B,EAAEwB,QACxBiM,EAAQvM,KAAKY,SAASqK,EAAO3K,QAC7BkM,EAAQ/B,EAAE3K,OAEPuF,EAAI,EAAGA,EAAI6F,EAASuB,YAAapH,EAGxC,IAFA,IAAMqH,EAAWrH,EAAI0G,EACfY,EAAWtH,EAAI8G,EACZS,EAAK,EAAGA,EAAK1B,EAAS2B,YAAaD,EAG1C,IAFA,IAAME,EAAWH,EAAWC,EAAKR,EAC3BW,EAAWH,EAAK1B,EAAS8B,aAAerB,EACrCsB,EAAK,EAAGA,EAAK7B,EAAc6B,IAAM,CACxC,IAAMC,EAAKH,EAAWE,EAAK3B,EAC3B,KAAI4B,EAAK,GAAKA,GAAMhC,EAASiC,UAK7B,IAFA,IAAMC,EAAWH,EAAKhC,EAAO3I,QAAQ,GAC/B+K,EAAWX,EAAWQ,EAAKlB,EACxBsB,EAAK,EAAGA,EAAKpC,EAASqC,WAAYD,EAGzC,IAFA,IAAME,EAAWV,EAAWQ,EAAKjB,EAC3BoB,EAAWH,EAAKpC,EAASwC,YAAclC,EACpCmC,EAAK,EAAGA,EAAKtC,EAAasC,IAAM,CACvC,IAAMC,EAAKH,EAAWE,EAAKpC,EAC3B,KAAIqC,EAAK,GAAKA,GAAM1C,EAAS2C,SAM7B,IAHA,IACMC,EAAWT,EAAWO,EAAK3B,EAC7B8B,EAFaX,EAAWO,EAAK1C,EAAO3I,QAAQ,GAGvC0L,EAAK,EAAGA,EAAK9C,EAAS+C,aAAcD,EAAI,CAE/C,IADA,IAAME,EAAO1K,EAAMsK,EAAWE,EAAK9B,GAC1BiC,EAAK,EAAGA,EAAKjD,EAASkD,cAAeD,EAC5C3B,EAAMgB,EAAWW,EAAK7B,IAClB4B,EAAO3B,EAAMwB,EAAWI,GAE9BJ,GAAY7C,EAASkD,cAOjC,OAAO3D,EAAElH,YAGX1D,mBAAA,SAAOf,EAAamM,EAAkBC,GAiBpC,IAfA,IAAMmD,EAAcnD,EAASmD,YACvBjD,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBiD,EAAgBpD,EAASoD,cACzBhD,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBgD,EAAWrD,EAASO,QAAQ+C,MAC5BhD,EAAUN,EAASO,QAAQC,KAC3BC,EAAST,EAASO,QAAQG,IAC1BnB,EAAIjJ,SAAmB0J,EAAS3I,SAAUzD,EAAET,OAE5CmF,EAAQxD,KAAKY,SAAS9B,EAAEwB,QACxBiM,EAAQvM,KAAKY,SAASqK,EAAO3K,QAC7BkM,EAAQ/B,EAAE3K,OAEPuF,EAAI,EAAGA,EAAI6F,EAASuB,YAAapH,EAGxC,IAFA,IAAMqH,EAAWrH,EAAIvG,EAAEwD,QAAQ,GACzBqK,EAAWtH,EAAIoF,EAAEnI,QAAQ,GACtBmM,EAAK,EAAGA,EAAKvD,EAASwD,WAAYD,EAGzC,IAFA,IAAM3B,EAAWH,EAAW8B,EAAKhE,EAAEnI,QAAQ,GACrCqM,EAAWF,EAAKvD,EAAS0D,YAAcL,EACpCM,EAAK,EAAGA,EAAKR,EAAaQ,IAAM,CACvC,IAAMC,EAAKH,EAAWE,EAAKP,EAC3B,KAAIQ,EAAK,GAAKA,GAAM5D,EAAS6D,SAM7B,IAHA,IAAM3B,EAAWyB,EAAK5D,EAAO3I,QAAQ,GAC/B+K,EAAWX,EAAWoC,EAAKhQ,EAAEwD,QAAQ,GAElCsK,EAAK,EAAGA,EAAK1B,EAAS2B,YAAaD,EAG1C,IAFA,IAAMY,EAAWV,EAAWF,EAAKnC,EAAEnI,QAAQ,GACrCyK,EAAWH,EAAK1B,EAAS8B,aAAerB,EACrCsB,EAAK,EAAGA,EAAK7B,EAAc6B,IAAM,CACxC,IAAMC,EAAKH,EAAWE,EAAK3B,EAC3B,KAAI4B,EAAK,GAAKA,GAAMhC,EAASiC,UAK7B,IAFA,IAAM6B,EAAW5B,EAAWH,EAAKhC,EAAO3I,QAAQ,GAC1CwL,EAAWT,EAAWH,EAAKpO,EAAEwD,QAAQ,GAClCgL,EAAK,EAAGA,EAAKpC,EAASqC,WAAYD,EAGzC,IAFA,IAAM2B,EAAWzB,EAAWF,EAAKpC,EAASkD,YACpCX,EAAWH,EAAKpC,EAASwC,YAAclC,EACpCmC,EAAK,EAAGA,EAAKtC,EAAasC,IAAM,CACvC,IAAMC,EAAKH,EAAWE,EAAKpC,EAC3B,KAAIqC,EAAK,GAAKA,GAAM1C,EAAS2C,SAM7B,IAHA,IAAME,EAAWiB,EAAWrB,EAAK1C,EAAO3I,QAAQ,GAC1C4M,EAAWpB,EAAWF,EAAK1C,EAAS+C,WACtCkB,EAAWpB,EACNC,EAAK,EAAGA,EAAK9C,EAAS+C,aAAcD,EAAI,CAE/C,IADA,IAAME,EAAO1K,EAAM0L,EAAWlB,GACrBG,EAAK,EAAGA,EAAKjD,EAASkD,cAAeD,EAC5C3B,EAAMyC,EAAWd,IAAOD,EAAO3B,EAAM4C,EAAWhB,GAElDgB,GAAYjE,EAASkD,eASrC,OAAO3D,EAAElH,YAGX1D,2BAAA,SACI2K,EAAcS,EACdC,GACFtN,EAAiB,CAAC4M,EAAIS,GAAS,kBAkC/B,IAhCA,IAAMmE,EAAK5N,SAAmB0J,EAASmE,QAAS,WAC1CC,EAAWF,EAAGtP,OACd8K,EAAW5K,KAAKY,SAAS4J,EAAGlK,QAC5BiP,EAAYvP,KAAKY,SAASqK,EAAO3K,QACjCO,YAAC2O,OAAOC,OAAOC,OAEnBjD,cACArB,iBACAC,gBACA4C,eACAd,aACAU,YACAO,gBACAvB,cACAU,aACAP,iBACAU,gBACA5B,eAEI6D,EAASvE,EAAe,EAAIF,EAASO,QAAQG,IAC7CgE,EAAUvE,EAAc,EAAIH,EAASO,QAAQC,KAE7CG,EAAgC,iBAAfC,EACjBC,EAAeqD,EAAG9M,QAAQ,GAC1B0J,EAAaH,EAAiBuD,EAAG9M,QAAQ,GAAK8M,EAAG9M,QAAQ,GACzD2J,EAAaJ,EAAiBuD,EAAG9M,QAAQ,GAAK,EAC9C4J,EAAiBL,EAAiB,EAAIuD,EAAG9M,QAAQ,GACjD6J,EAAe3B,EAAGlI,QAAQ,GAC1B8J,EAAaP,EAAiBrB,EAAGlI,QAAQ,GAAKkI,EAAGlI,QAAQ,GACzD+J,EAAaR,EAAiBrB,EAAGlI,QAAQ,GAAK,EAC9CgK,EAAiBT,EAAiB,EAAIrB,EAAGlI,QAAQ,GAE9C+C,EAAI,EAAGA,EAAIoH,IAAapH,EAC/B,IAAK,IAAI2I,EAAK,EAAGA,EAAKC,IAAcD,EAClC,IAAK,IAAId,EAAK,EAAGA,EAAKC,IAAYD,EAMhC,IALA,IAAMH,EAAWG,EAAKyC,EAChBE,EAAQhK,KAAKb,IAAI,EAAGa,KAAKiK,KAAK/C,EAAWC,IACzC+C,EACFlK,KAAKwB,IAAIwF,GAAYzB,EAAe2B,GAAYC,GAE3CY,EAAK,EAAGA,EAAKC,IAAWD,EAAI,CAOnC,IANA,IAAMH,EAAWG,EAAKgC,EAChBI,EAAQnK,KAAKb,IAAI,EAAGa,KAAKiK,KAAKrC,EAAWC,IACzCuC,EACFpK,KAAKwB,IAAIkG,GAAWlC,EAAcoC,GAAYC,GAE9CwC,EAAU,EACLtD,EAAKiD,EAAOjD,EAAKmD,IAASnD,EAGjC,IAFA,IAAMK,EAAKL,EAAKI,EAAeD,EAEtBO,EAAK0C,EAAO1C,EAAK2C,IAAS3C,EAOjC,IANA,IACM6C,EACFhE,EAAe9G,EAAI+G,EAAaQ,EAAKP,EAAaiB,EAChD8C,EAAYZ,GAASpE,EAAe,EAAI6B,GAC1CwC,GAASpE,EAAc,GAJhBiC,EAAKI,EAAcD,IAIOiC,EAAQ1B,EAEpCG,EAAK,EAAGA,EAAKC,IAAeD,EAAI,CAGvC+B,GAFctF,EAASuF,EAAW7D,EAAiB6B,GACpCoB,EAAUa,EAAYjC,GAO3CmB,EAFiBvD,EAAe1G,EAAI2G,EAAakB,EAC7CjB,EAAa2B,EAAK1B,EAAiB8B,GAClBkC,EAK7B,OAAOd,EAAG7L,YAGZ1D,2BAAA,SACI2K,EAAcS,EACdC,GA6BF,IA5BA,IAAMkE,EAAK5N,SAAmB0J,EAASmE,QAAS,WAC1CC,EAAWF,EAAGtP,OACde,YAACwP,OAAMC,OAAMC,OAAMC,OACnB5F,EAAW5K,KAAKY,SAAS4J,EAAGlK,QAC5BoG,YAAC+J,OAAMC,OAAMC,OAAMC,OACnBrB,EAAYvP,KAAKY,SAASqK,EAAO3K,QACjCuQ,YAACrB,OAAOC,OAAOC,OAAOoB,OAE1BrE,cACA4B,gBACAjD,iBACAC,gBACA4C,eACAc,YACA5B,aACAU,YACAO,gBACAM,aACA7B,cACAU,aACAqB,gBACA5B,iBACAU,gBAEIqD,EAAW1C,EAAc,EAAInD,EAASO,QAAQ+C,MAC9CmB,EAASvE,EAAe,EAAIF,EAASO,QAAQG,IAC7CgE,EAAUvE,EAAc,EAAIH,EAASO,QAAQC,KAE1CrG,EAAI,EAAGA,EAAIoH,IAAapH,EAC/B,IAAK,IAAI2I,EAAK,EAAGA,EAAKC,IAAcD,EAElC,IAAK,IAAIc,EAAK,EAAGA,EAAKC,IAAWD,EAO/B,IANA,IAAMH,EAAWG,EAAKiC,EAChBC,EAAQnL,KAAKb,IAAI,EAAGa,KAAKiK,KAAKnB,EAAWC,IACzCqC,EACFpL,KAAKwB,IAAIqH,GAAWL,EAAcM,GAAYC,GAGzC1B,EAAK,EAAGA,EAAKC,IAAYD,EAMhC,IALA,IAAMH,EAAWG,EAAKyC,EAChBE,EAAQhK,KAAKb,IAAI,EAAGa,KAAKiK,KAAK/C,EAAWC,IACzC+C,EACFlK,KAAKwB,IAAIwF,GAAYzB,EAAe2B,GAAYC,GAE3CY,EAAK,EAAGA,EAAKC,IAAWD,EAAI,CAOnC,IANA,IAAMH,EAAWG,EAAKgC,EAChBI,EAAQnK,KAAKb,IAAI,EAAGa,KAAKiK,KAAKrC,EAAWC,IACzCuC,GACFpK,KAAKwB,IAAIkG,GAAWlC,EAAcoC,GAAYC,GAE9CwC,GAAU,EACLzB,GAAKuC,EAAOvC,GAAKwC,IAASxC,GAGjC,IAFA,IAAMI,GAAKJ,GAAKG,EAAcD,EAErB/B,GAAKiD,EAAOjD,GAAKmD,IAASnD,GAGjC,IAFA,IAAMK,GAAKL,GAAKI,EAAeD,EAEtBO,GAAK0C,EAAO1C,GAAK2C,KAAS3C,GAQjC,IAPA,IACM6C,GACFM,EAAOpL,EAAIqL,EAAOjC,GAAKkC,EAAO/D,GAAKgE,EAAOtD,GACxC8C,GAAYZ,GAASnB,EAAc,EAAIQ,IACzCY,GAASrE,EAAe,EAAI6B,IAC5ByC,GAASrE,EAAc,GALhBiC,GAAKI,EAAcD,IAKOqD,EAAQ9C,EAEpCG,GAAK,EAAGA,GAAKC,IAAeD,GAAI,CAGvC+B,IAFctF,EAASuF,GAAWhC,IACnBoB,EAAUa,GAAYjC,IAM7CmB,EAASe,EAAOhL,EAAIiL,EAAOxB,EAAKyB,EAAOrD,EAAKsD,EAAO5C,EAAKI,GACpDkC,GAMd,OAAOd,EAAG7L,YAGZ1D,4BAAA,SAAgBf,EAAa0L,EAAcU,GAEzCtN,EAAiB,CAACkB,EAAG0L,GAAK,mBAa1B,IAXA,IAAMwC,EAAe9B,EAAS8B,aACxBU,EAAcxC,EAASwC,YACvBtC,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBQ,EAAyC,iBAAxBX,EAASY,WAC1BoF,EAAK1P,SAAmB0J,EAASiG,YAAa,WAE9CvB,EAAU1E,EAASO,QAAQC,KAC3BiE,EAASzE,EAASO,QAAQG,IAC1B9I,EAAO9C,KAAK+C,WAAWjE,GACvBsS,EAAQpR,KAAK+C,WAAWyH,GACrByC,EAAK,EAAGA,EAAK7B,IAAgB6B,EAKpC,IAJA,IAAMoE,EAAQxL,KAAKb,IAAI,EAAGa,KAAKiK,MAAMH,EAAS1C,GAAMD,IAC9C+C,EAAQlK,KAAKwB,IACf6D,EAAS2B,WAAY3B,EAASiC,SAAWwC,EAAS1C,GAAMD,GAEnDW,EAAK,EAAGA,EAAKtC,IAAesC,EAKnC,IAJA,IAAM2D,EAAQzL,KAAKb,IAAI,EAAGa,KAAKiK,MAAMF,EAAUjC,GAAMD,IAC/CuC,EAAQpK,KAAKwB,IACf6D,EAASqC,UAAWrC,EAAS2C,QAAU+B,EAAUjC,GAAMD,GAElDM,EAAK,EAAGA,EAAK9C,EAAS+C,aAAcD,EAC3C,IAAK,IAAIG,EAAK,EAAGA,EAAKjD,EAASkD,cAAeD,EAAI,CAGhD,IADA,IAAI+B,EAAU,EACL7K,EAAI,EAAGA,EAAI6F,EAASuB,YAAapH,EACxC,IAAK,IAAIuH,EAAKyE,EAAOzE,EAAKmD,IAASnD,EAEjC,IADA,IAAMM,EAAKD,EAAKL,EAAKI,EAAe2C,EAC3BrC,EAAKgE,EAAOhE,EAAK2C,IAAS3C,EAAI,CACrC,IAAMM,EAAKD,EAAKL,EAAKI,EAAckC,EAEjCM,GADErE,EAEE/I,EAAK3C,IAAIkF,EAAG6H,EAAIU,EAAII,GAAMoD,EAAMjR,IAAIkF,EAAGuH,EAAIU,EAAIa,GAG/CrL,EAAK3C,IAAIkF,EAAG2I,EAAId,EAAIU,GAAMwD,EAAMjR,IAAIkF,EAAG8I,EAAIvB,EAAIU,GAK3D4D,EAAG3Q,IAAI2P,EAASjD,EAAIU,EAAIK,EAAIG,GAKpC,OAAO+C,EAAG3N,YAGZ1D,4BAAA,SAAgBf,EAAa0L,EAAcU,GAqBzC,IAnBA,IAAM0D,EAAc1D,EAAS0D,YACvB5B,EAAe9B,EAAS8B,aACxBU,EAAcxC,EAASwC,YACvBW,EAAcnD,EAASmD,YACvBjD,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YAEvBkG,EAAK/P,SAAmB0J,EAASiG,YAAa,WAC9CK,EAAWD,EAAGzR,OACde,YAAC4Q,OAAMC,OAAMC,OAAMC,OACnBhH,EAAW5K,KAAKY,SAAS4J,EAAGlK,QAC5BoG,YAAC+J,OAAMC,OAAMC,OAAMC,OACnBiB,EAAU7R,KAAKY,SAAS9B,EAAEwB,QAC1BuQ,YAACiB,OAAKC,OAAKC,OAAKC,OAEhBlB,EAAW7F,EAASO,QAAQ+C,MAC5BoB,EAAU1E,EAASO,QAAQC,KAC3BiE,EAASzE,EAASO,QAAQG,IAEvBiD,EAAK,EAAGA,EAAKR,IAAeQ,EAMnC,IALA,IAAMqD,EAAQrM,KAAKb,IAAI,EAAGa,KAAKiK,MAAMiB,EAAWlC,GAAMD,IAChDqC,EAAQpL,KAAKwB,IACf6D,EAASwD,UAAWxD,EAAS6D,QAAUgC,EAAWlC,GAAMD,GACtDxB,EAAWyB,EAAK4C,EAEbxE,EAAK,EAAGA,EAAK7B,IAAgB6B,EAOpC,IANA,IAAMoE,EAAQxL,KAAKb,IAAI,EAAGa,KAAKiK,MAAMH,EAAS1C,GAAMD,IAC9C+C,EAAQlK,KAAKwB,IACf6D,EAAS2B,WACR3B,EAASiC,SAAWwC,EAAS1C,GAAMD,GAClCgC,EAAW/B,EAAKyE,EAAOtE,EAEpBO,EAAK,EAAGA,EAAKtC,IAAesC,EAOnC,IANA,IAAM2D,EAAQzL,KAAKb,IAAI,EAAGa,KAAKiK,MAAMF,EAAUjC,GAAMD,IAC/CuC,EAAQpK,KAAKwB,IACf6D,EAASqC,UACRrC,EAAS2C,QAAU+B,EAAUjC,GAAMD,GAClCK,EAAWJ,EAAKgE,EAAO3C,EAEpBhB,EAAK,EAAGA,EAAK9C,EAAS+C,aAAcD,EAG3C,IAFA,IAAMmB,EAAWnB,EAAK4D,EAAO7D,EAEpBI,EAAK,EAAGA,EAAKjD,EAASkD,cAAeD,EAAI,CAEhD,IADA,IAAI+B,EAAU,EACL7K,EAAI,EAAGA,EAAI6F,EAASuB,YAAapH,EAIxC,IAHA,IAAMqH,EAAWrH,EAAIyM,EACfnF,EAAWtH,EAAIoL,EAEZhC,EAAKyD,EAAOzD,EAAKwC,IAASxC,EAKjC,IAJA,IACMpB,GADKwB,EAAKJ,EAAKG,EAAcmC,GACbgB,EAAMrF,EACtBI,EAAW2B,EAAKiC,EAAO/D,EAEpBC,GAAKyE,EAAOzE,GAAKmD,IAASnD,GAKjC,IAJA,IACMkB,IADKb,EAAKL,GAAKI,EAAe2C,GACdqC,EAAM3E,EACtBG,GAAWZ,GAAK+D,EAAO7D,EAEpBQ,GAAKgE,EAAOhE,GAAK2C,IAAS3C,GAAI,CACrC,IAEM2B,GAAW3B,GAAKsD,EAAOpD,GAE7B0C,GACI2B,GALOlE,EAAKL,GAAKI,EAAckC,GACbqC,EAAMnE,GAILE,GAAMpD,EAASqE,GAAWd,GAKzDqD,EAASrC,EAAWhB,GAAM+B,EAMpC,OAAOqB,EAAGhO,YAGZ1D,iCAAA,SACIgB,OAACmK,UAAOC,WAAQC,aAAUzD,SAAM1I,eAAYC,2BAE1CwF,EAASxE,KAAKmS,gBAAgBnH,EAAOC,EAAQC,GAYjD,OAVIzD,IAGFjD,EAASmD,MAAOnD,EAAQiD,IAEtB1I,IACFyF,EACI5F,EAAcoB,KAAMwE,EAAQzF,EAAYC,IAGvCwF,GAGT3E,4BAAA,SACIf,EAAamM,EACbC,GACFtN,EAAiB,CAACkB,EAAGmM,GAAS,mBAc9B,IAZA,IAAMG,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAUN,EAASO,QAAQC,KAC3BC,EAAST,EAASO,QAAQG,IAC1BwG,EAAQlH,EAASkD,YAAclD,EAAS+C,WACxCxD,EAAIjJ,SAAU0J,EAAS3I,SAAUzD,EAAET,OACnCmF,EAAQxD,KAAKY,SAAS9B,EAAEwB,QACxBiM,EAAQvM,KAAKY,SAASqK,EAAO3K,QAC7BkM,EAAQ/B,EAAE3K,OAEPuF,EAAI,EAAGA,EAAI6F,EAASuB,YAAapH,EAGxC,IAFA,IAAMqH,EAAWrH,EAAIvG,EAAEwD,QAAQ,GACzBqK,EAAWtH,EAAIoF,EAAEnI,QAAQ,GACtBsK,EAAK,EAAGA,EAAK1B,EAAS2B,YAAaD,EAG1C,IAFA,IAAME,EAAWH,EAAWC,EAAKnC,EAAEnI,QAAQ,GACrCyK,EAAWH,EAAK1B,EAAS8B,aAAexB,EACrCyB,EAAK,EAAGA,EAAK7B,IAAgB6B,EAAI,CACxC,IAAMC,EAAKH,EAAWE,EAAK3B,EAC3B,KAAI4B,EAAK,GAAKA,GAAMhC,EAASiC,UAK7B,IAFA,IAAMC,EAAWH,EAAKhC,EAAO3I,QAAQ,GAC/B+K,EAAWX,EAAWQ,EAAKpO,EAAEwD,QAAQ,GAClCgL,EAAK,EAAGA,EAAKpC,EAASqC,WAAYD,EAGzC,IAFA,IAAME,EAAWV,EAAWQ,EAAK7C,EAAEnI,QAAQ,GACrCmL,EAAWH,EAAKpC,EAASwC,YAAc/B,EACpCgC,EAAK,EAAGA,EAAKtC,IAAesC,EAAI,CACvC,IAAMC,EAAKH,EAAWE,EAAKpC,EAC3B,KAAIqC,EAAK,GAAKA,GAAM1C,EAAS2C,SAO7B,IAJA,IAAMmB,EAAW5B,EAAWO,EAAK1C,EAAO3I,QAAQ,GAC1CwL,EAAWT,EAAWO,EAAK1C,EAAS+C,WACtCgB,EAAWzB,EACXO,EAAWiB,EACNhB,EAAK,EAAGA,EAAK9C,EAAS+C,aAAcD,EAAI,CAE/C,IADA,IAAME,EAAO1K,EAAMsK,EAAWE,GACrBqE,EAAI,EAAGA,EAAID,IAASC,EAC3B7F,EAAMyC,EAAWoD,IAAMnE,EAAO3B,EAAMwB,EAAWsE,GAEjDpD,GAAYmD,EACZrE,GAAYqE,IAQxB,OAAO3H,EAAElH,YAGX1D,oCAAA,SACI2K,EAAcS,EACdC,GACFtN,EAAiB,CAAC4M,EAAIS,GAAS,2BA0B/B,IAxBA,IAAMmE,EAAK5N,SAAmB0J,EAASmE,QAAS,WAC1CC,EAAWF,EAAGtP,OACde,YAACwP,OAAMC,OAAMC,OACb3F,EAAW5K,KAAKY,SAAS4J,EAAGlK,QAC5BoG,YAAC+J,OAAMC,OAAMC,OACbpB,EAAYvP,KAAKY,SAASqK,EAAO3K,QACjCuQ,YAACrB,OAAOC,OAAOC,OAEnBjD,cACArB,iBACAC,gBACA4C,eACAd,aACAU,YACAO,gBACAvB,cACAU,aACAP,iBACAU,gBAEIiC,EAASvE,EAAe,EAAIF,EAASO,QAAQG,IAC7CgE,EAAUvE,EAAc,EAAIH,EAASO,QAAQC,KAC7C0G,EAAQhE,EAAcH,EAEnB5I,EAAI,EAAGA,EAAIoH,IAAapH,EAC/B,IAAK,IAAI2I,EAAK,EAAGA,EAAKC,IAAcD,EAClC,IAAK,IAAId,EAAK,EAAGA,EAAKC,IAAYD,EAMhC,IALA,IAAMH,EAAWG,EAAKyC,EAChBE,EAAQhK,KAAKb,IAAI,EAAGa,KAAKiK,KAAK/C,EAAWC,IACzC+C,EACFlK,KAAKwB,IAAIwF,GAAYzB,EAAe2B,GAAYC,GAE3CY,EAAK,EAAGA,EAAKC,IAAWD,EAAI,CAOnC,IANA,IAAMH,EAAWG,EAAKgC,EAChBI,EAAQnK,KAAKb,IAAI,EAAGa,KAAKiK,KAAKrC,EAAWC,IACzCuC,EACFpK,KAAKwB,IAAIkG,GAAWlC,EAAcoC,GAAYC,GAE9CwC,EAAU,EACLtD,EAAKiD,EAAOjD,EAAKmD,IAASnD,EAGjC,IAFA,IAAMK,EAAKL,EAAKI,EAAeD,EAEtBO,EAAK0C,EAAO1C,EAAK2C,IAAS3C,EAMjC,IALA,IACM6C,EAAWM,EAAOpL,EAAIqL,EAAO9D,EAAK+D,EAAOrD,EACzC8C,EAAYZ,GAASpE,EAAe,EAAI6B,GAC1CwC,GAASpE,EAAc,GAHhBiC,EAAKI,EAAcD,IAGOiC,EAAQ1B,EAEpCsE,EAAK,EAAGA,EAAKF,IAASE,EAAI,CAIjCpC,GAFctF,EAASuF,GADZnC,EAAKoE,EAAQE,IAET/C,EAAUa,EAAYkC,GAK3ChD,EAASe,EAAOhL,EAAIiL,EAAOpD,EAAKqD,EAAO3C,EAAKI,GAAMkC,EAK1D,OAAOd,EAAG7L,YAGZ1D,qCAAA,SACIf,EAAa0L,EAAcU,GAC7BtN,EAAiB,CAACkB,EAAG0L,GAAK,4BAc1B,IAZA,IAAMwC,EAAe9B,EAAS8B,aACxBU,EAAcxC,EAASwC,YACvBtC,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvB6F,EAAK1P,SAAmB0J,EAASiG,YAAa,WAE9CvB,EAAU1E,EAASO,QAAQC,KAC3BiE,EAASzE,EAASO,QAAQG,IAC1BwG,EAAQlH,EAASkD,YAAclD,EAAS+C,WAExCnL,EAAO9C,KAAK+C,WAAWjE,GACvBsS,EAAQpR,KAAK+C,WAAWyH,GACrByC,EAAK,EAAGA,EAAK7B,IAAgB6B,EAKpC,IAJA,IAAMoE,EAAQxL,KAAKb,IAAI,EAAGa,KAAKiK,MAAMH,EAAS1C,GAAMD,IAC9C+C,EAAQlK,KAAKwB,IACf6D,EAAS2B,WAAY3B,EAASiC,SAAWwC,EAAS1C,GAAMD,GAEnDW,EAAK,EAAGA,EAAKtC,IAAesC,EAKnC,IAJA,IAAM2D,EAAQzL,KAAKb,IAAI,EAAGa,KAAKiK,MAAMF,EAAUjC,GAAMD,IAC/CuC,EAAQpK,KAAKwB,IACf6D,EAASqC,UAAWrC,EAAS2C,QAAU+B,EAAUjC,GAAMD,GAElDS,EAAK,EAAGA,EAAKjD,EAASkD,cAAeD,EAAI,CAKhD,IAJA,IAAMH,EAAKnI,KAAK0M,MAAMpE,EAAKiE,GACrBE,EAAKnE,EAAKiE,EAEZlC,EAAU,EACL7K,EAAI,EAAGA,EAAI6F,EAASuB,YAAapH,EACxC,IAAK,IAAIuH,EAAKyE,EAAOzE,EAAKmD,IAASnD,EAEjC,IADA,IAAMM,EAAKD,EAAKL,EAAKI,EAAe2C,EAC3BrC,EAAKgE,EAAOhE,EAAK2C,IAAS3C,EAAI,CACrC,IAAMM,EAAKD,EAAKL,EAAKI,EAAckC,EACnCM,GAAWpN,EAAK3C,IAAIkF,EAAG6H,EAAIU,EAAII,GAAMoD,EAAMjR,IAAIkF,EAAGuH,EAAIU,EAAIa,GAIhE+C,EAAG3Q,IAAI2P,EAASjD,EAAIU,EAAIK,EAAIsE,GAIlC,OAAOpB,EAAG3N,YAGZ1D,iBAAA,SAAuBf,EAAM0T,GAE3B,OADA5U,EAAiBkB,EAAG,QACbL,EAAKuB,KAAK+C,WAAWjE,GAAI0T,IAGlC3S,mBAAA,SAAyBf,EAAM2T,EAAmB9P,GAChD/E,EAAiB,CAACkB,EAAG2T,GAAU,UAE/B,IAAMC,EAAqB5T,EAAEiB,MAAM+D,QAC7B6O,EAAgB3S,KAAKY,SAAS6R,EAAQnS,QAC5CoS,EAAS/P,GAAQgQ,EAActP,OAI/B,IAHA,IAAMmB,EAAShD,SAAUkR,EAAU5T,EAAET,OAC/ByE,EAAO9C,KAAK+C,WAAWjE,GAEpBkE,EAAI,EAAGA,EAAIwB,EAAOvB,OAAQD,EAAG,CACpC,IAAMI,EAASoB,EAAOrB,WAAWH,GAE3B4P,EAAwBxP,EAAOU,QACrC8O,EAAYjQ,GAAQgQ,EAAcvP,EAAOT,IAEzC,IAAMkQ,EAAgB/P,EAAKgQ,WAAWF,GACtCpO,EAAO1E,OAAOkD,GAAKF,EAAKhD,OAAO+S,GAEjC,OAAOrO,EAAOjB,YAGhB1D,2BAAA,SACIf,EAAMiU,EAAsBC,GAC9BpV,EAAiB,CAACkB,GAAI,kBAEtB,IAAMwJ,EAAOyK,EAAWE,QAAO,SAAC9N,EAAGE,GAAM,OAAAF,EAAIE,KAEvC6N,EAAW9S,eAAa+S,YAAYrU,EAAEiB,MAAOgT,EAAYzK,GACzD8K,EACFhT,eAAaiT,YAAYH,EAAS7P,OAAQ0P,EAAW1P,QACnDiQ,EACFlT,eAAamT,oBAAoBzU,EAAEiB,MAAOgT,EAAYzK,GACpDkL,EACFpT,eAAaqT,oBAAoBT,EAAOD,EAAW1P,QACjDqQ,EACFtT,eAAauT,aAAaL,EAAkBN,EAAOD,EAAW1P,QAElE,OAAOuQ,YAAa9U,EAAEmF,QAAQiP,GAAWE,GAC7BnP,QAAQqP,GACRxP,MAAM0P,EAAkBE,IAG9B7T,mBAAR,SACIf,EAAaoM,EACb2I,GACFjW,EAAiBkB,EAAG,UA8BpB,IA5BA,IAAM8P,EAAc1D,EAAS0D,YACvB5B,EAAe9B,EAAS8B,aACxBU,EAAcxC,EAASwC,YACvBY,EAAgBpD,EAASoD,cACzBhD,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBuI,EAAuB5I,EAAS4I,qBAChCC,EAAwB7I,EAAS6I,sBACjCC,EAAuB9I,EAAS8I,qBAChCzF,EAAWrD,EAASO,QAAQ+C,MAC5B7C,EAAST,EAASO,QAAQG,IAC1BJ,EAAUN,EAASO,QAAQC,KAE3BuI,EACY,QAAbJ,EAAqBK,OAAOC,kBACPD,OAAOE,kBAE3BvC,EAAU7R,KAAKY,SAAS9B,EAAEwB,QAC1B+T,EAAS7S,SAAU0J,EAAS3I,SAAUzD,EAAET,OACxCiW,EAAaD,EAAOvU,OAEpByU,EAAqBrJ,EAAS3I,SAAS,GAAK2I,EAAS3I,SAAS,GAChE2I,EAAS3I,SAAS,GAAK2I,EAAS3I,SAAS,GACvCiS,EACFtJ,EAAS3I,SAAS,GAAK2I,EAAS3I,SAAS,GAAK2I,EAAS3I,SAAS,GAC9DkS,EAAmBvJ,EAAS3I,SAAS,GAAK2I,EAAS3I,SAAS,GAC5DmS,EAAmBxJ,EAAS3I,SAAS,GAElCoS,EAAQ,EAAGA,EAAQzJ,EAASuB,YAAakI,EAGhD,IAFA,IAAMC,EAAoBD,EAAQJ,EAC5BM,EAAmBF,EAAQ7V,EAAEwD,QAAQ,GAClCwS,EAAU,EAAGA,EAAU5J,EAAS+C,aAAc6G,EACrD,IAAK,IAAIC,EAAS,EAAGA,EAAS7J,EAASwD,WAAYqG,EAAQ,CAGzD,IAFA,IAAMC,EAAeD,EAASnG,EAAcL,EACxC0G,EAAYD,EACTC,EAAY,GACjBA,GAAa3G,EAMf,IAJA,IAAM4G,EACFrP,KAAKwB,IAAI6D,EAAS6D,QAAS+E,EAAuBkB,GAChDG,EACFP,EAAoBG,EAASP,EACxBY,EAAO,EAAGA,EAAOlK,EAAS2B,YAAauI,EAAM,CAGpD,IAFA,IAAMC,EAAaD,EAAOpI,EAAerB,EACrC2J,EAAUD,EACPC,EAAU,GACfA,GAAWhK,EAKb,IAHA,IAAMiK,EACF1P,KAAKwB,IAAI6D,EAASiC,SAAU4G,EAAwBsB,GAClDG,EAAkBL,EAAoBC,EAAOX,EAC1CgB,EAAO,EAAGA,EAAOvK,EAASqC,WAAYkI,EAAM,CAGnD,IAFA,IAAMC,EAAaD,EAAO/H,EAAclC,EACpCmK,EAAUD,EACPC,EAAU,GACfA,GAAWpK,EASb,IAPA,IAAMqK,EACF/P,KAAKwB,IAAI6D,EAAS2C,QAASmG,EAAuB0B,GAEhDG,EAAkBL,EAAkBC,EAAOf,EAC7CoB,EAAc7B,EACd8B,EAAW,EACXC,EAAQ,EACHC,EAAShB,EAAWgB,EAASf,EACjCe,GAAU3H,EAAe,CAE5B,IADA,IAAM4H,EAAerB,EAAmBoB,EAASnX,EAAEwD,QAAQ,GAClD6T,EAAOb,EAASa,EAAOZ,EAC3BY,GAAQ7K,EAAgB,CAE3B,IADA,IAAM8K,EAAaF,EAAeC,EAAOrX,EAAEwD,QAAQ,GAC1C+T,EAAOV,EAASU,EAAOT,EAC3BS,GAAQ9K,EAAe,CAC1B,IACM+K,EAAQzE,EADKuE,EAAaC,EAAOvX,EAAEwD,QAAQ,GACdwS,GAOnC,GANkB,QAAbjB,GAAsByC,EAAQR,EACjCA,EAAcQ,EACQ,QAAbzC,IACTkC,GAAYO,EACZN,KAEEO,MAAMT,GACR,MAGJ,GAAIS,MAAMT,GACR,MAGJ,GAAIS,MAAMT,GACR,MAIJxB,EADqBuB,EAAkBf,GAEtB,QAAbjB,EAAqBkC,EAAWC,EAAQF,IAMtD,OAAOzB,EAAO9Q,YAGhB1D,sBAAA,SAAUf,EAAaoM,GAGrB,OAFAtN,EAAiBkB,EAAG,aAEbkB,KAAKwW,OAAO1X,EAAGoM,EAAU,OAAOuL,WAGzC5W,8BAAA,SACI2K,EAAc1L,EAAaoM,GAC7BtN,EAAiB,CAAC4M,EAAI1L,GAAI,qBAuB1B,IArBA,IAAM8P,EAAc1D,EAAS0D,YACvB5B,EAAe9B,EAAS8B,aACxBU,EAAcxC,EAASwC,YACvBW,EAAcnD,EAASmD,YACvBjD,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBiD,EAAgBpD,EAASoD,cACzBhD,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBuI,EAAuB5I,EAAS4I,qBAChCC,EAAwB7I,EAAS6I,sBACjCC,EAAuB9I,EAAS8I,qBAChCzF,EAAWuF,EAAuB,EAAI5I,EAASO,QAAQ+C,MACvDhD,EAAUwI,EAAuB,EAAI9I,EAASO,QAAQC,KACtDC,EAASoI,EAAwB,EAAI7I,EAASO,QAAQG,IACtDwD,EAAK5N,SAAmB1C,EAAEiB,MAAO,WAEjC2W,EAAgB,GAAKrI,EAAcjD,EAAeC,GAElD+F,EAAQpR,KAAK+C,WAAWyH,GAErBmK,EAAQ,EAAGA,EAAQzJ,EAASuB,YAAakI,EAChD,IAAK,IAAIG,EAAU,EAAGA,EAAU5J,EAAS+C,aAAc6G,EACrD,IAAK,IAAI6B,EAAU,EAAGA,EAAUzL,EAAS6D,UAAW4H,EAClD,IAAK,IAAIC,EAAQ,EAAGA,EAAQ1L,EAASiC,WAAYyJ,EAC/C,IAAK,IAAIC,EAAQ,EAAGA,EAAQ3L,EAAS2C,UAAWgJ,EAAO,CAMrD,IAJA,IAAMC,EAAgBH,EAAUpI,EAC1BwI,EAAcH,EAAQjL,EACtBqL,EAAcH,EAAQrL,EACxB0E,EAAU,EACL+G,EAAS,EAAGA,EAASnD,EACzBmD,GAAU3I,EAAe,CAC5B,IAAM4I,GAAWJ,EAAgBG,GAAUrI,EAC3C,KAAIsI,EAAU,GAAKA,GAAWhM,EAASwD,UACnC7I,KAAK+B,MAAMsP,KAAaA,GAG5B,IAAK,IAAIC,EAAO,EAAGA,EAAOpD,EACrBoD,GAAQ7L,EAAgB,CAC3B,IAAM8L,GAASL,EAAcI,GAAQnK,EACrC,KAAIoK,EAAQ,GAAKA,GAASlM,EAAS2B,WAC/BhH,KAAK+B,MAAMwP,KAAWA,GAG1B,IAAK,IAAIC,EAAO,EAAGA,EAAOrD,EACrBqD,GAAQ9L,EAAe,CAC1B,IAAM+L,GAASN,EAAcK,GAAQ3J,EACrC,KAAI4J,EAAQ,GAAKA,GAASpM,EAASqC,UAC/B1H,KAAK+B,MAAM0P,KAAWA,GAM1BpH,GADIkB,EAAMjR,IAAIwU,EAAOuC,EAASE,EAAOE,EAAOxC,KAKlD1F,EAAG7O,IACC2P,EAAUwG,EAAe/B,EAAOgC,EAASC,EAAOC,EAChD/B,GAMd,OAAO1F,EAAG7L,YAGZ1D,sBAAA,SAAUf,EAAaoM,GAGrB,OAFAtN,EAAiBkB,EAAG,aAEbkB,KAAKwW,OAAO1X,EAAGoM,EAAU,OAAOuL,WAGjC5W,+BAAR,SAA2Bf,EAAaoM,GAiBtC,IAfA,IAAMqM,EAAe/V,SAAU0J,EAAS3I,SAAU,SAC5CqM,EAAc1D,EAAS0D,YACvB5B,EAAe9B,EAAS8B,aACxBU,EAAcxC,EAASwC,YACvBY,EAAgBpD,EAASoD,cACzBhD,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBuI,EAAuB5I,EAAS4I,qBAChCC,EAAwB7I,EAAS6I,sBACjCC,EAAuB9I,EAAS8I,qBAChCzF,EAAWrD,EAASO,QAAQ+C,MAC5B7C,EAAST,EAASO,QAAQG,IAC1BJ,EAAUN,EAASO,QAAQC,KAE3B5I,EAAO9C,KAAK+C,WAAWjE,GACpB6V,EAAQ,EAAGA,EAAQzJ,EAASuB,YAAakI,EAChD,IAAK,IAAIG,EAAU,EAAGA,EAAU5J,EAAS+C,aAAc6G,EACrD,IAAK,IAAIC,EAAS,EAAGA,EAAS7J,EAASwD,WAAYqG,EAAQ,CAGzD,IAFA,IAAMC,EAAeD,EAASnG,EAAcL,EACxC0G,EAAYD,EACTC,EAAY,GACjBA,GAAa3G,EAIf,IAFA,IAAM4G,EACFrP,KAAKwB,IAAI6D,EAAS6D,QAAS+E,EAAuBkB,GAC7CI,EAAO,EAAGA,EAAOlK,EAAS2B,YAAauI,EAAM,CAGpD,IAFA,IAAMC,EAAaD,EAAOpI,EAAerB,EACrC2J,EAAUD,EACPC,EAAU,GACfA,GAAWhK,EAIb,IAFA,IAAMiK,EACF1P,KAAKwB,IAAI6D,EAASiC,SAAU4G,EAAwBsB,GAC/CI,EAAO,EAAGA,EAAOvK,EAASqC,WAAYkI,EAAM,CAGnD,IAFA,IAAMC,EAAaD,EAAO/H,EAAclC,EACpCmK,EAAUD,EACPC,EAAU,GACfA,GAAWpK,EASb,IAPA,IAAMqK,EACF/P,KAAKwB,IAAI6D,EAAS2C,QAASmG,EAAuB0B,GAGlD8B,EAAWtD,OAAOC,kBAClBsD,GAAe,EAEVxB,EAAShB,EAAWgB,EAASf,EACjCe,GAAU3H,EAEb,IADA,IAAM2I,EAAShB,EAASjB,EACfmB,EAAOb,EAASa,EAAOZ,EAC3BY,GAAQ7K,EAEX,IADA,IAAM6L,EAAOhB,EAAOd,EACXgB,EAAOV,EAASU,EAAOT,EAC3BS,GAAQ9K,EAAe,CAC1B,IAAM8L,EAAOhB,EAAOX,EACdY,EAAQxT,EAAK3C,IAAIwU,EAAOsB,EAAQE,EAAME,EAAMvB,GAC9CwB,GAASkB,IACXA,EAAWlB,EACXmB,EAAcR,EAASlD,EACfC,EACJmD,EAAOpD,EAAwBsD,GAM3CE,EAAahX,IAAIkX,EAAa9C,EAAOI,EAAQK,EAAMK,EAAMX,KAMnE,OAAOyC,EAAahU,YAGtB1D,8BAAA,SACI2K,EAAc1L,EAAa2L,EAC3BS,GACFtN,EAAiB,CAACkB,EAAG2L,GAAI,qBAoBzB,IAlBA,IAAM8M,EAAevX,KAAK0X,mBAAmB5Y,EAAGoM,GAC1C0D,EAAc1D,EAAS0D,YACvB5B,EAAe9B,EAAS8B,aACxBU,EAAcxC,EAASwC,YACvBY,EAAgBpD,EAASoD,cACzBhD,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBuI,EAAuB5I,EAAS4I,qBAChCC,EAAwB7I,EAAS6I,sBACjCC,EAAuB9I,EAAS8I,qBAChCzF,EAAWuF,EAAuB,EAAI5I,EAASO,QAAQ+C,MACvDhD,EAAUwI,EAAuB,EAAI9I,EAASO,QAAQC,KACtDC,EAASoI,EAAwB,EAAI7I,EAASO,QAAQG,IACtDwD,EAAK5N,SAAmB1C,EAAEiB,MAAO,WAEjC4X,EAAY3X,KAAK+C,WAAWwU,GAC5BnG,EAAQpR,KAAK+C,WAAWyH,GAErBmK,EAAQ,EAAGA,EAAQzJ,EAASuB,YAAakI,EAChD,IAAK,IAAIG,EAAU,EAAGA,EAAU5J,EAAS+C,aAAc6G,EACrD,IAAK,IAAI6B,EAAU,EAAGA,EAAUzL,EAAS6D,UAAW4H,EAClD,IAAK,IAAIC,EAAQ,EAAGA,EAAQ1L,EAASiC,WAAYyJ,EAC/C,IAAK,IAAIC,EAAQ,EAAGA,EAAQ3L,EAAS2C,UAAWgJ,EAAO,CAMrD,IAJA,IAAMC,EAAgBH,EAAUpI,EAC1BwI,EAAcH,EAAQjL,EACtBqL,EAAcH,EAAQrL,EACxB0E,EAAU,EACL+G,EAAS,EAAGA,EAASnD,EACzBmD,GAAU3I,EAAe,CAC5B,IAAM4I,GAAWJ,EAAgBG,GAAUrI,EAC3C,KAAIsI,EAAU,GAAKA,GAAWhM,EAASwD,UACnC7I,KAAK+B,MAAMsP,KAAaA,GAG5B,IAAK,IAAIC,EAAO,EAAGA,EAAOpD,EACrBoD,GAAQ7L,EAAgB,CAC3B,IAAM8L,GAASL,EAAcI,GAAQnK,EACrC,KAAIoK,EAAQ,GAAKA,GAASlM,EAAS2B,WAC/BhH,KAAK+B,MAAMwP,KAAWA,GAG1B,IAAK,IAAIC,EAAO,EAAGA,EAAOrD,EACrBqD,GAAQ9L,EAAe,CAC1B,IAAM+L,GAASN,EAAcK,GAAQ3J,EACrC,KAAI4J,EAAQ,GAAKA,GAASpM,EAASqC,UAC/B1H,KAAK+B,MAAM0P,KAAWA,GAD1B,CAKA,IAQMM,EARS9D,EACPC,EAAwBC,EAC5B,EACA2D,EAAUxX,IAAIwU,EAAOuC,EAASE,EAAOE,EAAOxC,KAE5CmC,EAASlD,EAAwBC,EACjCmD,EAAOnD,EAAuBqD,EAED,EAAI,EACrC,GAAa,IAATO,EAMJ1H,GADIkB,EAAMjR,IAAIwU,EAAOuC,EAASE,EAAOE,EAAOxC,GACzB8C,KAIzBxI,EAAG7O,IAAI2P,EAASyE,EAAOgC,EAASC,EAAOC,EAAO/B,GAMxD,OAAO1F,EAAG7L,YAGZ1D,2BAAA,SACIf,EAAa+Y,EAAmBC,EAChCC,GACFna,EAAiBkB,EAAG,kBAqBpB,IAnBM,IAAA+B,UAAC8T,OAAOqD,OAAWC,OAAUC,OAC7BrG,EAAU7R,KAAKY,SAAS9B,EAAEwB,QAC1BkE,EAAS,IAAImG,aACfxM,OAAKgK,cAAc,CAACwM,EAAOkD,EAAWC,EAAUI,KAE9CC,EAAuC,CAC1CJ,GAAgBF,EAAY,EAAKG,EAAY,EAAIA,EACjDD,GAAgBD,EAAW,EAAKG,EAAW,EAAIA,GAG5CG,EAAwC,CAC3CL,GAAgBF,EAAY,EAAKA,EAAY,EAAIA,EACjDE,GAAgBD,EAAW,EAAKA,EAAW,EAAIA,GAE9CO,EAAY,EACVC,EACFH,EAAmB,GAAKC,EAAoB,GAC1CG,EACFJ,EAAmB,GAAKC,EAAoB,GACvC/S,EAAI,EAAGA,EAAIsP,EAAOtP,IACzB,IAAK,IAAImT,EAAI,EAAGA,EAAIX,EAAWW,IAO7B,IANA,IAAMC,EAAgBH,EAAwBE,EACxCE,EAAiB7S,KAAK+B,MAAM6Q,GAC5BE,EAAUF,EAAgBC,EAC1BE,EAAgB/S,KAAKwB,IAAI2Q,EAAY,EAAGnS,KAAKiK,KAAK2I,IAClDI,EAAexT,EAAIvG,EAAEwD,QAAQ,GAAKoW,EAAiB5Z,EAAEwD,QAAQ,GAC7DwW,EAAezT,EAAIvG,EAAEwD,QAAQ,GAAKsW,EAAgB9Z,EAAEwD,QAAQ,GACzDyW,EAAI,EAAGA,EAAIjB,EAAUiB,IAU5B,IATA,IAAMC,EAAgBT,EAAwBQ,EACxCE,EAAiBpT,KAAK+B,MAAMoR,GAC5BE,EAAUF,EAAgBC,EAC1BE,EACFtT,KAAKwB,IAAI4Q,EAAW,EAAGpS,KAAKiK,KAAKkJ,IAC/BI,EAAgBP,EAAeI,EAAiBna,EAAEwD,QAAQ,GAC1D+W,EAAgBP,EAAeG,EAAiBna,EAAEwD,QAAQ,GAC1DgX,EAAiBT,EAAeM,EAAgBra,EAAEwD,QAAQ,GAC1DiX,EAAiBT,EAAeK,EAAgBra,EAAEwD,QAAQ,GACvDhB,EAAI,EAAGA,EAAI4W,EAAa5W,IAAK,CAIpC,IAAMkY,EAAU3H,EAAQuH,EAAgB9X,GAClCmY,EAAa5H,EAAQwH,EAAgB/X,GAIrCoY,EAAMF,GAHK3H,EAAQyH,EAAiBhY,GAGRkY,GAAWN,EAEvCS,EAAWD,GADFD,GAHK5H,EAAQ0H,EAAiBjY,GAGFmY,GAAcP,EACxBQ,GAAOf,EAExCnU,EAAO6T,KAAesB,EAK9B,OAAO/W,SAAU4B,EAAQ,CAACmQ,EAAOkD,EAAWC,EAAUI,KAGxDrY,mCAAA,SAAuB2K,EAAc1L,EAAaiZ,GAChDna,EAAiB,CAAC4M,EAAI1L,GAAI,0BA+B1B,IA7BM,IAAA+B,UAAC8T,OAAOiF,OAASC,OAAQC,OACzBpT,UAAGqT,OAASC,OAEZ3F,EAAS,IAAI1J,aAAagK,EAAQiF,EAAUC,EAASC,GAOrDG,EAAmC,CACtClC,GAAgBgC,EAAU,EAAKH,EAAU,EAAIA,EAC7C7B,GAAgBiC,EAAS,EAAKH,EAAS,EAAIA,GAGxCK,EAAmC,CACtCnC,GAAgBgC,EAAU,EAAKA,EAAU,EAAIA,EAC7ChC,GAAgBiC,EAAS,EAAKA,EAAS,EAAIA,GAGxCG,EAAcF,EAAe,GAAKC,EAAe,GACjDE,EAAaH,EAAe,GAAKC,EAAe,GAMhDtP,EAAW5K,KAAKY,SAAS4J,EAAGlK,QAC9B+H,EAAS,EACJhD,EAAI,EAAGA,EAAIsP,EAAOtP,IAEzB,IADA,IAAMgV,EAAUhV,EAAIvG,EAAEwD,QAAQ,GACrBkW,EAAI,EAAGA,EAAIuB,EAASvB,IAU3B,IATA,IAAM8B,EAAM9B,EAAI2B,EACVI,EAAc1U,KAAK+B,MAAM0S,GACzBE,EAAiB3U,KAAKwB,IAAIxB,KAAKiK,KAAKwK,GAAMV,EAAU,GAEpDa,EAAeJ,EAAUE,EAAczb,EAAEwD,QAAQ,GACjDoY,EAAkBL,EAAUG,EAAiB1b,EAAEwD,QAAQ,GAEvDqY,EAAUL,EAAMC,EAChBK,EAAiB,EAAMD,EACpB5B,EAAI,EAAGA,EAAIiB,EAAQjB,IAmB1B,IAlBA,IAAM8B,EAAM9B,EAAIqB,EACVU,EAAejV,KAAK+B,MAAMiT,GAC1BE,EAAgBlV,KAAKwB,IAAIxB,KAAKiK,KAAK+K,GAAMhB,EAAS,GAClDmB,EAAUH,EAAMC,EAChBG,EAAiB,EAAMD,EAEvBE,EAAkBT,EAAeK,EAAehc,EAAEwD,QAAQ,GAC1D6Y,EAAmBV,EAAeM,EAAgBjc,EAAEwD,QAAQ,GAC5D8Y,EACFV,EAAkBI,EAAehc,EAAEwD,QAAQ,GACzC+Y,EACFX,EAAkBK,EAAgBjc,EAAEwD,QAAQ,GAE1CgZ,EACFV,EAAiBK,EACfM,EAA6BX,EAAiBI,EAC9CQ,EAA6Bb,EAAUM,EACvCQ,EAAsBd,EAAUK,EAC7B1Z,EAAI,EAAGA,EAAIwY,EAAOxY,IAAK,CAC9B,IAAMoa,EAAQ9Q,EAASvC,KACvBgM,EAAO6G,EAAkB5Z,IACrBoa,EAAQJ,EACZjH,EAAO8G,EAAmB7Z,IAAMoa,EAAQH,EACxClH,EAAO+G,EAAqB9Z,IACxBoa,EAAQF,EACZnH,EAAOgH,EAAsB/Z,IAAMoa,EAAQD,EAKnD,OAAOE,WAAYtH,EAAQ,CAACM,EAAOkF,EAAQD,EAASE,GAAQhb,EAAET,QAGhEwB,kCAAA,SACIf,EAAa+Y,EAAmBC,EAChCC,GACFna,EAAiBkB,EAAG,yBAsBpB,IApBM,IAAA+B,UAAC8T,OAAOqD,OAAWC,OAAUC,OAC7BrG,EAAU7R,KAAKY,SAAS9B,EAAEwB,QAC1B+T,EAAS,IAAI1J,aAAagK,EAAQkD,EAAYC,EAAWI,GAEzDC,EAAuC,CAC1CJ,GAAgBF,EAAY,EAAKG,EAAY,EAAIA,EACjDD,GAAgBD,EAAW,EAAKG,EAAW,EAAIA,GAG5CG,EAAwC,CAC3CL,GAAgBF,EAAY,EAAKA,EAAY,EAAIA,EACjDE,GAAgBD,EAAW,EAAKA,EAAW,EAAIA,GAG5CQ,EACFH,EAAmB,GAAKC,EAAoB,GAC1CG,EACFJ,EAAmB,GAAKC,EAAoB,GAE5CwD,EAAe,EACVvW,EAAI,EAAGA,EAAIsP,EAAOtP,IAEzB,IADA,IAAMwW,EAAcxW,EAAIvG,EAAEwD,QAAQ,GACzBkW,EAAI,EAAGA,EAAIX,EAAWW,IAO7B,IANA,IAAMC,EAAgBH,EAAwBE,EAKxCsD,EAAYD,EAJOhW,KAAKwB,IAC1B2Q,EAAY,EACZD,EAAelS,KAAKkW,MAAMtD,GACX5S,KAAK+B,MAAM6Q,IACqB3Z,EAAEwD,QAAQ,GACpDyW,EAAI,EAAGA,EAAIjB,EAAUiB,IAO5B,IANA,IAAMC,EAAgBT,EAAwBQ,EAKxCiD,EAAYF,EAJOjW,KAAKwB,IAC1B4Q,EAAW,EACXF,EAAelS,KAAKkW,MAAM/C,GACXnT,KAAK+B,MAAMoR,IACmBla,EAAEwD,QAAQ,GAClDhB,EAAI,EAAGA,EAAI4W,EAAa5W,IAAK,CAGpC,IAAM2a,EAASpK,EAAQmK,EAAY1a,GACnC+S,EAAOuH,KAAkBK,EAKjC,OAAOrZ,SACHyR,EAAQ,CAACM,EAAOkD,EAAWC,EAAUI,GAAcpZ,EAAET,QAG3DwB,0CAAA,SACI2K,EAAc1L,EAAaiZ,GAC7Bna,EAAiB,CAAC4M,EAAI1L,GAAI,iCAiC1B,IA/BM,IAAA+B,UAAC8T,OAAOiF,OAASC,OAAQC,OACzBpT,UAAGqT,OAASC,OAEZ3F,EAAS,IAAI1J,aAAagK,EAAQiF,EAAUC,EAASC,GACrDlP,EAAW5K,KAAKY,SAAS4J,EAAGlK,QAK5B2Z,EAAmC,CACtClC,GAAgBgC,EAAU,EAAKH,EAAU,EAAIA,EAC7C7B,GAAgBiC,EAAS,EAAKH,EAAS,EAAIA,GAGxCK,EAAmC,CACtCnC,GAAgBgC,EAAU,EAAKA,EAAU,EAAIA,EAC7ChC,GAAgBiC,EAAS,EAAKA,EAAS,EAAIA,GAGxCG,EAAcF,EAAe,GAAKC,EAAe,GACjDE,EAAaH,EAAe,GAAKC,EAAe,GAEhDgC,EAAiB,EAAI/B,EACrBgC,EAAgB,EAAI/B,EAIpBgC,EAAyC,EAA5BvW,KAAKiK,KAAKoM,GAAuB,EAC9CG,EAAuC,EAA3BxW,KAAKiK,KAAKqM,GAAsB,EAGzC9W,EAAI,EAAGA,EAAIsP,EAAOtP,IAEzB,IADA,IAAMwW,EAAcxW,EAAIvG,EAAEwD,QAAQ,GACzBkW,EAAI,EAAGA,EAAIoB,EAASpB,IAM3B,IALA,IAAMsD,EAAYD,EAAcrD,EAAI1Z,EAAEwD,QAAQ,GAGxCga,EAAazW,KAAK+B,MAAM4Q,EAAI0D,GAC5BK,EAAW1W,KAAK+B,MAAM0U,EAAcF,EAAY,GAC7CrD,EAAI,EAAGA,EAAIc,EAAQd,IAO1B,IANA,IAAMiD,EAAYF,EAAY/C,EAAIja,EAAEwD,QAAQ,GAGtCka,EAAa3W,KAAK+B,MAAMmR,EAAIoD,GAC5BM,EAAW5W,KAAK+B,MAAM4U,EAAcH,EAAW,GAE5C/a,EAAI,EAAGA,EAAIwY,EAAOxY,IAAK,CAI9B,IAHA,IAAIob,EAAQ,EAGHC,EAAW,EAAGA,EAAWP,EAAWO,IAAY,CACvD,IAAMC,EAAMD,EAAWJ,EAEvB,KAAIK,EAAM,GAAKA,GAAO7C,GAAtB,CAIA,IAAM8C,EAAYhB,EAAce,EAAMpS,EAAGlI,QAAQ,GAC3CmW,EAAgBmE,EAAMzC,EAK5B,GAAI3B,IAJqB3S,KAAKwB,IAC1BuS,EAAU,EACV7B,EAAelS,KAAKkW,MAAMtD,GACX5S,KAAK+B,MAAM6Q,IAI9B,IAAK,IAAIqE,EAAW,EAAGA,EAAWT,EAAUS,IAAY,CACtD,IAAMC,EAAMD,EAAWL,EAEvB,KAAIM,EAAM,GAAKA,GAAO/C,GAAtB,CAIA,IAAMgD,EAAYH,EAAYE,EAAMvS,EAAGlI,QAAQ,GACzC0W,EAAgB+D,EAAM3C,EAMxBrB,IALqBlT,KAAKwB,IAC1BwS,EAAS,EACT9B,EAAelS,KAAKkW,MAAM/C,GACXnT,KAAK+B,MAAMoR,MAG5B0D,GAAS9R,EAASoS,EAAY1b,OAIpC+S,EAAO2H,EAAY1a,GAAKob,EAKhC,OAAOf,WAAYtH,EAAQvV,EAAEiB,MAAOjB,EAAET,QAGxCwB,yCAAA,SACIf,EAAame,EAAqBxV,EAAcyV,EAChDC,GACFvf,EAAiBkB,EAAG,gCAEpB,IAAMse,EAAWte,EAAEiB,MAAM,GACnBsd,EAAOD,EAAW,EAClBvL,EAAU7R,KAAKY,SAAS9B,EAAEwB,QAC1B2C,EAAOnE,EAAEmE,KACTuB,EAAS,IAAImG,aAAa1H,GAEhC,SAASqa,EAAkBjV,GAQzB,IAPA,IAAMkV,EAAiBlV,EAAS+U,EAC5BI,EACAnV,EAASkV,EAAiB1X,KAAKb,IAAI,EAAGuY,EAAiBN,GACrDQ,EAAepV,EAASkV,EAC1B1X,KAAKwB,IAAIkW,EAAiBN,EAAaI,GAEvC7X,EAAM,EACHgY,GAAkBC,EAAcD,IAAkB,CACvD,IAAME,EAAI7L,EAAQ2L,GAClBhY,GAAOkY,EAAIA,EAEb,OAAOlY,EAGT,IAAK,IAAI6C,EAAS,EAAGA,EAASpF,EAAMoF,IAAU,CAC5C,IAAM7C,EAAM8X,EAAkBjV,GACxBsV,EAAM9L,EAAQxJ,GAAUxC,KAAKC,IAAI2B,EAAOyV,EAAQ1X,GAAM2X,GAC5D3Y,EAAO6D,GAAUsV,EAGnB,OAAOhC,WAAYnX,EAAQ1F,EAAEiB,QAG/BF,oBAAA,SACI2K,EAAcoT,EAAsBC,EACpCZ,EAAqBxV,EAAcyV,EACnCC,GACFvf,EAAiB4M,EAAI,WAQrB,IAPA,IAAM4S,EAAW5S,EAAGzK,MAAM,GACpB6K,EAAW5K,KAAKY,SAAS4J,EAAGlK,QAC5Bwd,EAAmB9d,KAAKY,SAASgd,EAAWtd,QAC5Cyd,EAAoB/d,KAAKY,SAASid,EAAYvd,QAC9CkE,EAAS,IAAImG,aAAaH,EAAGvH,MAC7BA,EAAOuH,EAAGvH,KAEPoF,EAAS,EAAGA,EAASpF,EAAMoF,IAAU,CAQ5C,IAPA,IAAMkV,EAAiBlV,EAAS+U,EAC1BY,EACD3V,EAASkV,EAAkB1X,KAAKb,IAAI,EAAGuY,EAAiBN,GACvDgB,EAAY5V,EAASkV,EACvB1X,KAAKwB,IAAI+V,EAAUG,EAAiBN,EAAc,GAElDiB,EAAO,EACF1W,EAAIwW,EAAYxW,EAAIyW,EAAUzW,IACrC0W,GAAQrY,KAAKC,IAAIgY,EAAiBtW,GAAI,GAExC0W,EAAOhB,EAAQgB,EAAOzW,EAEtB,IAASD,EAAIwW,EAAYxW,EAAIyW,EAAUzW,IAAK,CAC1C,IAAI2W,GAAO,EAAIjB,EAAQC,EAAOW,EAAiBtW,GAC3CuW,EAAkB1V,GAAU6V,EAC5B7V,IAAWb,IACb2W,GAAOtY,KAAKC,IAAIoY,GAAOf,IAEzBgB,GAAOvT,EAASvC,GAChB7D,EAAOgD,IAAM2W,GAGjB,OAAOxC,WAAYnX,EAAQgG,EAAGzK,QAGhCF,wBAAA,SACI8E,EAAkByZ,EAAqBC,EACvCC,GACF1gB,EAAiB+G,EAAQ,eASzB,IAPA,IAAM4Z,EAAgBH,EAAazZ,EAAS6Z,UAAW7Z,GACjD8H,EAAY8R,EAAcxe,MAAM,GAChC0e,EAAYF,EAAcxe,MAAM,GAChCgE,EAAMkE,QAAkB,CAACwE,EAAW4R,GAAa,SACjDvX,EAAU9G,KAAKY,SAASmD,EAAIzD,QAC5Boe,EAAW1e,KAAKY,SAAS2d,EAAcje,QAEpC+E,EAAI,EAAGA,EAAIoH,IAAapH,EAAG,CAClC,IAAMgD,EAAShD,EAAIoZ,EAGbE,EAAM,IAAIhU,aAAa8T,EAAY,GACzCE,EAAI,GAAKD,EAASrW,GAClB,IAAK,IAAIuW,EAAQ,EAAGA,EAAQD,EAAItb,SAAUub,EACxCD,EAAIC,GAASD,EAAIC,EAAQ,GAAKF,EAASrW,EAASuW,GAKlD,IAFA,IAAMC,EAASC,OAAgBR,EAAKS,YAC9BC,EAAY3Z,EAAIgZ,EACbY,EAAW,EAAGA,EAAWZ,IAAcY,EAAU,CACxD,IAAMzG,EAAIqG,IAGV/X,EAAQkY,EAAYC,GAAYN,EAAItb,OAEpC,IAAK,IAAI6b,EAAQ,EAAGA,EAAQP,EAAItb,OAAQ6b,IACtC,GAAI1G,EAAImG,EAAIO,GAAQ,CAClBpY,EAAQkY,EAAYC,GAAYC,EAChC,QAKR,OAAOnb,GAGTlE,mBAAA,SAAO4S,EAAmBqH,EAAeqF,EAAiBC,GAExDxhB,EAAiB6U,EAAS,UAE1B,IAAM1O,EAAM,IAAI4G,aAAa8H,EAAQxP,KAAO6W,GAC5C/V,EAAIF,KAAKub,GAGT,IAFA,IAAMC,EAAarf,KAAKY,SAAS6R,EAAQnS,QAEhCgf,EAAQ,EAAGA,EAAQ7M,EAAQxP,OAAQqc,EACtCD,EAAWC,IAAU,GAAKD,EAAWC,GAASxF,IAChD/V,EAAIub,EAAQxF,EAAQuF,EAAWC,IAAUH,GAG7C,OAAOI,WAAYxb,EAAK,CAAC0O,EAAQxP,KAAM6W,GAAQ,UAGjDja,8BAAA,SACI2f,EAAiBC,EAAkBC,EACnCC,EAAsBC,GACxBhiB,EAAiB4hB,EAAO,qBAExB,IAAMK,EAAY7f,KAAKY,SAAS4e,EAAMlf,QAChCwf,EAAa9f,KAAKY,SAAS6e,EAAOnf,QACxC,OAAOhC,EACHuhB,EAAWC,EAAYJ,EAAeC,EAAcC,IAG1D/f,yBAAA,SAAaf,EAAaiI,EAAmB+E,GAE3C3N,OAAKC,OACc,SAAf0N,GACA,WAAM,MAAA,+DACFA,KACR3N,OAAKC,OACD2I,EAAY,GACZ,WACI,MAAA,sDAAsDA,KAgB9D,IAdA,IAAM0F,EAAY3N,EAAEiB,MAAM,GACpBggB,EAAcjhB,EAAEiB,MAAM,GACtBigB,EAAalhB,EAAEiB,MAAM,GACrBkgB,EAAanhB,EAAEiB,MAAM,GAErBmgB,EAAeH,EAAchZ,EAC7BoZ,EAAcH,EAAajZ,EAC3BqZ,EAAcH,GAAclZ,EAAYA,GAExC8K,EAAU7R,KAAKY,SAAS9B,EAAEwB,QAC1BkE,EACF,IAAImG,aAAa8B,EAAYyT,EAAeC,EAAcC,GAE1D/H,EAAY,EACPhT,EAAI,EAAGA,EAAIoH,IAAapH,EAC/B,IAAK,IAAIgb,EAAI,EAAGA,EAAIH,IAAgBG,EAGlC,IAFA,IAAMC,EAAMza,KAAK+B,MAAMyY,EAAItZ,GACrBwZ,EAAWF,EAAItZ,EACZyZ,EAAI,EAAGA,EAAIL,IAAeK,EAIjC,IAHA,IAAMC,EAAM5a,KAAK+B,MAAM4Y,EAAIzZ,GAErB2Z,GAAWH,EAAUxZ,EADVyZ,EAAIzZ,GAC6BqZ,EACzC9e,EAAI,EAAGA,EAAI8e,IAAe9e,EAAG,CACpC,IACMqf,EADMrf,EAAIof,EAENT,GAAcQ,EAAMT,GAAcM,EAAMP,EAAc1a,IAChEb,EAAO6T,KAAexG,EAAQ8O,GAKtC,OAAOhF,WACHnX,EAAQ,CAACiI,EAAWyT,EAAcC,EAAaC,KAG7CvgB,gCAAR,SACIsF,EAAWE,EAAWhH,EACtBuiB,GACF,IAAMlO,EAAWtS,eAAaygB,2BAA2B1b,EAAEpF,MAAOsF,EAAEtF,OAC9DyE,EAAShD,SAAUkR,EAAUrU,GAC7B+J,EAAQpI,KAAKY,SAASuE,EAAE7E,QACxBwgB,EAAQ9gB,KAAKY,SAASyE,EAAE/E,QACxBygB,EAAiB3gB,eAAa4gB,iBAAiB7b,EAAEpF,MAAO2S,GACxDuO,EAAiB7gB,eAAa4gB,iBAAiB3b,EAAEtF,MAAO2S,GAExD5L,EAAUtC,EAAO1E,OACvB,GAAIihB,EAAe1d,OAAS4d,EAAe5d,SAAW,EACpD,IAAK,IAAIL,EAAI,EAAGA,EAAI8D,EAAQzD,SAAUL,EACpC8D,EAAQ9D,GAAK4d,EAAGxY,EAAMpF,EAAIoF,EAAM/E,QAASyd,EAAM9d,EAAI8d,EAAMzd,aAG3D,CAAA,IAAM6d,EAAOlhB,KAAK+C,WAAWoC,GACvBgc,EAAOnhB,KAAK+C,WAAWsC,cACpBrC,GACP,IAAME,EAAMsB,EAAOrB,WAAWH,GAExBoe,EAAOle,EAAIY,OAAOqB,EAAExB,MAC1Bod,EAAe9iB,SAAQ,SAAAqD,GAAK,OAAA8f,EAAK9f,GAAK,KACtC,IAAM+f,EAASH,EAAKpO,WAAWsO,GAEzBE,EAAOpe,EAAIY,OAAOuB,EAAE1B,MAC1Bsd,EAAehjB,SAAQ,SAAAqD,GAAK,OAAAggB,EAAKhgB,GAAK,KACtC,IAAMigB,EAASJ,EAAKrO,WAAWwO,GAE/Bxa,EAAQ9D,GAAK4d,EAAGxY,EAAMiZ,GAASP,EAAMS,KAXvC,IAASve,EAAI,EAAGA,EAAI8D,EAAQzD,SAAUL,IAA7BA,GAcX,OAAOwB,EAAOjB,YAGhB1D,kBAAA,SAAwBf,EAAM0iB,EAAsB7e,GAClD,OAAOnE,EAAMM,EAAG0iB,EAAY7e,IAG9B9C,oBAAA,aAEAA,2BAAA,WACE,OAAO,IAITA,oBAAA,WACE,OAAON,YAAMkiB,oBAGf5hB,0BAAA,SACI6hB,EACAlC,EACAmC,EACAC,EACAC,EACAC,GAmBF,IAjBM,IAAAjhB,UAAC8T,OAAOoN,OAAaC,OAAY9J,OACjC+J,EAAWzC,EAAMzf,MAAM,GAEtBmiB,OAAYC,OACb9N,EACF7S,SAAU,CAACygB,EAAUC,EAAYC,EAAWjK,GAAc,WAExDkK,EAAUpiB,KAAKY,SAAS4e,EAAMlf,QAC9B+hB,EAAariB,KAAKY,SAAS+gB,EAASrhB,QACpCgiB,EAAYtiB,KAAKY,SAAS8gB,EAAOphB,QAEjCiiB,EAAWb,EAAOpf,QAClBkgB,EAAYnO,EAAO/R,QAKhB+C,EAAI,EAAGA,EAAI4c,EAAU5c,IAAK,CACjC,IAAMod,EAAe,EAAJpd,EACXqd,EAAKN,EAAQK,GACbE,EAAKP,EAAQK,EAAW,GACxBG,EAAKR,EAAQK,EAAW,GACxBI,EAAKT,EAAQK,EAAW,GAExBK,EAAeT,EAAWhd,GAChC,KAAIyd,GAAQnO,GAUZ,IANA,IAAMwF,EAAe+H,EAAa,GAC7BU,EAAKF,IAAOX,EAAc,IAAMG,EAAa,GAC9C,EACE9H,EACD+H,EAAY,GAAMU,EAAKF,IAAOX,EAAa,IAAMG,EAAY,GAAK,EAE9D1X,EAAI,EAAGA,EAAIyX,EAAYzX,IAAK,CACnC,IAAMsY,EAAgBb,EAAa,EAC/BQ,GAAMX,EAAc,GAAKtX,IACzB,IAAOiY,EAAKE,IAAOb,EAAc,GAErC,GAAIgB,EAAO,GAAKA,EAAOhB,EAAc,EACnC,IAAK,IAAIjjB,EAAI,EAAGA,EAAIqjB,EAAWrjB,IAC7B,IAAK,IAAIia,EAAI,EAAGA,EAAIb,EAAaa,IAAK,CACpC,IAAMiK,EACFjK,EAAIja,EAAI0jB,EAAU,GAAK/X,EAAI+X,EAAU,GAAKnd,EAAImd,EAAU,GAC5DnO,EAAOvU,OAAOkjB,GAAOlB,OAM3B,GAAe,aAAXD,EACF,CAAA,IAAMoB,EAASpd,KAAK+B,MAAMmb,GACpBG,EAAYrd,KAAKiK,KAAKiT,GACtBI,EAAQJ,EAAOE,EAErB,IAASnkB,EAAI,EAAGA,EAAIqjB,EAAWrjB,IAAK,CAKlC,IAJMskB,EAAQjB,EAAY,EACtBQ,GAAMX,EAAa,GAAKljB,EAAIsb,EAC5B,IAAOuI,EAAKE,IAAOb,EAAa,IAEzB,GAAKoB,EAAOpB,EAAa,EAClC,IAASjJ,EAAI,EAAGA,EAAIb,EAAaa,IAAK,CAC9BiK,EACFjK,EAAIja,EAAI0jB,EAAU,GAAK/X,EAAI+X,EAAU,GAAKnd,EAAImd,EAAU,GAC5DnO,EAAOvU,OAAOkjB,GAAOlB,MAKzB,CAAA,IAAMuB,EAAUxd,KAAK+B,MAAMwb,GACrBE,EAAWzd,KAAKiK,KAAKsT,GACrBG,EAAQH,EAAOC,EAErB,IAAStK,EAAI,EAAGA,EAAIb,EAAaa,IAAK,CACpC,IAEMS,EAAU8I,EAFZU,EAAMjK,EAAIsK,EAAUd,EAAS,GAAKU,EAASV,EAAS,GACpDO,EAAOP,EAAS,IAKdiB,EAAWlB,EAFjBU,EAAMjK,EAAIuK,EAAWf,EAAS,GAAKU,EAASV,EAAS,GACjDO,EAAOP,EAAS,IAKd9I,EAAa6I,EAFnBU,EAAMjK,EAAIsK,EAAUd,EAAS,GAAKW,EAAYX,EAAS,GACnDO,EAAOP,EAAS,IAOdkB,EAAMjK,GAAWgK,EAAWhK,GAAW+J,EACvCG,EAASjK,GAHK6I,EAFpBU,EAAMjK,EAAIuK,EAAWf,EAAS,GAAKW,EAAYX,EAAS,GACpDO,EAAOP,EAAS,IAIuB9I,GAAc8J,EAEzDP,EAAMjK,EAAIja,EAAI0jB,EAAU,GAAK/X,EAAI+X,EAAU,GAAKnd,EAAImd,EAAU,GAC9DnO,EAAOvU,OAAOkjB,GAAOS,GAAQC,EAASD,GAAON,UAIjD,IAASrkB,EAAI,EAAGA,EAAIqjB,IAAarjB,EAAG,CAClC,IAAMskB,EAIN,IAJMA,EAAQjB,EAAY,EACtBQ,GAAMX,EAAa,GAAKljB,EAAIsb,EAC5B,IAAOuI,EAAKE,IAAOb,EAAa,IAEzB,GAAKoB,EAAOpB,EAAa,EAClC,IAASjJ,EAAI,EAAGA,EAAIb,EAAaa,IAAK,CAC9BiK,EACFjK,EAAIja,EAAI0jB,EAAU,GAAK/X,EAAI+X,EAAU,GAAKnd,EAAImd,EAAU,GAC5DnO,EAAOvU,OAAOkjB,GAAOlB,MAKzB,CAAA,IAAM6B,EAAW9d,KAAKkW,MAAMqH,GACtBQ,EAAW/d,KAAKkW,MAAMgH,GAC5B,IAAShK,EAAI,EAAGA,EAAIb,EAAaa,IAAK,CACpC,IAAM8K,EAAQ9K,EAAI4K,EAAWpB,EAAS,GAClCqB,EAAWrB,EAAS,GAAKO,EAAOP,EAAS,GACvCuB,EACF/K,EAAIja,EAAI0jB,EAAU,GAAK/X,EAAI+X,EAAU,GAAKnd,EAAImd,EAAU,GAC5DnO,EAAOvU,OAAOgkB,GAAUxB,EAAUuB,OAM5C,OAAOxP,EAAO9Q,YAGhB1D,0BAAA,SACIkkB,EAAuBC,EAAsBC,EAC7CC,GACI,IAAArjB,wCAACsjB,cAAWC,eAAY1Q,cAAWpR,YAAS+hB,eAGlD,OAAOrkB,KAAKskB,QACRP,EAAeC,EAAcC,EAAaI,EAAY3Q,EACtD0Q,EAAYD,EAAW7hB,EAAS4hB,GAHb,IAMzBrkB,qBAAA,SAASf,EAAW2T,GAClB,IAAM8R,EAAe9R,EAAQ1S,MACvBokB,EAAYI,EAAaA,EAAalhB,OAAS,GAE/CxC,yCAAC2jB,OAAaC,OAAW/Q,OAAWpR,OAE1C,GAAkB,IAAdmiB,EACF,OAAO7hB,SAAU,GAAI4hB,EAAa1lB,EAAET,OAOtC,IAJA,IAAMwE,EAAS,IAAI6hB,eAAa,CAACD,EAAW/Q,GAAY5U,EAAET,OACpDsmB,EAAc3kB,KAAKY,SAAS6R,EAAQnS,QACpCskB,EAAQ5kB,KAAKY,SAAS9B,EAAEwB,QAErB0C,EAAI,EAAGA,EAAIyhB,EAAWzhB,IAAK,CAGlC,IAFA,IAAM+G,EAAQ,GACV8a,EAAe,EACVvhB,EAAI,EAAGA,EAAI6gB,EAAW7gB,IAAK,CAClC,IAAMsB,EAAM+f,EAAY3hB,EAAImhB,EAAY7gB,GACxCuhB,GAAgBjgB,EAAMtC,EAAQgB,GAC9ByG,EAAMhB,KAAKnE,GAEb,GAAIigB,EAAe,GAAKA,GAAgB/lB,EAAEmE,KAAOyQ,EAC/C,MAAM,IAAIpU,MACN,oBAAoByK,0BAA6BjL,EAAEiB,OAGzD,IAAK,IAAIyH,EAAI,EAAGA,EAAIkM,EAAWlM,IAC7B3E,EAAO/C,OAAOkD,EAAI0Q,EAAYlM,GAAKod,EAAMC,EAAenR,EAAYlM,GAGxE,OAAO3E,EAAOU,WAAWU,QAAQugB,IAGnC3kB,sBAAA,SACI4S,EAAiBqS,EAAiB/kB,GAC9B,IAAAc,wCAACsjB,cAAWC,eAAY1Q,cAAWpR,YAAS+hB,eAE5CH,EAAe5f,SAAU,GAE/B,OAAOtE,KAAKskB,QACR7R,EAASqS,EAAS/kB,EAAOskB,EAAY3Q,EAAW0Q,EAAYD,EAC5D7hB,EAAS4hB,GAHU,IAMzBrkB,iBAAA,SACIE,EAAoBmJ,EAAsB7K,GAC5CA,EAAQA,GAASF,OAAK4mB,WAAW7b,GACjC,IAAMpJ,EACF3B,OAAK6mB,kBAAkB3mB,EAAOF,OAAKgK,cAAcpI,IAErD,OADAD,EAAO+D,KAAKqF,GACLvJ,WAASslB,WAAWnlB,EAAQC,EAAO1B,EAAO2B,OAGnDH,qBAAA,SAAyBf,GACvB,GAAgB,WAAZA,EAAET,MACJ,MAAM,IAAIiB,MAAM,gDAEhB,OAAOU,KAAK6D,KAAK/E,EAAEiB,MAAO,EAAGjB,EAAET,QAInCwB,sBAAA,SAA0Bf,GACxB,IAAMgB,EAAS3B,OAAK6mB,kBACDlmB,EAAET,MAAOF,OAAKgK,cAAcrJ,EAAEiB,QACjD,OAAOC,KAAK8K,WAAWhL,EAAQhB,EAAEiB,MAAOjB,EAAET,QAG5CwB,qBAAA,SAASkC,EAAemjB,EAAcxhB,GACpC,OAAOtD,eAAa+kB,aAAapjB,EAAOmjB,EAAMxhB,IAGxC7D,oBAAR,SACI4S,EAAiBqS,EAAiB/kB,EAAoBskB,EACtD3Q,EAAmB0Q,EAAoBD,EACvC7hB,EAAmB4hB,EACnBkB,GACF,IAAMC,EAAe,CAAChB,EAAa3Q,EAAWA,GAExCiR,EAAc3kB,KAAKY,SAAS6R,EAAQnS,QACpCglB,EAActlB,KAAKY,SAASkkB,EAAQxkB,QAE1C,GAAmB,IAAf+jB,EACF,OAAOzhB,SAAU,GAAI7C,EAAO+kB,EAAQzmB,OAGtC,IAAMwE,EAAS,IAAI6hB,eAAaW,EAAcP,EAAQzmB,OACtDwE,EAAO/C,OAAO+D,KAAM7D,KAAKY,SAASsjB,EAAa5jB,QAAuB,IAEtE,IAAK,IAAI0C,EAAI,EAAGA,EAAIohB,EAAYphB,IAAK,CAGnC,IAFA,IAAM+G,EAAQ,GACV8a,EAAe,EACVvhB,EAAI,EAAGA,EAAI6gB,EAAW7gB,IAAK,CAClC,IAAMsB,EAAM+f,EAAY3hB,EAAImhB,EAAY7gB,GACxCyG,EAAMhB,KAAKnE,GACXigB,GAAgBjgB,EAAMtC,EAAQgB,GAGhC,GAAIuhB,EAAe,GAAKA,GAAgBR,EAAa3Q,EACnD,MAAM,IAAIpU,MACN,oBAAoByK,0BAA6BhK,GAGvD,IAAK,IAAIyH,EAAI,EAAGA,EAAIkM,EAAWlM,IACzB4d,EACFviB,EAAO/C,OAAO+kB,EAAenR,EAAYlM,IACrC8d,EAAYtiB,EAAI0Q,EAAYlM,GAEhC3E,EAAO/C,OAAO+kB,EAAenR,EAAYlM,GAAsB,IAAjBsd,EAAQnhB,KAClD2hB,EAAY,GACZA,EAAYtiB,EAAI0Q,EAAYlM,GAItC,OAAO3E,EAAOU,WAAWU,QAAQlE,OAvjFDwlB,0BCvCpBC,EAAc/hB,GAE5B,IADA,IAAMiH,EAAe,IAAIC,aAAalH,EAAKJ,QAClCL,EAAI,EAAGA,EAAIS,EAAKJ,SAAUL,EACjC0H,EAAa1H,GAAK6C,KAAK4f,IAAIhiB,EAAKT,IAElC,OAAO0H,EAGF,IAyBMgb,EAA0B,CACrCC,WAAYC,MACZC,YAAa,MACbC,WA3BE,SAACC,GACQ,IAAAjnB,aACDknB,EAAaD,EAAKlnB,QACpB6L,EAAe,IAAIC,aAAaxM,OAAKgK,cAAcrJ,EAAEiB,QACzD,GAAgB,cAAZjB,EAAET,MAEJqM,EAAe8a,EADAQ,EAAWvmB,KAAKU,IAAIrB,EAAEwB,QAAQR,aAU7C,IAPA,IAAMmmB,EAAcD,EAAWvmB,KAAKU,IAAIrB,EAAEwB,QACpCU,EAAOilB,EAAYnlB,mBAAmBE,KACtCE,EAAO+kB,EAAYnlB,mBAAmBI,KACtCglB,EACFF,EAAWvmB,KAAKU,IAAIa,EAAKV,QAAQR,OAC/BqmB,EACFH,EAAWvmB,KAAKU,IAAIe,EAAKZ,QAAQR,OAC5BkD,EAAI,EAAGA,EAAIkjB,EAAS7iB,OAAQL,IAAK,CACxC,IAAMojB,EAAOF,EAASljB,GAChBqjB,EAAOF,EAASnjB,GACtB0H,EAAa1H,GAAK6C,KAAKygB,MAAMF,EAAMC,GAGvC,OAAOL,EAAWlb,WAAWJ,EAAc5L,EAAEiB,MAAO,sBC3B1CwmB,EAA6B3F,GAE3C,OAAO,SAAC4F,EAAkBC,EAAkBre,EACpC0Y,EAAmBziB,GACzB,IAAMqU,EAAWtS,eAAaygB,2BAA2B2F,EAAQC,GAE3DC,EAAahU,EAASrP,OACtBsjB,EAAgBxoB,OAAKyoB,eAAelU,GACpCmU,EAAa1oB,OAAKgK,cAAcuK,GAEhClO,EACFrG,OAAK2oB,uBAAuBzoB,EAA0BwoB,GAEpDE,EAAQP,EAAOnjB,OACf2jB,EAAQP,EAAOpjB,OAEf4jB,EAAW9oB,OAAKyoB,eAAeJ,GAC/BU,EAAW/oB,OAAKyoB,eAAeH,GAE/B1F,EAAiB3gB,eAAa4gB,iBAAiBwF,EAAQ9T,GACvDuO,EAAiB7gB,eAAa4gB,iBAAiByF,EAAQ/T,GAE7D,GAAIqO,EAAe1d,OAAS4d,EAAe5d,SAAW,EACpD,IAAK,IAAIL,EAAI,EAAGA,EAAIwB,EAAOnB,SAAUL,EACnCwB,EAAOxB,GAAK4d,EAAGxY,EAAMpF,EAAIoF,EAAM/E,QAASyd,EAAM9d,EAAI8d,EAAMzd,6BAGjDL,GACP,IAAME,EAAM/E,OAAKgF,WAAWH,EAAG0jB,EAAYC,GAErCvF,EAAOle,EAAIY,OAAOijB,GACxBhG,EAAe9iB,SAAQ,SAAAqD,GAAK,OAAA8f,EAAK9f,GAAK,KACtC,IAAM+f,EAASljB,OAAK2U,WAAWsO,EAAM2F,EAAOE,GAEtC3F,EAAOpe,EAAIY,OAAOkjB,GACxB/F,EAAehjB,SAAQ,SAAAqD,GAAK,OAAAggB,EAAKhgB,GAAK,KACtC,IAAMigB,EAASpjB,OAAK2U,WAAWwO,EAAM0F,EAAOE,GAE5C1iB,EAAOxB,GAAK4d,EAAGxY,EAAMiZ,GAASP,EAAMS,KAXtC,IAASve,EAAI,EAAGA,EAAIwB,EAAOnB,SAAUL,IAA5BA,GAeX,MAAO,CAACwB,EAAQkO,aC7CJyU,EAAQpB,GAEf,IAAAqB,WAAQvoB,YACRmC,SAAME,SAEPglB,EAAWrnB,EAAQY,KAAKU,IAAIa,EAAKV,QAAQR,OACzCqmB,EAAWtnB,EAAQY,KAAKU,IAAIe,EAAKZ,QAAQR,OAEzCunB,EAAcxoB,EAAQyoB,eAAetmB,EAAKjB,MAAO,aAYvD,OAVgBlB,EAAQY,KAAKU,IAAIknB,EAAY/mB,QAKrCQ,mBAAqB,CAC3BE,KAAMnC,EAAQyoB,eAAetmB,EAAKjB,MAAO,UAAWmmB,GACpDhlB,KAAMrC,EAAQyoB,eAAepmB,EAAKnB,MAAO,UAAWomB,IAG/CkB,EAGF,IAAME,EAA8B,CACzC5B,WAAY6B,UACZ3B,YAAa,MACbC,WAAYqB,YC1BEM,EACZ1B,GACK,IAAAqB,WAAQvoB,YACRC,MAIP,OAFAD,EAAQ6oB,OAAO5oB,EAAEwB,QAEV,CAACA,OAAQxB,EAAEwB,OAAQP,MAAOjB,EAAEiB,MAAO1B,MAAOS,EAAET,OAG9C,IAAMspB,EAA+B,CAC1ChC,WAAYiC,WACZ/B,YAAa,MACbC,WAAY2B,YCbEzmB,EAAK+kB,GAEZ,IAAAqB,WAAQvoB,YACRmM,UAEDhK,EAAOnC,EAAQY,KAAKU,IAAI6K,EAAM1K,QAAQQ,mBAAmBE,KACzD6mB,EAAUhpB,EAAQY,KAAKU,IAAIa,EAAKV,QAAQR,OAK9C,OAAOjB,EAAQyoB,eAAetmB,EAAKjB,MAAOiB,EAAK3C,MAAOwpB,GAGjD,IAAMC,EAA2B,CACtCnC,WAAYoC,OACZlC,YAAa,MACbC,WAAY9kB,YCZEgnB,EACZjC,GAEK,IAAAqB,WAAQvoB,YAASopB,UACjBnpB,MACAT,UAGP,GAAc,cAAVA,EAAuB,CACzB,GAAgB,cAAZS,EAAET,MACJ,OAAOopB,EAAS,CAACL,OAAQ,CAACtoB,KAAID,YAIhC,IAAMqpB,EAAcjgB,QAASnJ,EAAEiB,OACzBooB,EAASH,EAAK,CAACZ,OAAQ,CAACtoB,KAAID,UAASopB,MAAO,CAAC5pB,MAAO,aAEpDmG,EACF2iB,EAAQ,CAACC,OAAQ,CAACpmB,KAAMmnB,EAAQjnB,KAAMgnB,GAAcrpB,YAKxD,OAHAqpB,EAAYE,UACZvpB,EAAQwpB,8BAA8BF,GAE/B3jB,EAIT,GAAgB,cAAZ1F,EAAET,MAAuB,CAC3B,IAAMiqB,EAAWtnB,EAAK,CAAComB,OAAQ,CAACpc,MAAOlM,GAAID,YACrC2F,EAASwjB,EAAK,CAACZ,OAAQ,CAACtoB,EAAGwpB,GAAWzpB,UAASopB,MAAO,CAAC5pB,WAI7D,OAFAQ,EAAQwpB,8BAA8BC,GAE/B9jB,EAGT,IAAKrG,OAAKoqB,gBAAgBzpB,EAAET,MAAOA,GAIjC,MAAO,CAACiC,QADFkE,EAASijB,EAAS,CAACL,OAAQ,CAACtoB,KAAID,aACfyB,OAAQP,MAAOyE,EAAOzE,MAAO1B,SAGtD,GAAc,UAAVA,EAAmB,CACrB,IAAMyB,EAASjB,EAAQY,KAAKU,IAAIrB,EAAEwB,QAAQR,OACpC4K,EAAe8d,WAAWC,KAAK3oB,GACrC,OAAOjB,EAAQyoB,eAAexoB,EAAEiB,MAAO,QAAS2K,GAGlD,GAAc,SAAVrM,EAAkB,CAIpB,IAAMmF,EAAQ3E,EAAQY,KAAKU,IAAIrB,EAAEwB,QAAQR,OACnC4oB,EAAOvqB,OAAKwqB,aAAa,CAAC,GAAI7pB,EAAET,OAEhCwC,8DAAC+nB,OAAYpE,OAGnB,OAAO3lB,EAAQyoB,eAAe9C,EAAa,OAAQoE,GAGrD,MAAM,IAAItpB,MAAM,iCAAiCR,EAAET,aAAYA,GAG1D,IAAMwqB,EAA2B,CACtClD,WAAYmD,OACZjD,YAAa,MACbC,WAAYkC,YCzDEe,EACZC,EAAcC,EACdC,EAAuC7qB,GACzC,OAAmB,MAAf6qB,EACK,SAACroB,OAACumB,WAAQvoB,YACT6H,IAACvB,MAAGE,MACJ2gB,EAAannB,EAEnBjB,EAAiB,CAACuH,EAAGE,GAAI2jB,GAEzB,IAAM5gB,EAAQ4d,EAAWvmB,KAAKU,IAAIgF,EAAE7E,QAAQR,OACtCghB,EAAQkF,EAAWvmB,KAAKU,IAAIkF,EAAE/E,QAAQR,OAEtCqpB,EAAS9qB,GAAS8G,EAAE9G,MAEpBwS,2BAAC+X,OAAYpE,OAGnB,OAAOwB,EAAWsB,eAAe9C,EAAa2E,EAAQP,IAInD,SAAC/nB,OAACumB,WAAQvoB,YACT6H,IAACvB,MAAGE,MACJ2gB,EAAannB,EAEnB,GAAgB,cAAZsG,EAAE9G,OAAqC,cAAZgH,EAAEhH,MAAuB,CACtD,IAAM+qB,EAAYpB,EACd,CAACZ,OAAQ,CAACtoB,EAAGqG,GAAItG,QAASmnB,EAAYiC,MAAO,CAAC5pB,MAAO,eAEnDgrB,EAAgBrD,EAAWvmB,KAAKU,IAAIipB,EAAU9oB,QAE9CgpB,EAAQD,EAAcvoB,mBAAmBE,KACzCuoB,EAAQF,EAAcvoB,mBAAmBI,KAEzCsoB,EACFxD,EAAWvmB,KAAKU,IAAImpB,EAAMhpB,QAAQR,OAChC2pB,EACFzD,EAAWvmB,KAAKU,IAAIopB,EAAMjpB,QAAQR,OAEhC4pB,EAAY1B,EACd,CAACZ,OAAQ,CAACtoB,EAAGuG,GAAIxG,QAASmnB,EAAYiC,MAAO,CAAC5pB,MAAO,eAEnDsrB,EAAgB3D,EAAWvmB,KAAKU,IAAIupB,EAAUppB,QAE9CspB,EAAQD,EAAc7oB,mBAAmBE,KACzC6oB,EAAQF,EAAc7oB,mBAAmBI,KAEzC4oB,EACF9D,EAAWvmB,KAAKU,IAAIypB,EAAMtpB,QAAQR,OAChCiqB,EACF/D,EAAWvmB,KAAKU,IAAI0pB,EAAMvpB,QAAQR,OAEhC+Q,6BAACmZ,OAAgBC,OAAgBzF,OAGjC0F,EACFlE,EAAWsB,eAAe9C,EAAa,UAAWwF,GAEhDG,EACFnE,EAAWsB,eAAe9C,EAAa,UAAWyF,GAEhDzlB,EAAS2iB,EACX,CAACC,OAAQ,CAACpmB,KAAMkpB,EAAYhpB,KAAMipB,GAAatrB,QAASmnB,IAO5D,OALAA,EAAWqC,8BAA8Be,GACzCpD,EAAWqC,8BAA8BqB,GACzC1D,EAAWqC,8BAA8B6B,GACzClE,EAAWqC,8BAA8B8B,GAElC3lB,EAEP,IAAM4D,EAAQ4d,EAAWvmB,KAAKU,IAAIgF,EAAE7E,QAAQR,OACtCghB,EAAQkF,EAAWvmB,KAAKU,IAAIkF,EAAE/E,QAAQR,OAEtCqpB,EAAS9qB,GAAS8G,EAAE9G,MAEpB+rB,2BAACxB,OAAYpE,OAGnB,OAAOwB,EAAWsB,eAAe9C,EAAa2E,EAAQP,aAS5CyB,EAA8BzJ,GAE5C,OAAO,SAAC4F,EAAkBC,EAAkB+C,EACpCC,EAAyBK,EACzBC,GACN,IAAMvF,EAAcpkB,eAAaygB,2BAA2B2F,EAAQC,GAC9DI,EAAa1oB,OAAKgK,cAAcqc,GAChCkC,EAAalC,EAAYnhB,OACzBsjB,EAAgBxoB,OAAKyoB,eAAepC,GAEpC8F,EAAiBnsB,OAAK2oB,uBAAuB,UAAWD,GACxD0D,EAAiBpsB,OAAK2oB,uBAAuB,UAAWD,GAExD9F,EAAiB3gB,eAAa4gB,iBAAiBwF,EAAQhC,GACvDvD,EAAiB7gB,eAAa4gB,iBAAiByF,EAAQjC,GAEvDpc,EAAQhI,eAAae,uBAAuBqoB,EAAWC,GACvD3I,EAAQ1gB,eAAae,uBAAuB2oB,EAAWC,GAEvDhD,EAAQP,EAAOnjB,OACf4jB,EAAW9oB,OAAKyoB,eAAeJ,GAE/BQ,EAAQP,EAAOpjB,OACf6jB,EAAW/oB,OAAKyoB,eAAeH,GAErC,GAAI1F,EAAe1d,OAAS4d,EAAe5d,SAAW,EACpD,IAAK,IAAIL,EAAI,EAAGA,EAAIsnB,EAAejnB,OAAQL,IAAK,CAC9C,IAAMwnB,EAAOxnB,EAAIoF,EAAM/E,OACjBonB,EAAOznB,EAAI8d,EAAMzd,OAEjBmB,EACFoc,EAAGxY,EAAa,EAAPoiB,GAAWpiB,EAAa,EAAPoiB,EAAW,GAAI1J,EAAa,EAAP2J,GAC5C3J,EAAa,EAAP2J,EAAW,IAExBH,EAAetnB,GAAKwB,EAAOxD,KAC3BupB,EAAevnB,GAAKwB,EAAOtD,yBAGpB8B,GACP,IAAME,EAAM/E,OAAKgF,WAAWH,EAAG0jB,EAAYC,GAErCvF,EAAOle,EAAIY,OAAOijB,GACxBhG,EAAe9iB,SAAQ,SAAAqD,GAAK,OAAA8f,EAAK9f,GAAK,KACtC,IAAM+f,EAASljB,OAAK2U,WAAWsO,EAAM2F,EAAOE,GAEtC3F,EAAOpe,EAAIY,OAAOkjB,GACxB/F,EAAehjB,SAAQ,SAAAqD,GAAK,OAAAggB,EAAKhgB,GAAK,KACtC,IAAMigB,EAASpjB,OAAK2U,WAAWwO,EAAM0F,EAAOE,GAEtCwD,EACF9J,EAAGxY,EAAe,EAATiZ,GAAajZ,EAAe,EAATiZ,EAAa,GAAIP,EAAe,EAATS,GAChDT,EAAe,EAATS,EAAa,IAE1B+I,EAAetnB,GAAK0nB,EAAS1pB,KAC7BupB,EAAevnB,GAAK0nB,EAASxpB,MAhB/B,IAAS8B,EAAI,EAAGA,EAAIsnB,EAAejnB,OAAQL,MAAlCA,GAmBX,MAAO,CAACsnB,EAAgBC,EAAgB/F,ICjKrC,IAAMmG,EAAUpE,YAA+BphB,EAAGE,GAAM,OAAAF,EAAIE,KACtDulB,EACTP,YAAgCf,EAAOC,EAAOK,EAAOC,GACnD,MAAO,CAAC7oB,KAAMsoB,EAAQM,EAAO1oB,KAAMqoB,EAAQM,MAGpCgB,EAAM9B,EAAiB+B,MAAKH,EAASC,GAErCG,EAA0B,CACrCpF,WAAYmF,MACZjF,YAAa,MACbC,WAAY+E,YCTEG,EAAsBpK,GAEpC,OAAO,SAAC9gB,EAAQzB,EAAO4pB,GAGrB,IAFA,IAAMne,EACF3L,OAAK2oB,uBAAuBzoB,EAA0ByB,EAAOuD,QACxDL,EAAI,EAAGA,EAAIlD,EAAOuD,SAAUL,EACnC8G,EAAU9G,GAAK4d,EAAG9gB,EAAOkD,GAAIilB,GAE/B,OAAOne,YCAKmhB,EACZjC,EAAcpI,EAA0BviB,GAC1C,OAAO,SAACwC,OAACumB,WAAQa,UAAOppB,YACfC,MAEP,GADAlB,EAAiBkB,EAAGkqB,GACJ,WAAZlqB,EAAET,OAAgC,WAAVA,EAC1B,MAAM,IAAIiB,MAAM,wDAQlB,IALA,IAAM0mB,EAAannB,EACbiB,EAASkmB,EAAWvmB,KAAKU,IAAIrB,EAAEwB,QAAQR,OACvCorB,EAAQ/sB,OAAKgK,cAAcrJ,EAAEiB,OAC7BopB,EAAS9qB,GAASS,EAAET,MACpByL,EAAY3L,OAAK6mB,kBAAkBmE,EAAQ+B,GACxCloB,EAAI,EAAGA,EAAIkoB,IAASloB,EAC3B8G,EAAU9G,GAAK4d,EAAG9gB,EAAOkD,GAAIilB,GAE/B,OAAOjC,EAAWsB,eAAexoB,EAAEiB,MAAOopB,EAAQrf,aAatCqhB,EACZnC,EAAcoC,EAA4B/sB,GAC5C,OAAO,SAACwC,OAACumB,WAAQa,UAAOppB,YACfC,MAEP,GADAlB,EAAiBkB,EAAGkqB,GACJ,WAAZlqB,EAAET,OAAgC,WAAVA,EAC1B,MAAM,IAAIiB,MAAM,wDAGlB,IAAM0mB,EAAannB,EACbiB,EAASkmB,EAAWvmB,KAAKU,IAAIrB,EAAEwB,QAAQR,OACvCqpB,EAAS9qB,GAASS,EAAET,MACpByL,EAAYshB,EAAUtrB,EAAQqpB,EAAQlB,GAC5C,OAAOjC,EAAWsB,eAAexoB,EAAEiB,MAAOopB,EAAQrf,ICrD/C,IAAMuhB,EAAWL,GAAsB,SAACM,GAAO,OAAAzlB,KAAKiK,KAAKwb,MACnDC,EAAiBJ,EAAwBK,OAAMH,GAE/CI,EAA2B,CACtC9F,WAAY6F,OACZ3F,YAAa,MACbC,WAAYyF,GCNDG,EAAUV,GAAsB,SAACM,GAAO,OAAAzlB,KAAK8lB,IAAIL,MACjDM,EAAgBT,EAAwBU,MAAKH,GAE7CI,EAA0B,CACrCnG,WAAYkG,MACZhG,YAAa,MACbC,WAAY8F,GCNDG,EAAYf,GAAsB,SAACM,GAAO,OAAAzlB,KAAKmmB,MAAMV,MACrDW,EAAkBd,EAAwBe,QAAOH,GAEjDI,EAA4B,CACvCxG,WAAYuG,QACZrG,YAAa,MACbC,WAAYmG,GCNDG,EAAYpB,GAAsB,SAACM,GAAO,OAAAzlB,KAAK+B,MAAM0jB,MACrDe,EAAkBlB,EAAwBmB,QAAOF,GAEjDG,EAA4B,CACvC5G,WAAY2G,QACZzG,YAAa,MACbC,WAAYuG,GCNDG,EAAUxB,GAAsB,SAACM,GAAO,OAAAzlB,KAAK4mB,IAAInB,MACjDoB,EAAgBvB,EAAwBwB,MAAKH,GAE7CI,EAA0B,CACrCjH,WAAYgH,MACZ9G,YAAa,MACbC,WAAY4G,YCTEG,EACZzkB,EAAmBF,EAAoB3F,EACvClE,GAIF,IAHA,IAAMoF,EAAOtF,OAAK2oB,uBACdzoB,EAA0BF,OAAKgK,cAAc5F,IAExCS,EAAI,EAAGA,EAAIS,EAAKJ,SAAUL,EAAG,CAGpC,IAFA,IAAMqF,EAASrF,EAAIkF,EACflD,EAAMoD,EAAMC,GACP/E,EAAI,EAAGA,EAAI4E,IAAc5E,EAAG,CACnC,IAAM4F,EAAQd,EAAMC,EAAS/E,GACzB4F,EAAQlE,IACVA,EAAMkE,GAGVzF,EAAKT,GAAKgC,EAEZ,OAAOvB,ECfF,IAAMqpB,EACTvG,YAA+B5gB,EAAQC,GAAW,OAAAD,EAASC,KAClDmnB,EACT1C,YAAgCf,EAAOC,EAAOK,EAAOC,GACnD,MAAO,CACL7oB,KAAMsoB,EAAQM,EAAQL,EAAQM,EAC9B3oB,KAAMooB,EAAQO,EAAQN,EAAQK,MAIzBoD,EACTjE,EAAiBkE,WAAUH,EAAcC,GAEhCG,EAA+B,CAC1CvH,WAAYsH,WACZpH,YAAa,MACbC,WAAYkH,GCfDG,GAAYnC,GAAsB,SAACM,GAAO,OAAA,EAAIzlB,KAAKunB,KAAK9B,MACxD+B,GAAkBlC,EAAwBmC,QAAOH,IAEjDI,GAA4B,CACvC5H,WAAY2H,QACZzH,YAAa,MACbC,WAAYuH,aCNEG,GACZ/pB,EAAkBrB,EAAiBa,EAAgBlD,EACnD1B,GACF,IAAMovB,EAAcjrB,aAAWkrB,iBAAiB3tB,EAAOqC,EAAOa,GACxDI,EAASlF,OAAKgK,cAAclF,GAC5B0qB,EAAWxvB,OAAKyoB,eAAe7mB,GAErC,GAAI0tB,EAAa,CACf,IAAMG,EAAaprB,aAAWqrB,kBAAkBzrB,EAAOurB,GACvD,OAAOlqB,EAAKqqB,SAASF,EAAYA,EAAavqB,GAIhD,IADA,IAAM0qB,EAAU5vB,OAAK2oB,uBAAuBzoB,EAA0BgF,GAC7DL,EAAI,EAAGA,EAAIK,IAAUL,EAAG,CAC/B,IAAMW,EAAOV,EAAKI,OACZf,EAAUnE,OAAKyoB,eAAe3jB,GAE9B+qB,EADM7vB,OAAKgF,WAAWH,EAAGW,EAAMrB,GACpBjB,KAAI,SAACoI,EAAanG,GAAM,OAAAmG,EAAMrH,EAAMkB,MAC/C2qB,EAAS9vB,OAAK2U,WAAWkb,EAAMjuB,EAAMsD,OAAQsqB,GACnDI,EAAQ/qB,GAAKS,EAAKwqB,GAEpB,OAAOF,WAGOjqB,GACZiiB,GAEK,IAAAqB,WAAQvoB,YAASopB,UACjBnpB,MACAsD,UAAOa,SAEdrF,EAAiBkB,EAAG,SAEd,IAAA+B,uCAACqtB,OAAQC,OACf3rB,aAAW4rB,kBAAkBtvB,EAAGovB,EAAQC,GAExC,IACMJ,EAAUP,GADH3uB,EAAQY,KAAKU,IAAIrB,EAAEwB,QAAQR,OACRouB,EAAQC,EAAOrvB,EAAEiB,MAAOjB,EAAET,OAC1D,OAAOQ,EAAQyoB,eAAe6G,EAAOrvB,EAAET,MAAO0vB,GAGzC,IAAMM,GAA4B,CACvC1I,WAAY2I,QACZzI,YAAa,MACbC,WAAYhiB,IC5CDyqB,GACThI,YAA+B5gB,EAAQC,GAAW,OAAAD,EAASC,KAClD4oB,GACTnE,YAAgCf,EAAOC,EAAOK,EAAOC,GACnD,MAAO,CAAC7oB,KAAMsoB,EAAQM,EAAO1oB,KAAMqoB,EAAQM,MAEpC4E,GAAM1F,EAAiB2F,MAAKH,GAASC,IAErCG,GAA0B,CACrChJ,WAAY+I,MACZ7I,YAAa,MACbC,WAAY2I,aCbEG,GACZprB,EAAmBqrB,EAAkBxwB,EAAiBywB,EACtDpc,GASF,IARA,IAAMqc,EAAQF,EAAOxrB,OACf6nB,EAAQ/sB,OAAKgK,cAAc0mB,GAC3BlB,EAAWxvB,OAAKyoB,eAAeiI,GAC/BG,EAAa7wB,OAAKyoB,eAAelU,GAEjClO,EAASrG,OAAK2oB,uBAChBzoB,EAA0BF,OAAKgK,cAAcuK,IAExC1P,EAAI,EAAGA,EAAIkoB,IAASloB,EAAG,CAK9B,IAJA,IAAME,EAAM/E,OAAKgF,WAAWH,EAAG+rB,EAAOpB,GAGhCvqB,EAAmB,IAAIrF,MAAMmF,EAAIG,QAC9B4rB,EAAI,EAAGA,EAAI7rB,EAAOC,OAAQ4rB,IACjC7rB,EAAO6rB,GAAK/rB,EAAI4rB,EAAKG,IAIvBzqB,EADiBrG,OAAK2U,WAAW1P,EAAQ2rB,EAAOC,IAC7BxrB,EAAMR,GAE3B,OAAOwB,WCxBO0qB,GACZpvB,EAAuB6C,EAAc5C,EAAiB1B,GAgExD,IA1DA,IAAM8wB,EAAQhxB,OAAK2G,eAAenC,EAAM5C,GAAO,GAyDzC2S,EAAW,CAAC,EAAG3S,EAAM,GAAI,GACtBiD,EAAI,EAAGA,EAAImsB,EAAOnsB,IACzB0P,EAAS,IAAM3S,EAAMiD,GAEvB0P,EAAS,GAAK3S,EAAMovB,GACpB,IAASnsB,EAAImsB,EAAQ,EAAGnsB,EAAIjD,EAAMsD,OAAQL,IACxC0P,EAAS,IAAM3S,EAAMiD,GAKvB,IAAMosB,EAA0C,GAG1C3c,EAAU,IAAI+V,WAAWzoB,EAAMovB,IAE/BE,EAAc,IAAI3K,eAAahS,EAAUrU,EAAOyB,GAGhDwvB,EAA0B,GAC1BC,EAA6B,IAAhB7c,EAAS,IAA4B,IAAhBA,EAAS,GACjD,IAAS1P,EAAI,EAAGA,EAAIjD,EAAMovB,GAAQnsB,IAAK,CAErC,IAAIwsB,SACJ,GAAID,EAEFC,EAAU1vB,EAAOkD,GAAG+b,eACf,CAEL,IADA,IAAM0Q,EAAa,GACVC,EAAI,EAAGA,EAAIhd,EAAS,GAAIgd,IAC/B,IAAK,IAAIC,EAAI,EAAGA,EAAIjd,EAAS,GAAIid,IAC/BF,EAAW1mB,KAAKsmB,EAAYlvB,IAAIuvB,EAAG1sB,EAAG2sB,IAG1CH,EAAUC,EAAWG,KAAK,KAI5B,QAAgCC,IAA5BT,EAAeI,GACjB/c,EAAQzP,GAAKosB,EAAeI,OACvB,CACL,IAAMM,EAAcC,OAAOC,KAAKZ,GAAgB/rB,OAChD+rB,EAAeI,GAAWM,EAC1Brd,EAAQzP,GAAK8sB,EACbR,EAAcvmB,KAAK/F,IAOvB,IAAMitB,EAAiBvd,EAAS5O,QAChCmsB,EAAe,GAAKF,OAAOC,KAAKZ,GAAgB/rB,OAChD,IAAM6sB,EAAe,IAAIxL,eAAauL,EAAgB5xB,GACtDixB,EAAcrxB,SAAQ,SAACkyB,EAAoBntB,GACzC,IAAK,IAAI0sB,EAAI,EAAGA,EAAIhd,EAAS,GAAIgd,IAC/B,IAAK,IAAIC,EAAI,EAAGA,EAAIjd,EAAS,GAAIid,IAC/BO,EAAa3vB,IAAI8uB,EAAYlvB,IAAIuvB,EAAGS,EAAoBR,GAAID,EAAG1sB,EAAG2sB,MAOxE,IAAM1L,EAAclkB,EAAM+D,QAG1B,OAFAmgB,EAAYkL,GAASc,EAAe,GAE7B,CACLG,aAAcF,EAAapwB,OAC3BmkB,cACAxR,mOC3HY,OAAO,WAAM,OAAA,IAAI5S,IAAkB,GCT5C,IAAMwwB,GAAiBpF,EAAgBqF,QAAM,SAAChF,GAAO,OAAAzlB,KAAK0qB,KAAKjF,MAEzDkF,GAA2B,CACtC7K,WAAY2K,OACZzK,YAAa,MACbC,WAAYuK,ICLDI,GAAkBxF,EAAgByF,SAAO,SAACpF,GAAO,OAAAzlB,KAAK8qB,MAAMrF,MAE5DsF,GAA4B,CACvCjL,WAAY+K,QACZ7K,YAAa,MACbC,WAAY2K,ICLDI,GAAiB5F,EAAgB6F,QAAM,SAACxF,GAAO,OAAAzlB,KAAKkrB,KAAKzF,MAEzD0F,GAA2B,CACtCrL,WAAYmL,OACZjL,YAAa,MACbC,WAAY+K,ICLDI,GAAkBhG,EAAgBiG,SAAO,SAAC5F,GAAO,OAAAzlB,KAAKsrB,MAAM7F,MAE5D8F,GAA4B,CACvCzL,WAAYuL,QACZrL,YAAa,MACbC,WAAYmL,ICLDI,GAAiBpG,EAAgBqG,QAAM,SAAChG,GAAO,OAAAzlB,KAAK0rB,KAAKjG,MAEzDkG,GAA2B,CACtC7L,WAAY2L,OACZzL,YAAa,MACbC,WAAYuL,ICLDI,GAAkBxG,EAAgByG,SAAO,SAACpG,GAAO,OAAAzlB,KAAK8rB,MAAMrG,MAE5DsG,GAA4B,CACvCjM,WAAY+L,QACZ7L,YAAa,MACbC,WAAY2L,aCPEI,GACZhgB,EAAqBgd,EAAkBxwB,EAAiBiE,EACxD4I,EACA2I,GAsBF,IArBA,IAAM7G,EAAe9B,EAAS8B,aACxBU,EAAcxC,EAASwC,YACvBpC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBwI,EAAwB7I,EAAS6I,sBACjCC,EAAuB9I,EAAS8I,qBAChCrI,EAAST,EAASO,QAAQG,IAC1BJ,EAAUN,EAASO,QAAQC,KAE3BuI,EACY,QAAbJ,EAAqBK,OAAOC,kBACPD,OAAOE,kBAE3BC,EAASxR,SAAOqI,EAAS3I,SAAUlE,GACnCiW,EAAaD,EAAOvU,OAEpByU,EACFrJ,EAAS3I,SAAS,GAAK2I,EAAS3I,SAAS,GAAK2I,EAAS3I,SAAS,GAC9DkS,EAAmBvJ,EAAS3I,SAAS,GAAK2I,EAAS3I,SAAS,GAC5DmS,EAAmBxJ,EAAS3I,SAAS,GAElC8C,EAAI,EAAGA,EAAI6F,EAASuB,YAAapH,EAGxC,IAFA,IAAMuP,EAAoBvP,EAAIkP,EACxBM,EAAmBxP,EAAI/C,EAAQ,GAC5BhB,EAAI,EAAGA,EAAI4J,EAAS+C,aAAc3M,EACzC,IAAK,IAAIsL,EAAK,EAAGA,EAAK1B,EAAS2B,YAAaD,EAM1C,IALA,IAAMG,EAAWH,EAAKI,EAAerB,EAC/BkE,EAAQhK,KAAKb,IAAI,EAAG+H,GACpB+kB,EACFjsB,KAAKwB,IAAI6D,EAASiC,SAAU4G,EAAwBhH,GAClDyI,EAAkBZ,EAAoBhI,EAAK6H,EACxCnH,EAAK,EAAGA,EAAKpC,EAASqC,WAAYD,EAAI,CAQ7C,IAPA,IAAMG,EAAWH,EAAKI,EAAclC,EAC9BwE,EAAQnK,KAAKb,IAAI,EAAGyI,GACpBskB,EACFlsB,KAAKwB,IAAI6D,EAAS2C,QAASmG,EAAuBvG,GAClDqI,EAAc7B,EACd8B,EAAW,EACXC,EAAQ,EACH9I,EAAK2C,EAAO3C,EAAK4kB,EAAO5kB,GAAM5B,EAAgB,CAErD,IADA,IAAM0mB,EAAWnd,EAAmB3H,EAAK5K,EAAQ,GACxCsL,EAAKoC,EAAOpC,EAAKmkB,EAAOnkB,GAAMrC,EAAe,CACpD,IACM+K,EAAQzE,EADGmgB,EAAWpkB,EAAKtL,EAAQ,GACRhB,GACf,QAAbuS,GAAsByC,EAAQR,EACjCA,EAAcQ,EACQ,QAAbzC,IACTkC,GAAYO,EACZN,KAGJ,GAAIO,MAAMT,GACR,MAIJxB,EADqBkB,EAAkBlI,EAAKoH,EAAmBpT,GAE9C,QAAbuS,EAAqBkC,EAAWC,EAAQF,EAKpD,OAAOzB,WAGO4d,GACZpgB,EAAqBgd,EAAkBxwB,EACvC6M,EAAmCgnB,EACnCC,gBADmCD,mBACnCC,MAYF,IAXA,IAAM5a,EAAe1U,SAAOqI,EAAS3I,SAAU,SACzCyK,EAAe9B,EAAS8B,aACxBU,EAAcxC,EAASwC,YACvBpC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBwI,EAAwB7I,EAAS6I,sBACjCC,EAAuB9I,EAAS8I,qBAChCrI,EAAST,EAASO,QAAQG,IAC1BJ,EAAUN,EAASO,QAAQC,KAE3B5I,EAAOD,SAAOgsB,EAAQxwB,EAAOwT,GAC1BxM,EAAI,EAAGA,EAAI6F,EAASuB,YAAapH,EACxC,IAAK,IAAI/D,EAAI,EAAGA,EAAI4J,EAAS+C,aAAc3M,EACzC,IAAK,IAAIsL,EAAK,EAAGA,EAAK1B,EAAS2B,YAAaD,EAAI,CAG9C,IAFA,IAAMG,EAAWH,EAAKI,EAAerB,EACjCkE,EAAQ9C,EACL8C,EAAQ,GACbA,GAASvE,EAKX,IAFA,IAAMwmB,EACFjsB,KAAKwB,IAAI6D,EAASiC,SAAU4G,EAAwBhH,GAC/CO,EAAK,EAAGA,EAAKpC,EAASqC,WAAYD,EAAI,CAG7C,IAFA,IAAMG,EAAWH,EAAKI,EAAclC,EAChCwE,EAAQvC,EACLuC,EAAQ,GACbA,GAASzE,EAOX,IALA,IAAMwmB,EACFlsB,KAAKwB,IAAI6D,EAAS2C,QAASmG,EAAuBvG,GAClD+J,EAAWtD,OAAOC,kBAClBsD,GAAe,EAEVvK,EAAK2C,EAAO3C,EAAK4kB,EAAO5kB,GAAM5B,EAErC,IADA,IAAM2B,EAAKC,EAAKH,EACPa,EAAKoC,EAAOpC,EAAKmkB,EAAOnkB,GAAMrC,EAAe,CACpD,IAAMoC,EAAKC,EAAKH,EACV6I,EAAQxT,EAAK3C,IAAIkF,EAAG6H,EAAIU,EAAItM,GAC9BgV,EAAQkB,IACVA,EAAWlB,EAETmB,EADEya,EACYC,IACR9sB,EAAI6F,EAASiC,SAAWD,GAAMhC,EAAS2C,QAAUD,GAC3C1C,EAAS+C,WACb3M,GACH4L,EAAKhC,EAAS2C,QAAUD,GAAM1C,EAAS+C,WAAa3M,EAE3C2L,EAAK+G,EAAuBrG,GAKlD4J,EAAahX,IAAIkX,EAAapS,EAAGuH,EAAIU,EAAIhM,IAKjD,OAAOiW,EC7FF,IAAM6a,GAA8B,CACzCzM,WAAY0M,UACZxM,YAAa,MACbC,oBAnCEC,GAGK,IAAAqB,WAAQvoB,YAASopB,UACjBnpB,MACPlB,EAAiBkB,EAAG,WACb,IAAAwzB,eAAYhwB,YAASiwB,QAAKC,oBAGjCr0B,OAAKC,OACDgC,eAAaqyB,+BAA+BnwB,EAH9B,IAId,WAAM,MAAA,wEACaA,0BAEvB,IAGIyB,EAHEmH,EAAW9K,eAAasyB,kBAC1B5zB,EAAEiB,MAA2CuyB,EAAYhwB,EAR3C,EASHiwB,EAAKC,GAGpB,GAA6B,IAAzBtnB,EAASG,aAA+C,IAA1BH,EAASE,cACvCjN,OAAKw0B,YAAYznB,EAASmE,QAASnE,EAAS3I,UAC9CwB,EAAM0jB,EAAS,CAACL,OAAQ,CAACtoB,KAAID,gBACxB,CACL,IAAMgT,EAAUhT,EAAQY,KAAKU,IAAIrB,EAAEwB,QAAQR,OACrC8yB,EAAUz0B,OAAKyoB,eAAe9nB,EAAEiB,OAChC8C,EAASgvB,GAAKhgB,EAAS/S,EAAEiB,MAAOjB,EAAET,MAAOu0B,EAAS1nB,EAAU,OAClEnH,EAAMlF,EAAQyoB,eACVpc,EAAS3I,SAAUzD,EAAET,MAAOwE,EAAO/C,QAEzC,OAAOiE,ICkCF,IAAM8uB,GAAsC,CACjDlN,WAAYmN,kBACZjN,YAAa,MACbC,oBArE8BC,GAKvB,IAAAqB,WAAQvoB,YAASopB,UACjBzd,OAAIQ,UACLlM,EAAIkM,EACVpN,EAAiB,CAAC4M,EAAIQ,GAAQ,mBAyB9B,IAxBO,IAAAsnB,eAAYhwB,YAASiwB,QAEtBrnB,EAAW9K,eAAasyB,kBAC1B5zB,EAAEiB,MAA2CuyB,EAAYhwB,EACzD,EAAmBiwB,GACjBvlB,EAAe9B,EAAS8B,aACxBU,EAAcxC,EAASwC,YACvBtC,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBwI,EAAwB7I,EAAS6I,sBACjCC,EAAuB9I,EAAS8I,qBAChCxI,EAAUwI,EAAuB,EAAI9I,EAASO,QAAQC,KACtDC,EAASoI,EAAwB,EAAI7I,EAASO,QAAQG,IACtDwD,EACFvM,SAAgB/D,EAAEiB,MAA2C,WAE3D2W,EAAgB,GAAKtL,EAAeC,GAEpC0nB,EAASl0B,EAAQY,KAAKU,IAAIqK,EAAGlK,QAAQR,OACrCsR,EAAQvO,SACV2H,EAAGzK,MAA2C,UAAWgzB,GAEpD1tB,EAAI,EAAGA,EAAI6F,EAASuB,YAAapH,EACxC,IAAK,IAAI/D,EAAI,EAAGA,EAAI4J,EAAS+C,aAAc3M,EACzC,IAAK,IAAIgZ,EAAM,EAAGA,EAAMpP,EAASiC,WAAYmN,EAC3C,IAAK,IAAIO,EAAM,EAAGA,EAAM3P,EAAS2C,UAAWgN,EAAK,CAK/C,IAHA,IAAMmY,EAAY1Y,EAAM3O,EAClBsnB,EAAYpY,EAAMrP,EACpB0E,EAAU,EACLjD,EAAK,EAAGA,EAAK8G,EAAuB9G,GAAM3B,EAAgB,CACjE,IAAMsR,GAAOoW,EAAY/lB,GAAMD,EAC/B,KAAI4P,EAAM,GAAKA,GAAO1R,EAAS2B,WAC3BhH,KAAK+B,MAAMgV,KAASA,GAGxB,IAAK,IAAIjP,EAAK,EAAGA,EAAKqG,EAAsBrG,GAAMpC,EAAe,CAC/D,IAAMwR,GAAOkW,EAAYtlB,GAAMD,EAC/B,KAAIqP,EAAM,GAAKA,GAAO7R,EAASqC,UAC3B1H,KAAK+B,MAAMmV,KAASA,GAKxB7M,GADckB,EAAMjR,IAAIkF,EAAGuX,EAAKG,EAAKzb,IAIzC8N,EAAG7O,IAAI2P,EAAUwG,EAAerR,EAAGiV,EAAKO,EAAKvZ,GAKrD,OAAOzC,EAAQyoB,eAAelY,EAAGrP,MAAOqP,EAAG/Q,MAAO+Q,EAAGtP,UCKhD,IAAMozB,GAAgC,CAC3CvN,WAAYwN,iBACZtN,YAAa,MACbC,oBAtEkCC,GAK3B,IAAAqB,WAAQvoB,YAASopB,UACjBnpB,MAAGs0B,UAAO/qB,WAAQgrB,SAAMC,aAE/Bn1B,OAAKC,OACDi1B,EAAKtzB,MAAMsD,SAAWiwB,EAASvzB,MAAMsD,QACrC,WAAM,MAAA,kFAEVlF,OAAKC,OACS,MAAViK,GAAkBgrB,EAAKtzB,MAAMsD,SAAWgF,EAAOtI,MAAMsD,QACrD,WAAM,MAAA,gFAEVlF,OAAKC,OACQ,MAATg1B,GAAiBC,EAAKtzB,MAAMsD,SAAW+vB,EAAMrzB,MAAMsD,QACnD,WAAM,MAAA,+EAGVzF,EAAiB,CAACkB,EAAGu0B,EAAMC,EAAUF,EAAO/qB,GAAS,aAEhD,IAAAkrB,oBACkB,MAAnBA,IACFA,EAAkB,MAsBpB,IAnBA,IAAM/vB,EAAQ3E,EAAQY,KAAKU,IAAIrB,EAAEwB,QAAQR,OACnC0zB,EAAQ30B,EAAQY,KAAKU,IAAIkzB,EAAK/yB,QAAQR,OACtC2zB,EAAU50B,EAAQY,KAAKU,IAAImzB,EAAShzB,QAAQR,OAC5C4zB,EAAQN,EAAQv0B,EAAQY,KAAKU,IAAIizB,EAAM9yB,QAAQR,OAC/B,IAAI6K,aAAa,CAAC,IAClCgpB,EAAUtrB,EACZxJ,EAAQY,KAAKU,IAAIkI,EAAO/H,QAAQR,OAChC,IAAI6K,aAAa,CAAC,IAChBojB,EAAU,IAAIpjB,aAAanH,EAAMH,QAEjCuwB,EAAgBD,EAAQtwB,OACxBwwB,EAAcH,EAAMrwB,OACpBywB,EAAgBL,EAAQpwB,OACxB0wB,EAAcP,EAAMnwB,OAEtB2wB,EAAO,EACPC,EAAK,EACLC,EAAK,EACLC,EAAK,EACAnxB,EAAI,EAAGA,EAAIQ,EAAMH,SAAUL,EAClC+qB,EAAQ/qB,GAAK2wB,EAAQK,MAChBxwB,EAAMR,GAAKwwB,EAAMS,MAASP,EAAMQ,KAC7BruB,KAAKunB,KAAKqG,EAAQU,KAAQZ,GAC9BS,GAAQJ,IACVI,EAAO,GAELC,GAAMF,IACRE,EAAK,GAEHC,GAAML,IACRK,EAAK,GAEHC,GAAML,IACRK,EAAK,GAGT,OAAOt1B,EAAQyoB,eAAexoB,EAAEiB,MAAOjB,EAAET,MAAO0vB,KCjErCqG,GAAiBnJ,EAAgBoJ,eAAa,SAAC/I,EAAIrD,GAC9D,IAAMqM,EAAYrM,EAClB,OAAIqD,EAAKgJ,EAAUC,aACVD,EAAUC,aAEZjJ,EAAKgJ,EAAUE,aAAeF,EAAUE,aAAelJ,KAGnDmJ,GAA2B,CACtC9O,WAAY0O,cACZxO,YAAa,MACbC,WAAYsO,aCXElzB,GAAK6kB,GAEZ,IAAAqB,WAAQvoB,YACRmM,UAED9J,EAAOrC,EAAQY,KAAKU,IAAI6K,EAAM1K,QAAQQ,mBAAmBI,KACzDwzB,EAAU71B,EAAQY,KAAKU,IAAIe,EAAKZ,QAAQR,OAK9C,OAAOjB,EAAQyoB,eAAepmB,EAAKnB,MAAOmB,EAAK7C,MAAOq2B,GAGjD,IAAMC,GAA2B,CACtChP,WAAYiP,OACZ/O,YAAa,MACbC,WAAY5kB,aCjBE+C,GACZ8hB,GAGK,IAAAqB,WAAQvoB,YAASopB,UACjBnpB,MACAiB,UAEDmrB,EAAQ/sB,OAAKgK,cAAcrJ,EAAEiB,OAC7B80B,EAAS12B,OAAK22B,uBAAuB/0B,EAAOmrB,GAC5C6J,EAAS52B,OAAKgK,cAAc0sB,GAElC12B,OAAKC,OACD8sB,IAAU6J,GACV,WAAM,MAAA,kBAAkBF,WAAeE,kCACzBj2B,EAAEiB,eAAcmrB,qFAGlCrsB,EAAQ6oB,OAAO5oB,EAAEwB,QAEjB,IAAMskB,EAAQ/lB,EAAQY,KAAKU,IAAIrB,EAAEwB,QAEjC,GAAgC,MAA5BskB,EAAM9jB,mBAA4B,CACpC,IAAME,EAAO4jB,EAAM9jB,mBAAmBE,KAChCE,EAAO0jB,EAAM9jB,mBAAmBI,KAEtCF,EAAKjB,MAAQ80B,EACb3zB,EAAKnB,MAAQ80B,EAGf,MAAO,CAACv0B,OAAQxB,EAAEwB,OAAQP,MAAO80B,EAAQx2B,MAAOS,EAAET,OAG7C,IAAM22B,GAA8B,CACzCrP,WAAYsP,UACZpP,YAAa,MACbC,WAAY7hB,aC/BEixB,GACZnP,GAEK,IAAAqB,WAAQvoB,YACR8D,eAEDwsB,EAAQhxB,OAAK2G,eAAenC,EAAMykB,EAAO,GAAGrnB,OAAO,GACrDwC,EAAWnC,eAAaqC,gBAAgB2kB,EAAO/lB,KAAI,SAAAnD,GAAK,OAAAA,EAAE6B,SAAQovB,GAEtE,GAAqC,IAAjChxB,OAAKgK,cAAc5F,GACrB,OAAO1D,EAAQyoB,eAAe/kB,EAAU6kB,EAAO,GAAG/oB,MAAO,IAI3D,IAAM82B,EAAU/N,EAAOnc,QAAO,SAAA/M,GAAK,OAAAC,OAAKgK,cAAcjK,EAAE6B,OAAS,KACjE,GAAuB,IAAnBo1B,EAAQ9xB,OACV,OAAO8xB,EAAQ,GAGjB,IAAMC,EAASD,EAAQ9zB,KAAI,SAAAnD,GAAK,OAAAA,EAAE6B,SAGlC,GAFAK,eAAai1B,uBAAuBD,EAAQjG,GAEnB,cAArBgG,EAAQ,GAAG92B,MAAuB,CACpC,IAAMi3B,EAAQH,EAAQ9zB,KAAI,SAACnD,GAAM,OAAA8C,EAAK,CAAComB,OAAQ,CAACpc,MAAO9M,GAAIW,eACrD02B,EAAQJ,EAAQ9zB,KAAI,SAACnD,GAAM,OAAAgD,GAAK,CAACkmB,OAAQ,CAACpc,MAAO9M,GAAIW,eAErD22B,EAAeN,GAAO,CAAC9N,OAAQkO,EAAOz2B,UAASopB,MAAO,CAACtlB,UACvD8yB,EAAeP,GAAO,CAAC9N,OAAQmO,EAAO12B,UAASopB,MAAO,CAACtlB,UAEvD6B,EACF2iB,EAAQ,CAACC,OAAQ,CAACpmB,KAAMw0B,EAAct0B,KAAMu0B,GAAe52B,YAO/D,OALAy2B,EAAMr3B,SAAQ,SAAAua,GAAK,OAAA3Z,EAAQwpB,8BAA8B7P,MACzD+c,EAAMt3B,SAAQ,SAAA+E,GAAK,OAAAnE,EAAQwpB,8BAA8BrlB,MACzDnE,EAAQwpB,8BAA8BmN,GACtC32B,EAAQwpB,8BAA8BoN,GAE/BjxB,EAUT,IAAMkxB,EAAWP,EAAQ9zB,KAAI,SAAAnD,GAC3B,IAAMy3B,EAAYx3B,OAAKgK,cAAcjK,EAAE6B,MAAM+D,MAAMqrB,IAEnD,OAAOlrB,GAAQ,CAACmjB,OAAQ,CAACtoB,EAAGZ,GAAIW,UAASopB,MAAO,CAACloB,MADnC,EAAE,EAAG41B,SAKrBpzB,EACInC,eAAaqC,gBAAgBizB,EAASr0B,KAAI,SAAAnD,GAAK,OAAAA,EAAE6B,SAAQ,GAE7D,IAAMguB,EAAU5vB,OAAK2oB,uBACjBqO,EAAQ,GAAG92B,MAAoBF,OAAKgK,cAAc5F,IAEtD,GAA6B,IAAzBmzB,EAAS,GAAG31B,MAAM,GAAU,CAE9B,IAAI61B,EAAS,EACbF,EAASz3B,SAAQ,SAAAC,GACf,IAAMyf,EAAM9e,EAAQY,KAAKU,IAAIjC,EAAEoC,QAAQR,OACjCmD,EAAO9E,OAAKgK,cAAcjK,EAAE6B,OAElCguB,EAAQxtB,IAAIod,EAAKiY,GACjBA,GAAU3yB,SAEP,CACL,IAAI4yB,EAAY,EAEhBH,EAASz3B,SAAQ,SAAAC,GAKf,IAJA,IAAM43B,EAAQj3B,EAAQY,KAAKU,IAAIjC,EAAEoC,QAAQR,OAErCi2B,EAAO,EAEFC,EAAM,EAAGA,EAAM93B,EAAE6B,MAAM,KAAMi2B,EAEpC,IADA,IAAMC,EAASD,EAAMzzB,EAAS,GAAKszB,EAC1BK,EAAM,EAAGA,EAAMh4B,EAAE6B,MAAM,KAAMm2B,EACpCnI,EAAQkI,EAASC,GAAOJ,EAAMC,KAIlCF,GAAa33B,EAAE6B,MAAM,MAIzB,IAAMo2B,EACF/1B,eAAaqC,gBAAgB0yB,EAAQ9zB,KAAI,SAAAnD,GAAK,OAAAA,EAAE6B,SAAQovB,GAEtDiH,EACFv3B,EAAQyoB,eAAe6O,EAAe/O,EAAO,GAAG/oB,MAAO0vB,GAI3D,OAFA2H,EAASz3B,SAAQ,SAAAC,GAAK,OAAAW,EAAQwpB,8BAA8BnqB,MAErDk4B,EAGF,IAAMC,GAA6B,CACxC1Q,WAAY2Q,SACZzQ,YAAa,MACbC,WAAYoP,IC5GDqB,GAAgBtL,EAAgBuL,OAAK,SAAClL,GAAO,OAAAzlB,KAAK4wB,IAAInL,MAEtDoL,GAA0B,CACrC/Q,WAAY6Q,MACZ3Q,YAAa,MACbC,WAAYyQ,ICLDI,GAAiB1L,EAAgB2L,QAAM,SAACtL,GAAO,OAAAzlB,KAAKgxB,KAAKvL,MAEzDwL,GAA2B,CACtCnR,WAAYiR,OACZ/Q,YAAa,MACbC,WAAY6Q,ICLDI,GAAiC,CAC5CpR,WAAYqR,aACZnR,YAAa,MACbC,WAAY,SAACjlB,GAwCX,QAxCYumB,WAAQvoB,YAASopB,UACvBvhB,IAAC5H,MAAGmM,WACJ4F,IAACvO,YAASiwB,QAAK0E,cACfjR,EAAannB,EAEb2E,EAAQwiB,EAAWvmB,KAAKU,IAAIrB,EAAEwB,QAAQR,OACtCivB,EAAQjwB,EAAEiB,MAAMsD,OAEhB6zB,EAAalR,EAAWvmB,KAAKU,IAAI8K,EAAO3K,QAAQR,OAChDq3B,EAAalsB,EAAOlL,MAAMsD,OAE1B+mB,qEACJ3d,cACAU,aACAU,YACAI,eACApB,cACAU,aACA9B,YACAuB,iBACAU,gBACAtC,iBACAC,gBACAC,mBACAC,kBACAhJ,aAOI60B,EAAUj5B,OAAKgK,cAAc5F,GAC7B80B,EAAU90B,EAASc,OACnBiR,EAAanW,OAAK6mB,kBAAkBlmB,EAAET,MAAO+4B,GAM1C/xB,EAAI,EAAGA,EAAIoH,IAAapH,EAC/B,IAAK,IAAIiyB,EAAO,EAAGA,EAAOzqB,IAAayqB,EAErC,IADA,IAAMC,EAAOD,EAAOtqB,EAAevB,EAAQG,IAClC4rB,EAAO,EAAGA,EAAOjqB,IAAYiqB,EAEpC,IADA,IAAMC,EAAOD,EAAO9pB,EAAcjC,EAAQC,KACjCpK,EAAI,EAAGA,EAAI2M,IAAc3M,EAAG,CAEnC,IADA,IAAIo2B,EAASxjB,OAAOyjB,iBACXtX,EAAI,EAAGA,EAAIjV,IAAgBiV,EAAG,CACrC,IAAMuX,EAAML,EAAOlX,EAAI/U,EACvB,GAAIssB,GAAO,GAAKA,EAAMzqB,EACpB,IAAK,IAAIqT,EAAI,EAAGA,EAAInV,IAAemV,EAAG,CACpC,IAAMqX,EAAMJ,EAAOjX,EAAIjV,EACvB,GAAIssB,GAAO,GAAKA,EAAMhqB,EAAS,CAC7B,IAAMogB,EAAS9vB,OAAK2U,WAChB,CAACzN,EAAGuyB,EAAKC,EAAKv2B,GAAIytB,EAAO5wB,OAAKyoB,eAAe9nB,EAAEiB,QAC7C+3B,EAAc35B,OAAK2U,WACrB,CAACuN,EAAGG,EAAGlf,GAAI61B,EACXh5B,OAAKyoB,eAAe3b,EAAOlL,QACzB4d,EAAMna,EAAMyqB,GAAUiJ,EAAWY,GACnCna,EAAM+Z,IACRA,EAAS/Z,KAQnBrJ,EAFoBnW,OAAK2U,WACrB,CAACzN,EAAGiyB,EAAME,EAAMl2B,GAAI+1B,EAASl5B,OAAKyoB,eAAerkB,KAC3Bm1B,EASlC,MAAO,CAACp3B,OAHO0lB,EAAWvlB,MACtBtC,OAAKwqB,aAAarU,EAAYxV,EAAET,OAAQkE,EAAUzD,EAAET,OAExC0B,MAAOwC,EAAUlE,MAAOS,EAAET,SC/EjC05B,GAA+C,CAC1DpS,WAAYqS,2BACZnS,YAAa,MACbC,WAAY,SAACjlB,OAACumB,WAAQvoB,YAASopB,UACvBvhB,IAAC5H,MAAGmM,WAAQT,OAEZqG,IAACvO,YAASiwB,QAAK0E,cACfjR,EAAannB,EAEbo5B,EACF95B,OAAK+5B,cACDp5B,EAAEiB,MAAOimB,EAAWvmB,KAAKU,IAAIrB,EAAEwB,QAAQR,QAGzCq4B,EAAUh6B,OAAK+5B,cACDjtB,EAAOlL,MACPimB,EAAWvmB,KAAKU,IAAI8K,EAAO3K,QAAQR,QAGjDsqB,qEACJ3d,cACAU,aACAU,YACAI,eACApB,cACAU,aACA9B,YACAuB,iBACAU,gBACAtC,iBACAC,gBACAC,mBACAC,kBACAhJ,aAOFpE,OAAKC,OACDoM,EAAG7G,OAASpB,EAASc,QACrB,WAAM,MAAA,YAAY20B,qEACuBz1B,EAASc,oBAC3CmH,EAAG7G,QAiBd,IAfA,IAAMy0B,EACFj6B,OAAK+5B,cACD31B,EAAUyjB,EAAWvmB,KAAKU,IAAIqK,EAAGlK,QAAQR,QAK3Cu4B,EAAYl6B,OAAKm6B,0BACDrtB,EAAOlL,MAAOkL,EAAO5M,OAOlCgH,EAAI,EAAGA,EAAIoH,IAAapH,EAC/B,IAAK,IAAIiyB,EAAO,EAAGA,EAAOzqB,IAAayqB,EAErC,IADA,IAAMC,EAAOD,EAAOtqB,EAAevB,EAAQG,IAClC4rB,EAAO,EAAGA,EAAOjqB,IAAYiqB,EAEpC,IADA,IAAMC,EAAOD,EAAO9pB,EAAcjC,EAAQC,KACjCpK,EAAI,EAAGA,EAAI2M,IAAc3M,EAAG,CAInC,IAHA,IAAIo2B,EAASxjB,OAAOyjB,iBAChBY,EAAO,EACPC,EAAO,EACFnY,EAAI,EAAGA,EAAIjV,IAAgBiV,EAAG,CACrC,IAAMuX,EAAML,EAAOlX,EAAI/U,EACvB,GAAIssB,GAAO,GAAKA,EAAMzqB,EACpB,IAAK,IAAIqT,EAAI,EAAGA,EAAInV,IAAemV,EAAG,CACpC,IAAMqX,EAAMJ,EAAOjX,EAAIjV,EACvB,GAAIssB,GAAO,GAAKA,EAAMhqB,EAAS,CAC7B,IAAM8P,EAAMsa,EAAG5yB,GAAGuyB,GAAKC,GAAKv2B,GAAK62B,EAAQ9X,GAAGG,GAAGlf,GAC3Cqc,EAAM+Z,IACRA,EAAS/Z,EACT4a,EAAOlY,EACPmY,EAAOhY,KAMjB6X,EAAUE,GAAMC,GAAMl3B,IAAM82B,EAAI/yB,GAAGiyB,GAAME,GAAMl2B,GASvD,MAAO,CAAChB,OAHO0lB,EAAWvlB,MACtBtC,OAAKwqB,aAAa0P,EAAWv5B,EAAET,OAAQ4M,EAAOlL,MAAOkL,EAAO5M,OAEhD0B,MAAOkL,EAAOlL,MAAO1B,MAAO4M,EAAO5M,SC/F1Co6B,GAA8C,CACzD9S,WAAY+S,0BACZ7S,YAAa,MACbC,WAAY,SAACjlB,OAACumB,WAAQvoB,YAASopB,UACvBvhB,IAAC5H,MAAGmM,WAAQT,OAEZqG,IAACvO,YAASiwB,QAAK0E,cACfjR,EAAannB,EAEbo5B,EACF95B,OAAK+5B,cACDp5B,EAAEiB,MAAOimB,EAAWvmB,KAAKU,IAAIrB,EAAEwB,QAAQR,QAGzCq4B,EAAUh6B,OAAK+5B,cACDjtB,EAAOlL,MACPimB,EAAWvmB,KAAKU,IAAI8K,EAAO3K,QAAQR,QAGjDsqB,qEACJ3d,cACAU,aACAU,YACAI,eACApB,cACAU,aACA9B,YACAuB,iBACAU,gBACAtC,iBACAC,gBACAC,mBACAC,kBACAhJ,aAOFpE,OAAKC,OACDoM,EAAG7G,OAASpB,EAASc,QACrB,WAAM,MAAA,YAAYq1B,oEACuBn2B,EAASc,oBAC3CmH,EAAG7G,QAiBd,IAfA,IAAMy0B,EACFj6B,OAAK+5B,cACD31B,EAAUyjB,EAAWvmB,KAAKU,IAAIqK,EAAGlK,QAAQR,QAK3Cu4B,EACFl6B,OAAKm6B,0BAA0Bx5B,EAAEiB,MAAOjB,EAAET,OAOrCgH,EAAI,EAAGA,EAAIoH,IAAapH,EAC/B,IAAK,IAAIiyB,EAAO,EAAGA,EAAOzqB,IAAayqB,EAErC,IADA,IAAMC,EAAOD,EAAOtqB,EAAevB,EAAQG,IAClC4rB,EAAO,EAAGA,EAAOjqB,IAAYiqB,EAEpC,IADA,IAAMC,EAAOD,EAAO9pB,EAAcjC,EAAQC,KACjCpK,EAAI,EAAGA,EAAI2M,IAAc3M,EAAG,CAInC,IAHA,IAAIo2B,EAASxjB,OAAOyjB,iBAChBgB,EAAUpB,EAAO,EAAK,EAAIA,EAC1BqB,EAAUnB,EAAO,EAAK,EAAIA,EACrBpX,EAAI,EAAGA,EAAIjV,IAAgBiV,EAAG,CACrC,IAAMuX,EAAML,EAAOlX,EAAI/U,EACvB,GAAIssB,GAAO,GAAKA,EAAMzqB,EACpB,IAAK,IAAIqT,EAAI,EAAGA,EAAInV,IAAemV,EAAG,CACpC,IAAMqX,EAAMJ,EAAOjX,EAAIjV,EACvB,GAAIssB,GAAO,GAAKA,EAAMhqB,EAAS,CAC7B,IAAM8P,EAAMsa,EAAG5yB,GAAGuyB,GAAKC,GAAKv2B,GAAK62B,EAAQ9X,GAAGG,GAAGlf,GAC3Cqc,EAAM+Z,IACRA,EAAS/Z,EACTgb,EAASf,EACTgB,EAASf,KAMnBQ,EAAUhzB,GAAGszB,GAAQC,GAAQt3B,IAAM82B,EAAI/yB,GAAGiyB,GAAME,GAAMl2B,GAS9D,MAAO,CAAChB,OAHO0lB,EAAWvlB,MACtBtC,OAAKwqB,aAAa0P,EAAWv5B,EAAET,OAAQS,EAAEiB,MAAOjB,EAAET,OAEtC0B,MAAOjB,EAAEiB,MAAO1B,MAAOS,EAAET,SC/FhCw6B,GACTtS,GAA6B,SAACphB,EAAWE,GAAc,OAAAF,EAAIE,KAClDyzB,GAAM/P,EAAiBgQ,MAAKF,IAE5BG,GAA0B,CACrCrT,WAAYoT,MACZlT,YAAa,MACbC,WAAYgT,ICRDG,GACThO,EAAgBiO,OAAK,SAAC5N,GAAO,OAAAA,GAAM,EAAIA,EAAMzlB,KAAK8lB,IAAIL,GAAM,KAEnD6N,GAA0B,CACrCxT,WAAYuT,MACZrT,YAAa,MACbC,WAAYmT,ICNRG,GAAIh5B,eAAai5B,MACjBC,GAAKl5B,eAAam5B,OAClBC,GAAKp5B,eAAaq5B,OAClBC,GAAKt5B,eAAau5B,OAClBC,GAAKx5B,eAAay5B,OAClBC,GAAK15B,eAAa25B,OAEXC,GAAgB/O,EACzBgP,OACA,SAAC3O,GACC,IAAM4O,EAAOr0B,KAAKq0B,KAAK5O,GACjBzgB,EAAIhF,KAAK4f,IAAI6F,GACbptB,EAAI,GAAO,EAAMk7B,GAAIvuB,GAC3B,OAAOqvB,GACF,MACKJ,GAAK57B,EAAI07B,IAAM17B,EAAKw7B,IAAMx7B,EAAIs7B,IAAMt7B,EAAIo7B,IAAMp7B,EAC/C2H,KAAK8lB,KAAK9gB,EAAIA,OAIhBsvB,GAA0B,CACrCxU,WAAYsU,MACZpU,YAAa,MACbC,WAAYkU,aCVEI,GACZpvB,EAAmBqvB,EACnBrU,GAgBF,IAfA,IAAMsU,EAAatvB,EAAMjL,MACnB4U,EAAQ2lB,EAAW,GACnBC,EAAWD,EAAW,GAEtBE,EAAYxU,EAAWvmB,KAAKU,IAAI6K,EAAM1K,QAEtCm6B,EAASD,EAAU15B,mBAAmBE,KACtC05B,EAASF,EAAU15B,mBAAmBI,KAGtCsjB,EAAc,CAAC7P,EAAO4lB,GACtB1T,EAAa1oB,OAAKgK,cAAcqc,GAChC0F,EAAa/rB,OAAK2oB,uBAAuB,UAAWD,GACpDsD,EAAahsB,OAAK2oB,uBAAuB,UAAWD,GAEjDxhB,EAAI,EAAGA,EAAIsP,EAAOtP,IAAK,CAmB9B,IAjBA,IAAMmT,EAAI1U,GAAM,CACdsjB,OAAQ,CAACtoB,EAAG27B,GACZ57B,QAASmnB,EACTiC,MAAO,CAAC7lB,MAAO,CAACiD,EAAG,GAAIpC,KAAM,CAAC,EAAGs3B,MAE7Bv3B,EAAIc,GAAM,CACdsjB,OAAQ,CAACtoB,EAAG47B,GACZ77B,QAASmnB,EACTiC,MAAO,CAAC7lB,MAAO,CAACiD,EAAG,GAAIpC,KAAM,CAAC,EAAGs3B,MAG7BI,EAAQxT,EAAQ,CAACC,OAAQ,CAACpmB,KAAMwX,EAAGtX,KAAM8B,GAAInE,QAASmnB,IAGtDnlB,YAACulB,SAAMC,SACPtiB,EAAM3D,eAAae,uBAAuBilB,EAAMC,GAE7C/kB,EAAI,EAAGA,EAAIi5B,EAAUj5B,IAAK,CACjC,IAAMyX,EAAI3Y,eAAaw6B,oBAAoB72B,EAAKzC,GAChD4oB,EAAW7kB,EAAIk1B,EAAWj5B,GAAKyX,EAAE/X,KACjCmpB,EAAW9kB,EAAIk1B,EAAWj5B,GAAKyX,EAAE7X,KAGnC8kB,EAAWqC,8BAA8B7P,GACzCwN,EAAWqC,8BAA8BrlB,GACzCgjB,EAAWqC,8BAA8BsS,GAG3C,IAAME,EACF7U,EAAWsB,eAAe9C,EAAa,UAAW0F,GAChD4Q,EACF9U,EAAWsB,eAAe9C,EAAa,UAAW2F,GAEhD3lB,EAAS2iB,EACX,CAACC,OAAQ,CAACpmB,KAAM65B,EAAW35B,KAAM45B,GAAYj8B,QAASmnB,IAK1D,OAHAA,EAAWqC,8BAA8BwS,GACzC7U,EAAWqC,8BAA8ByS,GAElCt2B,WAGOu2B,GACZ/vB,EAAmBqvB,EACnBrU,GACF,IAAMgV,EAAY78B,OAAKgK,cAAc6C,EAAMjL,OAErCy6B,EAAYxU,EAAWvmB,KAAKU,IAAI6K,EAAM1K,QAEtC4lB,EACFF,EAAWvmB,KAAKU,IAAIq6B,EAAU15B,mBAAmBE,KAAKV,QAAQR,OAG5DqmB,EACFH,EAAWvmB,KAAKU,IAAIq6B,EAAU15B,mBAAmBI,KAAKZ,QAAQR,OAGlE,GAsD6B,KADRmD,EArDH+3B,GAsDH/3B,EAAO,GAtDQ,CAC5B,IAAMuB,EAyDV,SAASy2B,EACL/U,EAAwBC,EAAwBljB,EAChDo3B,EACArU,GACF,GAAa,IAAT/iB,EACF,MAAO,CAACjC,KAAMklB,EAAUhlB,KAAMilB,GAGhC,IAAM1mB,EAAOW,eAAae,uBAAuB+kB,EAAUC,GAErD+U,EAAOj4B,EAAO,EAEdk4B,EAAc/6B,eAAag7B,qBAAqB37B,GAEhD47B,EAAeF,EAAYn6B,KAC3Bs6B,EAAeH,EAAYj6B,KAE3Bq6B,EAAY,CAACF,EAAah4B,QAE1Bm4B,EACFxV,EAAWsB,eAAeiU,EAAW,UAAWF,GAC9CI,EACFzV,EAAWsB,eAAeiU,EAAW,UAAWD,GAE9CI,EAAiBvU,EACnB,CAACC,OAAQ,CAACpmB,KAAMw6B,EAAct6B,KAAMu6B,GAAe58B,QAASmnB,IAE1D2V,EAAav7B,eAAaw7B,oBAAoBn8B,GAE9Co8B,EAAcF,EAAW36B,KACzB86B,EAAcH,EAAWz6B,KAEzB66B,EAAW,CAACF,EAAYx4B,QAExB24B,EACFhW,EAAWsB,eAAeyU,EAAU,UAAWF,GAC7CI,EACFjW,EAAWsB,eAAeyU,EAAU,UAAWD,GAE7CI,EAAgB/U,EAClB,CAACC,OAAQ,CAACpmB,KAAMg7B,EAAa96B,KAAM+6B,GAAcp9B,QAASmnB,IAGxDmW,EACFlB,EAAUI,EAAcC,EAAcJ,EAAMb,EAASrU,GAEnDoW,EAAgBD,EAAan7B,KAC7Bq7B,EAAgBF,EAAaj7B,KAE7Bo7B,EAAa,CAACF,EAAc/4B,QAE5Bk5B,EACFvW,EAAWsB,eAAegV,EAAY,UAAWF,GAC/CI,EACFxW,EAAWsB,eAAegV,EAAY,UAAWD,GAE/CI,EAAkBtV,EAAQ,CAC9BC,OAAQ,CAACpmB,KAAMu7B,EAAer7B,KAAMs7B,GACpC39B,QAASmnB,IAGL0W,EACFzB,EAAUY,EAAaC,EAAaZ,EAAMb,EAASrU,GAEjD2W,EAAeD,EAAY17B,KAC3B47B,EAAeF,EAAYx7B,KAE3B27B,EAAY,CAACF,EAAat5B,QAE1By5B,EACF9W,EAAWsB,eAAeuV,EAAW,UAAWF,GAC9CI,EACF/W,EAAWsB,eAAeuV,EAAW,UAAWD,GAE9CI,EAAiB7V,EACnB,CAACC,OAAQ,CAACpmB,KAAM87B,EAAc57B,KAAM67B,GAAel+B,QAASmnB,IAE1DiX,EAAI78B,eAAa88B,UAAUj6B,EAAMo3B,GACjC8C,EAAS,CAACF,EAAEj8B,KAAKqC,QAEjB+5B,EAAYpX,EAAWsB,eAAe6V,EAAQ,UAAWF,EAAEj8B,MAC3Dq8B,EAAYrX,EAAWsB,eAAe6V,EAAQ,UAAWF,EAAE/7B,MAE3DmmB,EAAcF,EAChB,CAACC,OAAQ,CAACpmB,KAAMo8B,EAAWl8B,KAAMm8B,GAAYx+B,QAASmnB,IAEpDsX,EACFtQ,EACI,CAAC5F,OAAQ,CAACjiB,EAAGkiB,EAAahiB,EAAG23B,GAAiBn+B,QAASmnB,IAGzDuX,EAAU1S,EAAI,CACFzD,OAAQ,CAACjiB,EAAGs3B,EAAiBp3B,EAAGi4B,GAChCz+B,QAASmnB,IAErBwX,EAAU/O,GAAI,CACFrH,OAAQ,CAACjiB,EAAGs3B,EAAiBp3B,EAAGi4B,GAChCz+B,QAASmnB,IAGrByX,EAAcz8B,EAAK,CAAComB,OAAQ,CAACpc,MAAOuyB,GAAU1+B,QAASmnB,IACvD0X,EAAc18B,EAAK,CAAComB,OAAQ,CAACpc,MAAOwyB,GAAU3+B,QAASmnB,IAEvD2X,EAAcz8B,GAAK,CAACkmB,OAAQ,CAACpc,MAAOuyB,GAAU1+B,QAASmnB,IACvD4X,EAAc18B,GAAK,CAACkmB,OAAQ,CAACpc,MAAOwyB,GAAU3+B,QAASmnB,IAEvD6X,EAAQ3I,GAAO,CACnB9N,OAAQ,CAACqW,EAAuBC,GAChC7+B,QAASmnB,EACTiC,MAAO,CAACtlB,KAAM,KAEVm7B,GAAQ5I,GAAO,CACnB9N,OAAQ,CAACuW,EAAuBC,GAChC/+B,QAASmnB,EACTiC,MAAO,CAACtlB,KAAM,KAGVo7B,GAAY/X,EAAWvmB,KAAKU,IAAI09B,EAAMv9B,QAAQR,OAC9Ck+B,GAAYhY,EAAWvmB,KAAKU,IAAI29B,GAAMx9B,QAAQR,OA2BpD,OAzBAkmB,EAAWqC,8BAA8BmT,GACzCxV,EAAWqC,8BAA8BoT,GACzCzV,EAAWqC,8BAA8BqT,GACzC1V,EAAWqC,8BAA8B2T,GACzChW,EAAWqC,8BAA8B4T,GACzCjW,EAAWqC,8BAA8B6T,GACzClW,EAAWqC,8BAA8BkU,GACzCvW,EAAWqC,8BAA8BmU,GACzCxW,EAAWqC,8BAA8BoU,GACzCzW,EAAWqC,8BAA8ByU,GACzC9W,EAAWqC,8BAA8B0U,GACzC/W,EAAWqC,8BAA8B2U,GACzChX,EAAWqC,8BAA8B+U,GACzCpX,EAAWqC,8BAA8BgV,GACzCrX,EAAWqC,8BAA8BhB,GACzCrB,EAAWqC,8BAA8BiV,GACzCtX,EAAWqC,8BAA8BkV,GACzCvX,EAAWqC,8BAA8BmV,GACzCxX,EAAWqC,8BAA8BoV,GACzCzX,EAAWqC,8BAA8BsV,GACzC3X,EAAWqC,8BAA8BqV,GACzC1X,EAAWqC,8BAA8BuV,GACzC5X,EAAWqC,8BAA8BwV,GACzC7X,EAAWqC,8BAA8ByV,IAElC,CAAC98B,KAAM+8B,GAAW78B,KAAM88B,IAzMzB/C,CAAU/U,EAAUC,EAAU6U,EAAWX,EAASrU,GAEhDxB,EAAc,CAACxZ,EAAMjL,MAAM,GAAIiL,EAAMjL,MAAM,IAEjD,GAAIs6B,EAAS,CACX,IAAM4D,EACFjY,EAAWsB,eAAe9C,EAAa,UAAWhgB,EAAOxD,MACvDk9B,EACFlY,EAAWsB,eAAe9C,EAAa,UAAWhgB,EAAOtD,MAEvDi9B,EAAuBnY,EAAWsB,eACpC,GAAI,UACJnpB,OAAKigC,kBAAkBpD,EAA8B,YACnDqD,EACF5W,EAAS,CAACL,OAAQ,CAACtoB,EAAGq/B,GAAWt/B,QAASmnB,IAExCsY,EACFtF,GAAUlT,WACN,CAACsB,OAAQ,CAACjiB,EAAG84B,EAAU54B,EAAG84B,GAAWt/B,QAASmnB,IAEhDuY,EACFvF,GAAUlT,WACN,CAACsB,OAAQ,CAACjiB,EAAG+4B,EAAU74B,EAAGg5B,GAAex/B,QAASmnB,IAGpDwY,EACFxY,EAAWvmB,KAAKU,IAAIm+B,EAAYh+B,QAAQR,OACtC2+B,EACFzY,EAAWvmB,KAAKU,IAAIo+B,EAAYj+B,QAAQR,OAS5C,OAPAkmB,EAAWqC,8BAA8B4V,GACzCjY,EAAWqC,8BAA8B6V,GACzClY,EAAWqC,8BAA8B8V,GACzCnY,EAAWqC,8BAA8BgW,GACzCrY,EAAWqC,8BAA8BiW,GACzCtY,EAAWqC,8BAA8BkW,GAElC,CAACv9B,KAAMw9B,EAAat9B,KAAMu9B,GAGnC,OAAOj6B,EAEP,IASmBvB,EAPby7B,EAiKV,SACIj/B,EAAkBwD,EAAco3B,GAGlC,IAFA,IAAMsE,EAAM,IAAIh0B,aAAoB,EAAP1H,GAEpBuV,EAAI,EAAGA,EAAIvV,EAAMuV,IAAK,CAG7B,IAFA,IAAIomB,EAAO,EACPC,EAAO,EACF9lB,EAAI,EAAGA,EAAI9V,EAAM8V,IAAK,CAC7B,IAAMkkB,EAAI78B,eAAa0+B,SAAStmB,EAAIO,EAAG9V,EAAMo3B,GACvC0E,EAAO3+B,eAAaw6B,oBAAoBn7B,EAAsBsZ,GACpE6lB,GAAQG,EAAK/9B,KAAOi8B,EAAEj8B,KAAO+9B,EAAK79B,KAAO+7B,EAAE/7B,KAC3C29B,GAAQE,EAAK/9B,KAAOi8B,EAAE/7B,KAAO69B,EAAK79B,KAAO+7B,EAAEj8B,KAEzCq5B,IACFuE,GAAQ37B,EACR47B,GAAQ57B,GAEV7C,eAAa4+B,mBAAmBL,EAAKC,EAAMC,EAAMrmB,GAEnD,OAAOmmB,EAnLDM,CAHS7+B,eAAae,uBAAuB+kB,EAAUC,GAGxB6U,EAAWX,GAE9C,OAAOj6B,eAAa8+B,uBAAuBR,GC7GxC,IAAMS,GAA0B,CACrCxZ,WAAYyZ,MACZvZ,YAAa,MACbC,oBA/BkBC,GAEX,IAAAqB,WAAQvoB,YACRmM,UAEDgwB,EAAY78B,OAAKgK,cAAc6C,EAAMjL,OAGrCs/B,EAAqBr0B,EAAMjL,MAAMiL,EAAMjL,MAAMsD,OAAS,GAGtDi8B,EAAUr7B,GAAQ,CACtBmjB,OAAQ,CAACtoB,EAAGkM,GACZnM,UACAopB,MAAO,CAACloB,MAAO,CALHi7B,EAAYqE,EAKDA,MAGnB76B,EAAS41B,GAASkF,GAAS,EAAOzgC,GAElC0gC,EACFt7B,GAAQ,CAACmjB,OAAQ,CAACtoB,EAAG0F,GAAS3F,UAASopB,MAAO,CAACloB,MAAOiL,EAAMjL,SAKhE,OAHAlB,EAAQwpB,8BAA8BiX,GACtCzgC,EAAQwpB,8BAA8B7jB,GAE/B+6B,IC1BIC,GAAoC,CAC/C7Z,WAAY8Z,gBACZ5Z,YAAa,MACbC,WAAY,SAACjlB,GAUX,QAVYumB,WAAevoB,sBACpB6gC,UACD1Z,EAAannB,EAEbwV,EAASlW,OAAK2oB,uBAChB4Y,EAAMrhC,MAA0BF,OAAKgK,cAAcu3B,EAAM3/B,QACvD2G,UAACiO,OAAOoN,OAAaC,OAAY9J,OAEjCoK,EAAY0D,EAAWvmB,KAAKU,IAAIu/B,EAAMp/B,QAAQR,OAE3C6/B,EAAW,EAAGA,EAAWhrB,EAAOgrB,IAGvC,IAFA,IAAM9jB,EAAc8jB,EAAW3d,EAAaD,EAAc7J,EAEjD8d,EAAM,EAAGA,EAAMjU,EAAaiU,IAGnC,IAFA,IAAMla,EAAYka,GAAOhU,EAAa9J,GAE7Bge,EAAM,EAAGA,EAAMlU,EAAYkU,IAGlC,IAFA,IAAMla,EAAYka,EAAMhe,EAEfpD,EAAU,EAAGA,EAAUoD,EAAapD,IAAW,CACtD,IAEMhW,EAFS,CAAC6V,EAAOqhB,EAAKE,EAAKphB,GAEhB,GAEX8qB,EAAS/5B,KAAKkW,MAAMiG,EAAaljB,GACjC+gC,EAAShkB,EAAcC,EAAYE,EAAYlH,EAEjDgrB,EAAcxd,EAAUud,GAE5B,GAAID,GAAU,GAAKA,EAAS5d,EAK1B8d,EAAcxd,EADVzG,EAAcC,EAFO8jB,EAAS1nB,EAEepD,GAGnDT,EAAOwrB,GAAUC,EAOzB,MAAO,CAACx/B,OADO0lB,EAAWvlB,MAAM4T,EAAQqrB,EAAM3/B,MAAO2/B,EAAMrhC,OAC3C0B,MAAO2/B,EAAM3/B,MAAO1B,MAAOqhC,EAAMrhC,SCjB9C,IAAM0hC,GAA2B,CACtCpa,WAAYqa,OACZna,YAAa,MACbC,oBA/BmBC,GAEZ,IAAAqB,WAAQvoB,YACRmM,UAEDgwB,EAAY78B,OAAKgK,cAAc6C,EAAMjL,OAGrCs/B,EAAqBr0B,EAAMjL,MAAMiL,EAAMjL,MAAMsD,OAAS,GAGtDi8B,EAAUr7B,GAAQ,CACtBmjB,OAAQ,CAACtoB,EAAGkM,GACZnM,UACAopB,MAAO,CAACloB,MAAO,CALHi7B,EAAYqE,EAKDA,MAGnB76B,EAAS41B,GAASkF,GAAS,EAAMzgC,GAEjC0gC,EACFt7B,GAAQ,CAACmjB,OAAQ,CAACtoB,EAAG0F,GAAS3F,UAASopB,MAAO,CAACloB,MAAOiL,EAAMjL,SAKhE,OAHAlB,EAAQwpB,8BAA8BiX,GACtCzgC,EAAQwpB,8BAA8B7jB,GAE/B+6B,IC3BIU,GACThV,EAAgBiV,YAAU,SAAC5U,GAAO,OAAApX,OAAOisB,SAAS7U,GAAM,EAAI,IAAG,QAEtD8U,GAA+B,CAC1Cza,WAAYua,WACZra,YAAa,MACbC,WAAYma,ICNDI,GACTpV,EAAgBqV,SAAO,SAAChV,GAAO,OAAAzlB,KAAK4f,IAAI6F,KAAQiV,EAAAA,EAAW,EAAI,IAAG,QAEzDC,GAA4B,CACvC7a,WAAY2a,QACZza,YAAa,MACbC,WAAYua,ICNDI,GACTxV,EAAgByV,SAAO,SAACpV,GAAO,OAAApX,OAAOqC,MAAM+U,GAAM,EAAI,IAAG,QAEhDqV,GAA4B,CACvChb,WAAY+a,QACZ7a,YAAa,MACbC,WAAY2a,ICNDG,GAAkB3V,EAAgB4V,SAAO,SAACvV,GAAO,OAAAzlB,KAAKi7B,MAAMxV,MAE5DyV,GAA4B,CACvCpb,WAAYkb,QACZhb,YAAa,MACbC,WAAY8a,ICLDI,GACT/V,EAAgBgW,cAAY,SAAC3V,GAAO,OAAAA,EAAK,EAAI,IAAG,QAEvC4V,GAAiC,CAC5Cvb,WAAYsb,aACZpb,YAAa,MACbC,WAAYkb,ICADG,GAA0B,CACrCxb,WAAYyb,MACZvb,YAAa,MACbC,WAAY,SAACjlB,OAACumB,WAAQa,UAAOppB,YACpBC,MACD4H,IAAC26B,qBAAkBC,aACnBtb,EAAannB,EACfgwB,EAAS/vB,EAAEiB,MACTgvB,EAAQF,EAAOxrB,OAEfk+B,EAAWpjC,OAAK2G,eAAeu8B,EAAkBxS,GACnDhqB,EAAO08B,EACLC,EAAephC,eAAaqhC,mBAAmB58B,EAAMkqB,GACvDvrB,EAAQwiB,EAAWvmB,KAAKU,IAAIrB,EAAEwB,QAAQR,OAC1C,GAAoB,MAAhB0hC,EAAsB,CAExB,IADA,IAAM9uB,EAAqB,IAAI3U,MAAMgxB,GAC5B/rB,EAAI,EAAGA,EAAI0P,EAASrP,OAAQL,IACnC0P,EAAS1P,GAAK6rB,EAAO2S,EAAax+B,IAGpCQ,EAAQorB,GAAcprB,EAAOqrB,EAAQ/vB,EAAET,MAAOmjC,EAAc9uB,GAC5D7N,EAAOzE,eAAashC,iBAAiB78B,EAAKxB,OAAQ0rB,GAElDF,EAASnc,EAGX9U,EAAiBkB,EAAG,OACpBsB,eAAayH,2BAA2B,MAAOhD,EAAMkqB,GAC/C,IAAAle,gDAAC8wB,OAAa75B,OAKdtD,EAASqoB,EAAQrpB,EAFJrF,OAAKgK,cAAcL,GAEI65B,EAAa7iC,EAAET,OACnDiC,EAAS0lB,EAAWvlB,MAAM+D,EAAQm9B,EAAa7iC,EAAET,OAEnDkE,EAAWo/B,EACXL,IAGF/+B,EADMmQ,EAAWtS,eAAa8E,qBAAqBy8B,EAAaJ,IAIlE,MAAO,CAACjhC,SAAQP,MAAOwC,EAAUlE,MAAOS,EAAET,SCdvC,IAAMujC,GAA8B,CACzCjc,WAAYkc,UACZhc,YAAa,MACbC,oBAnCEC,GAGK,IAAAqB,WAAQvoB,YAASopB,UACjBnpB,MACPlB,EAAiBkB,EAAG,WACb,IAAAwzB,eAAYhwB,YAASiwB,QAAKC,oBAGjCr0B,OAAKC,OACDgC,eAAaqyB,+BAA+BnwB,EAH9B,IAId,WAAM,MAAA,wEACaA,0BAEvB,IAGIyB,EAHEmH,EAAW9K,eAAasyB,kBAC1B5zB,EAAEiB,MAA2CuyB,EAAYhwB,EAR3C,EASHiwB,EAAKC,GAGpB,GAA6B,IAAzBtnB,EAASG,aAA+C,IAA1BH,EAASE,cACvCjN,OAAKw0B,YAAYznB,EAASmE,QAASnE,EAAS3I,UAC9CwB,EAAM0jB,EAAS,CAACL,OAAQ,CAACtoB,KAAID,gBACxB,CACL,IAAMgT,EAAUhT,EAAQY,KAAKU,IAAIrB,EAAEwB,QAAQR,OACrC8yB,EAAUz0B,OAAKyoB,eAAe9nB,EAAEiB,OAChC8C,EAASgvB,GAAKhgB,EAAS/S,EAAEiB,MAAOjB,EAAET,MAAOu0B,EAAS1nB,EAAU,OAClEnH,EAAMlF,EAAQyoB,eACVpc,EAAS3I,SAAUzD,EAAET,MAAOwE,EAAO/C,QAEzC,OAAOiE,IC2CF,IAAM+9B,GAAsC,CACjDnc,WAAYoc,kBACZlc,YAAa,MACbC,oBA7E8BC,GAKvB,IAAAqB,WAAQvoB,YAASopB,UACjBzd,OAAIQ,UACLlM,EAAIkM,EACVpN,EAAiB,CAACoN,YAAgB,mBAyBlC,IAxBO,IAAAsnB,eAAYhwB,YAASiwB,QAAKC,oBAE3BtnB,EAAW9K,eAAasyB,kBAC1B5zB,EAAEiB,MAA2CuyB,EAAYhwB,EACzD,EAAmBiwB,EAAKC,GACtB3gB,EAAUhT,EAAQY,KAAKU,IAAIrB,EAAEwB,QAAQR,OACrC6X,EAAY9U,SACdqI,EAAS3I,SAAUzD,EAAET,MACrB4zB,GAAiBpgB,EAAS/S,EAAEiB,MAAOjB,EAAET,MAAO6M,GAAUpL,QACpDkN,EAAe9B,EAAS8B,aACxBU,EAAcxC,EAASwC,YACvBpC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBwI,EAAwB7I,EAAS6I,sBACjCC,EAAuB9I,EAAS8I,qBAChCxI,EAAUwI,EAAuB,EAAI9I,EAASO,QAAQC,KACtDC,EAASoI,EAAwB,EAAI7I,EAASO,QAAQG,IACtDwD,EACFvM,SAAgB/D,EAAEiB,MAA2C,WAE3DgzB,EAASl0B,EAAQY,KAAKU,IAAIqK,EAAGlK,QAAQR,OACrCsR,EAAQvO,SACV2H,EAAGzK,MAA2C,UAAWgzB,GAEpD1tB,EAAI,EAAGA,EAAI6F,EAASuB,YAAapH,EACxC,IAAK,IAAI/D,EAAI,EAAGA,EAAI4J,EAAS+C,aAAc3M,EACzC,IAAK,IAAIgZ,EAAM,EAAGA,EAAMpP,EAASiC,WAAYmN,EAC3C,IAAK,IAAIO,EAAM,EAAGA,EAAM3P,EAAS2C,UAAWgN,EAAK,CAK/C,IAHA,IAAMmY,EAAY1Y,EAAM3O,EAClBsnB,EAAYpY,EAAMrP,EACpB0E,EAAU,EACLjD,EAAK,EAAGA,EAAK8G,EAAuB9G,GAAM3B,EAAgB,CACjE,IAAMsR,GAAOoW,EAAY/lB,GAAMD,EAC/B,KAAI4P,EAAM,GAAKA,GAAO1R,EAAS2B,WAC3BhH,KAAK+B,MAAMgV,KAASA,GAGxB,IAAK,IAAIjP,EAAK,EAAGA,EAAKqG,EAAsBrG,GAAMpC,EAAe,CAC/D,IAAMwR,GAAOkW,EAAYtlB,GAAMD,EAC/B,KAAIqP,EAAM,GAAKA,GAAO7R,EAASqC,UAC3B1H,KAAK+B,MAAMmV,KAASA,GADxB,CAIA,IAIMnF,EAJS7D,EAAwBC,EAAuB,EACzD2D,EAAUxX,IAAIkF,EAAGuX,EAAKG,EAAKzb,KACjB2L,EAAK+G,EAAuBrG,EAEV,EAAI,EACrC,GAAa,IAATiK,EAKJ1H,GADckB,EAAMjR,IAAIkF,EAAGuX,EAAKG,EAAKzb,GAClBsW,IAGvBxI,EAAG7O,IAAI2P,EAAS7K,EAAGiV,EAAKO,EAAKvZ,GAKrC,OAAOzC,EAAQyoB,eAAelY,EAAGrP,MAAOqP,EAAG/Q,MAAO+Q,EAAGtP,UCrEhD,IAAMkiC,GAAwC,CACnDrc,WAAYsc,oBACZpc,YAAa,MACbC,WAAY,SAACjlB,OAACumB,WAAQa,UAAOppB,YACpBC,MACD4H,IAAC4rB,eAAYhwB,YAASiwB,QAAKJ,wBAE3BnM,EAAannB,EACnBjB,EAAiBkB,EAAG,qBAEpB,IAAMgB,EAASkmB,EAAWvmB,KAAKU,IAAIrB,EAAEwB,QAAQR,OACvCoL,EAAW9K,eAAasyB,kBAC1B5zB,EAAEiB,MAA2CuyB,EAAYhwB,EACzD,CAAC,EAAG,GAAIiwB,GACN1hB,WClBNgB,EAAqBgd,EAAkBxwB,EACvC8zB,EAA8BjnB,GAChC,IACMg3B,EAAWrQ,GAAKhgB,EAASgd,EAAQxwB,EADvBF,OAAKyoB,eAAeiI,GACmB3jB,EAAU,OAC3DqM,EAAe0a,GACjBpgB,EAASgd,EAAQxwB,EAAO6M,GAAU,EAAMinB,GAE5C,MAAO,CAAC+P,EAASpiC,OAAQyX,EAAazX,gCDW7BqiC,OAAQC,OAGTC,EACFrc,EAAWvlB,MAAM0hC,EAAwBj3B,EAAS3I,SAAUzD,EAAET,OAC5DikC,EACFtc,EAAWvlB,MAAM2hC,EAAuBl3B,EAAS3I,SAAUzD,EAAET,OACjE,MAAO,CACL,CAACiC,OAAQ+hC,EAActiC,MAAOmL,EAAS3I,SAAUlE,MAAOS,EAAET,OAC1D,CAACiC,OAAQgiC,EAAeviC,MAAOmL,EAAS3I,SAAUlE,MAAO,YE3BzDkkC,GAA0BhkC,eAAagkC,wBAIhCC,GAA0C,CACrD7c,WAAY8c,sBACZ5c,YAAa,MACbC,WAAY,SAACjlB,OAACumB,WAAQvoB,YAASopB,UACvBvhB,IAAC8Y,UAAOC,WACR5O,IAAC6O,kBAAeC,iBAAcC,mBAAgB8iB,uBAG9C1c,EAAannB,EAEnBjB,EAAiB4hB,EAAO,2BAExB,IAAMK,EAAYmG,EAAWvmB,KAAKU,IAAIqf,EAAMlf,QAAQR,OAC9CggB,EAAakG,EAAWvmB,KAAKU,IAAIsf,EAAOnf,QAAQR,OAEhDsqB,kBAIN,MAAO,qCCvBLuY,GAA0BpkC,eAAaokC,wBAIhCC,GAA0C,CACrDjd,WAAYkd,sBACZhd,YAAa,MACbC,WAAY,SAACjlB,OAACumB,WAAQvoB,YAASopB,UACvBvhB,IAAC8Y,UAAOC,WACR5O,IAAC6O,kBAAeC,iBAAcC,mBAAgBkjB,iBAG9C9c,EAAannB,EAEnBjB,EAAiB4hB,EAAO,8BAExB,IAAMK,EAAYmG,EAAWvmB,KAAKU,IAAIqf,EAAMlf,QAAQR,OAC9CggB,EAAakG,EAAWvmB,KAAKU,IAAIsf,EAAOnf,QAAQR,OAOhDsqB,SALmB1K,EACDC,EACEC,EACFkjB,GAMxB,MAAO,uCC1BEC,GACTxc,YAA+BphB,EAAGE,GAAM,OAACF,IAAME,EAAK,EAAI,KAC/C29B,GACTja,EAAiBka,WAAUF,GAAc,KAAsB,QAEtDG,GAA+B,CAC1Cvd,WAAYsd,WACZpd,YAAa,MACbC,WAAYkd,ICkCP,IAAMG,GAA4B,CACvCxd,WAAYyd,QACZvd,YAAa,MACbC,oBA5CEC,GAEK,IAAAqB,WAAQvoB,YAASopB,UACjBnpB,MACAukC,aAAUC,kBAEjB1lC,EAAiBkB,EAAG,OAEpB,IAAMyD,EAAW8gC,EAAShiC,KACtB,SAAC+3B,EAAGp2B,GAAM,OAAAo2B,EAAE,GAAqBt6B,EAAEiB,MAAMiD,GAAKo2B,EAAE,MAE9Cr3B,EAAQshC,EAAShiC,KAAI,SAAA+3B,GAAK,OAAAA,EAAE,MAE5B51B,EAAQ3E,EAAQY,KAAKU,IAAIrB,EAAEwB,QAAQR,OACnCorB,EAAQ/sB,OAAKgK,cAAcrJ,EAAEiB,OAC7BgvB,EAAQjwB,EAAEiB,MAAMsD,OAChBsqB,EAAWxvB,OAAKyoB,eAAe9nB,EAAEiB,OAEjC8mB,EAAa1oB,OAAKgK,cAAc5F,GAChCmkB,EAAankB,EAASc,OACtBsjB,EAAgBxoB,OAAKyoB,eAAerkB,GACpCuE,EACF3I,OAAK2oB,uBAAuBhoB,EAAET,MAA0BwoB,GAEtC,IAAlByc,GACFx8B,EAAQjD,KAAKy/B,GAGf,IAAK,IAAItgC,EAAI,EAAGA,EAAIkoB,EAAOloB,IAAK,CAC9B,IACMugC,EADSplC,OAAKgF,WAAWH,EAAG+rB,EAAOpB,GAChBtsB,KAAI,SAAC0X,EAAG/V,GAAM,OAAA+V,EAAIhX,EAAMiB,MAGjD8D,EAFiB3I,OAAK2U,WAAWywB,EAAW7c,EAAYC,IAEpCnjB,EAAMR,GAK5B,MAAO,CAAC1C,OAFMzB,EAAQ4B,MAAMqG,EAASvE,EAAUzD,EAAET,OAE1B0B,MAAOwC,EAAUlE,MAAOS,EAAET,SCxCtCmlC,GAAuBvY,EAAgBwY,cAAY,SAACnY,GAAO,OAAA,EAAIA,KAE/DoY,GAAiC,CAC5C/d,WAAY8d,aACZ5d,YAAa,MACbC,WAAY0d,ICJDG,GAAuC,CAClDhe,WAAYie,mBACZ/d,YAAa,MACbC,WAAY,SAACjlB,GAiBX,QAjBYumB,WAAQa,UAAOppB,YACpB6gC,UACDh5B,IAACm9B,YAASC,cAAWC,WACrB/d,EAAannB,EAEbwV,EAASlW,OAAK2oB,uBAChB4Y,EAAMrhC,MAA0BF,OAAKgK,cAAcu3B,EAAM3/B,QACvD8Q,UAAC8D,OAAOoN,OAAaC,OAAY9J,OAEjCkS,uCAAC4Z,OAASC,OAIVC,EAAYr+B,KAAKs+B,IAAIN,GACrBO,EAAYv+B,KAAK4wB,IAAIoN,GACrBvhB,EAAY0D,EAAWvmB,KAAKU,IAAIu/B,EAAMp/B,QAAQR,OAE3C6/B,EAAW,EAAGA,EAAWhrB,EAAOgrB,IAGvC,IAFA,IAAM9jB,EAAc8jB,EAAW3d,EAAaD,EAAc7J,EAEjD8d,EAAM,EAAGA,EAAMjU,EAAaiU,IAGnC,IAFA,IAAMla,EAAYka,GAAOhU,EAAa9J,GAE7Bge,EAAM,EAAGA,EAAMlU,EAAYkU,IAGlC,IAFA,IAAMla,EAAYka,EAAMhe,EAEfpD,EAAU,EAAGA,EAAUoD,EAAapD,IAAW,CACtD,IAAMuvB,EAAS,CAAC1vB,EAAOqhB,EAAKE,EAAKphB,GAE3BhW,EAAIulC,EAAO,GACX55B,EAAI45B,EAAO,GAGbzE,GAAU9gC,EAAIklC,GAAWI,GAAa35B,EAAIw5B,GAAWC,EACrDI,GAAUxlC,EAAIklC,GAAWE,GAAaz5B,EAAIw5B,GAAWG,EACzDxE,EAAS/5B,KAAKkW,MAAM6jB,EAASoE,GAC7BM,EAASz+B,KAAKkW,MAAMuoB,EAASL,GAE7B,IAAInE,EAAcgE,EAUlB,GATyB,iBAAdA,IAEPhE,EADc,IAAZhrB,EA7BW,IAgCCgvB,EAAUhvB,IAKxB8qB,GAAU,GAAKA,EAAS5d,GAAcsiB,GAAU,GAChDA,EAASviB,EAMX+d,EAAcxd,EADVzG,EAHqByoB,GAAUtiB,EAAa9J,GACvB0nB,EAAS1nB,EAEsBpD,GAK1DT,EADewH,EAAcC,EAAYE,EAAYlH,GACpCgrB,EAOzB,MAAO,CAACx/B,OADO0lB,EAAWvlB,MAAM4T,EAAQqrB,EAAM3/B,MAAO2/B,EAAMrhC,OAC3C0B,MAAO2/B,EAAM3/B,MAAO1B,MAAOqhC,EAAMrhC,SCtExCkmC,GAAkBtZ,EAAgBuZ,SAAO,SAAClZ,GAErD,IAAMmZ,EAAO5+B,KAAK+B,MAAM0jB,GACxB,OAAIA,EAAKmZ,EAAO,GACP5+B,KAAK+B,MAAM0jB,GACTA,EAAKmZ,EAAO,GACd5+B,KAAKiK,KAAKwb,GAEbmZ,EAAO,GAAQ,EACVA,EAEAA,EAAO,KAKPC,GAA4B,CACvC/e,WAAY6e,QACZ3e,YAAa,MACbC,WAAYye,ICnBRI,GAAavkC,eAAawkC,gBAC1BxR,GAAQhzB,eAAaykC,WAEdC,GAAiB7Z,EAAgB8Z,QAAM,SAACzZ,GACnD,OAAIA,GAAM,EACD8H,GAAQ9H,EAERqZ,IAAc9+B,KAAK8lB,IAAIL,GAAM,MAI3B0Z,GAA2B,CACtCrf,WAAYof,OACZlf,YAAa,MACbC,WAAYgf,ICdDG,GACTha,EAAgBia,WAAS,SAAC5Z,GAAO,OAAA,GAAK,EAAIzlB,KAAK8lB,KAAKL,OAE3C6Z,GAA8B,CACzCxf,WAAYuf,UACZrf,YAAa,MACbC,WAAYmf,ICNDG,GAAiBna,EAAgBoa,QAAM,SAAC/Z,GACnD,OAAIA,EAAK,GACC,EACCA,EAAK,EACP,EAEA,KAIEga,GAA2B,CACtC3f,WAAY0f,OACZxf,YAAa,MACbC,WAAYsf,ICbDG,GAAgBta,EAAgBua,OAAK,SAACla,GAAO,OAAAzlB,KAAKs+B,IAAI7Y,MAEtDma,GAA0B,CACrC9f,WAAY6f,MACZ3f,YAAa,MACbC,WAAYyf,ICLDG,GAAiBza,EAAgB0a,QAAM,SAACra,GAAO,OAAAzlB,KAAK+/B,KAAKta,MAEzDua,GAA2B,CACtClgB,WAAYggB,OACZ9f,YAAa,MACbC,WAAY4f,ICCRI,GAAYjgC,KAAK4mB,IADP,uBACsB,EAEzBsZ,GAAqB9a,EAAgB+a,YAAU,SAAC1a,GAG3D,IAAM2a,EAAW3a,GAAMwa,GAIjBI,EAAW5a,EAAKwa,GAEhBK,EAAOtgC,KAAK8lB,IAAIL,GAUtB,OAPI4a,EACOC,EACAF,EACA3a,EAEAzlB,KAAK4mB,IAAI,EAAM0Z,MAKfC,GAA+B,CAC1CzgB,WAAYqgB,WACZngB,YAAa,MACbC,WAAYigB,aC9BEM,GAAUtgB,GAKjB,IAAAqB,WAAQa,UAAOppB,YACfC,MACAgwB,SAEPlxB,EAAiBkB,EAAG,aAKpB,IAHA,IAAMiwB,EAAQjwB,EAAEiB,MAAMsD,OAEhBqP,EAAqB,IAAI3U,MAAMgxB,GAC5B/rB,EAAI,EAAGA,EAAI0P,EAASrP,OAAQL,IACnC0P,EAAS1P,GAAKlE,EAAEiB,MAAM+uB,EAAK9rB,IAG7B,IACMwB,EAASoqB,GADA/vB,EAAQY,KAAKU,IAAIrB,EAAEwB,QAAQR,OACLhB,EAAEiB,MAAOjB,EAAET,MAAOywB,EAAMpc,GAG7D,MAAO,CAACpS,OADOzB,EAAQ4B,MAAM+D,EAAQkO,EAAU5T,EAAET,OACjC0B,MAAO2S,EAAUrU,MAAOS,EAAET,OAGrC,IAAMioC,GAAgC,CAC3C3gB,WAAY4gB,YACZ1gB,YAAa,MACbC,WAAYugB,ICgCP,IAAMG,GAAqC,CAChD7gB,WAAY8gB,iBACZ5gB,YAAa,MACbC,oBA7D6BC,GAKtB,IAAAqB,WAAQvoB,YAASopB,UACjBnpB,MACAiU,eAAYswB,aAEnBzlC,EAAiB,CAACkB,GAAI,kBAEtB,IAAMwJ,EAAOnK,OAAKgK,cAAc4K,GAE1B2zB,EAA4C,CAAC,CAAC,EAAG,IACvDA,EAAiB39B,WAAjB29B,EAA0BrD,GAE1B,IAAK,IAAIrgC,EAAI,EAAI+P,EAAW1P,OAAQL,EAAIlE,EAAEiB,MAAMsD,SAAUL,EACxD0jC,EAAiB39B,KAAK,CAAC,EAAG,IAG5B,IAAM49B,EAAUxD,GAAYrd,WAAW,CACrCsB,OAAQ,CAACtoB,KACTD,UACAopB,MAAO,CAACob,SAAUqD,EAAkBpD,cAAe,KAG/CsD,EACFxmC,eAAa+S,YAAYwzB,EAAQ5mC,MAAOgT,EAAYzK,GAAM,GAExDu+B,EAAoCzmC,eAAaiT,YACnDuzB,EAAoBvjC,OAAQ0P,EAAW1P,QAAQ,GAE7CgiB,EACFjlB,eAAamT,oBAAoBozB,EAAQ5mC,MAAOgT,EAAYzK,GAAM,GAIhEw+B,EACF7iC,GAAQ,CAACmjB,OAHwB,CAACtoB,EAAG6nC,GAGL9nC,UAASopB,MAFV,CAACloB,MAAO6mC,KAOrCG,EACFV,GAAU,CAACjf,OAJ0B,CAACtoB,EAAGgoC,GAILjoC,UAASopB,MAF5B,CAAC6G,KAAM+X,KAMtBriC,EAASP,GACX,CAACmjB,OAHsC,CAACtoB,EAAGioC,GAGbloC,UAASopB,MAFF,CAACloB,MAAOslB,KAQjD,OAJAxmB,EAAQwpB,8BAA8Bse,GACtC9nC,EAAQwpB,8BAA8Bye,GACtCjoC,EAAQwpB,8BAA8B0e,GAE/BviC,IC5DIwiC,GAAiB/b,EAAgBgc,QAAM,SAAC3b,GAAO,OAAAzlB,KAAKunB,KAAK9B,MAEzD4b,GAA2B,CACtCvhB,WAAYshB,OACZphB,YAAa,MACbC,WAAYkhB,ICJDG,GAA6B,CACxCxhB,WAAYyhB,SACZvhB,YAAa,MACbC,WAAY,SAACjlB,OAACumB,WAAQvoB,YACbC,MACDknB,EAAannB,EACnBjB,EAAiBkB,EAAG,UAIpB,IAFA,IAAMgB,EAASkmB,EAAWvmB,KAAKU,IAAIrB,EAAEwB,QAAQR,OACvCgK,EAAY,IAAIa,aAAa7K,EAAOuD,QACjCL,EAAI,EAAGA,EAAIlD,EAAOuD,SAAUL,EAAG,CACtC,IAAMkG,EAAQpJ,EAAOkD,GACrB8G,EAAU9G,GAAKkG,EAAQA,EAGzB,MAAO,CAAC5I,OADO0lB,EAAWvlB,MAAMqJ,EAAWhL,EAAEiB,MAAOjB,EAAET,OACtC0B,MAAOjB,EAAEiB,MAAO1B,MAAOS,EAAET,SCfhCgpC,GAAwB9gB,YAA+BphB,EAAGE,GACrE,IAAMgF,EAAOlF,EAAIE,EACjB,OAAOgF,EAAOA,KAEHi9B,GACTve,EAAiBwe,oBAAmBF,IAE3BG,GAAwC,CACnD7hB,WAAY4hB,oBACZ1hB,YAAa,MACbC,WAAYwhB,ICXDG,GAAiBxc,EAAgByc,QAAM,SAACpc,EAAIrD,GACvD,IAAM0f,EAAY1f,EAClB,OAAI1R,MAAM+U,GACDsc,IAEAtc,EAAK,EAAI,EAAIqc,EAAUzqB,SAIrB2qB,GAA2B,CACtCliB,WAAY+hB,OACZ7hB,YAAa,MACbC,WAAY2hB,ICZDK,GAAgB7c,EAAgB8c,OAAK,SAACzc,GAAO,OAAAzlB,KAAKmiC,IAAI1c,MAEtD2c,GAA0B,CACrCtiB,WAAYoiB,MACZliB,YAAa,MACbC,WAAYgiB,ICLDI,GAAiBjd,EAAgBkd,QAAM,SAAC7c,GAAO,OAAAzlB,KAAKuiC,KAAK9c,MAEzD+c,GAA2B,CACtC1iB,WAAYwiB,OACZtiB,YAAa,MACbC,WAAYoiB,IC4Id,IC7HO,IAAMI,GAA6B,CACxC3iB,WAAY4iB,SACZ1iB,YAAa,MACbC,oBAnBEC,GAEK,IAAAqB,WAAQa,UAAOppB,YACf8D,SACA7D,MACPlB,EAAiBkB,EAAG,UAEpB,IACM+B,KADShC,EAAQY,KAAKU,IAAIrB,EAAEwB,QAAQR,0BACnCswB,iBAAcnM,gBAAaxR,YAElC,MAAO,CACL5T,EAAQyoB,eAAerD,EAAanlB,EAAET,MAAO+xB,GAC7CvxB,EAAQyoB,eAAe,CAAC7U,EAAQpP,QAAS,QAASoP,WDiI3B+1B,GAzEW,CACpC9iB,EACA8K,GACAI,GACA7F,EACAiG,GACAI,GACAI,GACAI,GACAQ,GACAS,GACAK,GACArK,EACA4C,EACAgJ,GACAlN,EACA8O,GACAK,GACAI,GACAC,GACA0B,GACAV,GACAiB,GACAG,GACAgB,GACArO,EACAK,EACAgT,GACAK,GACAjT,EACA5E,EACAoY,GACApL,GACAyL,GACAI,GACAG,GACA/T,EACAmU,GACAG,GACAU,GACAE,GACAE,GACAb,GACAjU,EACAsV,GACAI,GACAM,GACAC,GACArb,EACA4b,GACA1O,GACA2O,GACAe,GACAnX,GACAyX,GACAG,GACAG,GACAG,GACAI,GACAxX,GACA+X,GACAI,GACAU,GACAC,GACAK,GACAK,GACAlZ,GACAsZ,GACAI,GACA/B,GACAgC,IAGyBG,aAAAA,KAAe,CAArC,IAAMC,UACTC,iBAAeD,iDEpKD"}